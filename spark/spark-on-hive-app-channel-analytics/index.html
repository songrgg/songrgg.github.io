<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Spark on Hive实现APP渠道分析 · Songrgg's Blog</title><meta name="description" content="Spark on Hive实现APP渠道分析 - songrgg"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://songrgg.github.io/atom.xml" title="Songrgg's Blog"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/songrgg" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Spark on Hive实现APP渠道分析</h1><div class="post-info">Feb 4, 2018</div><div class="post-content"><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近在做APP投放渠道分析，就是Android应用投放到应用市场，所谓渠道就是huawei,xiaomi,yingyongbao之类，运营人员根据数据分析渠道的下载安装情况、各个渠道的投放效果。</p>
<h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>完成一个Android渠道分析的展示面板，包含以下指标：</p>
<ul>
<li>APP总新增激活数量</li>
<li>按渠道划分的新增数量</li>
<li>各渠道的新增变化走势图（以小时为单位）</li>
<li>品牌占比</li>
<li>操作系统占比</li>
</ul>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/images/app-channel-analytics-architecture.png" alt=""></p>
<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>APP激活时上报给服务端数据，Flume处理数据并将数据发送到Kafka。</p>
<h4 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h4><p>客户端上报对JSON格式更加友好，所以这里选择使用JSON格式，格式定义一方面需要考虑客户端的开发成本，一方面需要考虑日后的拓展性，所以最直接的方法是统一固定的字段，将根据事件所变化的内容放到拓展字段里去，拓展字段是Map类型，可以支持各种拓展的形式。</p>
<h4 id="数据内容"><a href="#数据内容" class="headerlink" title="数据内容"></a>数据内容</h4><p>以此次渠道分析为例，客户端需要上传客户端的渠道、APP版本、设备标志符、设备型号等信息，更详细的如Geo信息，如果想获得更好的数据展示效果，可以上传，但在此场景可以不需要，这些是主动上报的部分。还有一部分内容是需要在服务端获取的，例如设备IP，为了之后的地理展示，可以使用MaxMind公司的IP与城市对应的数据库进行地理解析。</p>
<h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><p><a href="https://flume.apache.org" target="_blank" rel="noopener">flume</a>接受到客户端的数据之后，需要对数据进行解析JSON，并且获得用户IP、分析Geo Location做一些轻量级的处理，因为这个部分是在前端flume做的，这个部分的flume重点是逻辑要轻，重要的是吞吐量高和延迟低。</p>
<p>接下来前端flume把处理完的数据按照事件名发送到<a href="https://kafka.apache.org" target="_blank" rel="noopener">Kafka</a>同名的topic中，后端flume消费Kafka并将消息转存到Hdfs中。</p>
<h4 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h4><p>将数据从Hdfs持久化到Hive，一方面是更节省空间，一方面是更有利于<a href="https://spark.apache.org" target="_blank" rel="noopener">Spark</a>进行查询。</p>
<p>这里持久化到Hive的方法，可以有几种：</p>
<ul>
<li>Flume直接读取Kafka的数据并存储到Hive，这是由Flume的Hive Sink实现的，数据持久化到Hive Transaction表，是Hive 0.13引入的，支持ACID。</li>
<li>Flume读取数据到Hdfs，支持配置文件路径，可以根据时间来划分存储路径，之后可以定期使用Hive加载数据，将数据存储到Hive中去。</li>
</ul>
<p>第一种方法，相对来说配置简单，省去了中间一步转储的过程。第二种方法，相对繁琐，但是之后会有一个好处。</p>
<p>下面是设备注册表<code>device_registration</code>的schema</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`bi.device_registration`</span>(</span><br><span class="line">  <span class="string">`app_id`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`uid`</span> <span class="built_in">bigint</span>,</span><br><span class="line">  <span class="string">`time`</span> <span class="built_in">bigint</span>,</span><br><span class="line">  <span class="string">`ip`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`device_id`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`app_version`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`os_name`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`os_version`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`device_brand`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`device_model`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`ua_name`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`ua_version`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`channel`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`ts`</span> <span class="keyword">timestamp</span>,</span><br><span class="line">  <span class="string">`lon`</span> <span class="keyword">double</span>,</span><br><span class="line">  <span class="string">`lat`</span> <span class="keyword">double</span>,</span><br><span class="line">  <span class="string">`country`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`city`</span> <span class="keyword">string</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这里要提一下，为什么有了<code>time</code>这个unix时间戳，还需要<code>ts</code>这个<code>timestamp</code>类型的时间，实际上是为了之后的查询工具<code>Superset</code>需要使用来实现按时间查询。</p>
<h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><p>这里的计算每小时运行一次，从Hive中读取过去一个小时的设备激活原数据，与<code>device_registration</code>进行比对，将未出现在<code>device_registration</code>中的设备信息加入。</p>
<p>这里可以使用<code>JOIN</code>来实现，Spark数据表之间的Join方式有多种，<code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>full_outer</code>, <code>left</code>, <code>left_outer</code>, <code>right</code>, <code>right_outer</code>, <code>left_semi</code>, <code>left_anti</code></p>
<p>这里场景适合使用<code>left_anti</code>，因为是取不在这个集合的设备信息。</p>
<p>这里还要注意，因为时间区间内的数据有可能会有重复，所以需要取时间较早的那条，这里用到了<code>groupByKey</code>和<code>reduceGroups</code>，具体是</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">deviceInfos.as[<span class="type">Device</span>]</span><br><span class="line">    .groupByKey(_.device_id)</span><br><span class="line">    .reduceGroups((x, y) =&gt; <span class="keyword">if</span> (x.time &lt; y.time) x <span class="keyword">else</span> y)</span><br><span class="line">    .map[<span class="type">Device</span>]((x: (<span class="type">String</span>, <span class="type">Device</span>)) =&gt; x._2)</span><br><span class="line">    .write.mode(<span class="type">SaveMode</span>.<span class="type">Append</span>)</span><br><span class="line">    .format(<span class="string">"hive"</span>)</span><br><span class="line">    .saveAsTable(<span class="string">"bi.device_registration"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>查询引擎使用<a href="https://prestodb.io" target="_blank" rel="noopener">Presto</a>，配置Hive Connector，实时搜索数据。刚才上面提到数据持久化Hive中的两种方法，其中支持事务的表不可用于Presto的查询，因为Hive Transaction表的数据格式未被Presto支持(详见<a href="https://github.com/prestodb/presto/issues/1970" target="_blank" rel="noopener">Implement Hive ACID table support</a>)。</p>
<h5 id="直接查询"><a href="#直接查询" class="headerlink" title="直接查询"></a>直接查询</h5><p>通过上一步的<code>device_registration</code>表，我们可以通过时间维度进行查询。</p>
<p>直接查询就是查询raw data，数据更加丰富。这里以“按渠道划分的新增数量”为例，</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="string">"channel"</span> <span class="keyword">AS</span> <span class="string">"channel"</span>,</span><br><span class="line">       date_trunc(<span class="string">'hour'</span>, <span class="keyword">CAST</span>(ts <span class="keyword">AS</span> <span class="keyword">TIMESTAMP</span>)) <span class="keyword">AS</span> <span class="string">"__timestamp"</span>,</span><br><span class="line">       <span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> <span class="string">"count"</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="string">"bi"</span>.<span class="string">"device_registration"</span></span><br><span class="line"><span class="keyword">WHERE</span> <span class="string">"ts"</span> &gt;= from_iso8601_timestamp(<span class="string">'2018-02-03T16:29:29'</span>)</span><br><span class="line">  <span class="keyword">AND</span> <span class="string">"ts"</span> &lt;= from_iso8601_timestamp(<span class="string">'2018-02-05T08:29:29'</span>)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="string">"channel"</span>,</span><br><span class="line">         date_trunc(<span class="string">'hour'</span>, <span class="keyword">CAST</span>(ts <span class="keyword">AS</span> <span class="keyword">TIMESTAMP</span>))</span><br></pre></td></tr></table></figure>
<h5 id="预先计算"><a href="#预先计算" class="headerlink" title="预先计算"></a>预先计算</h5><p>预先计算就是将图表展示需要的数据结果提前计算存储到数据库，查询的时候直接就可以从结果表中查询。</p>
<p>预先计算是用空间换时间，损失一些灵活性，不如查询raw data时可以自由定制查询。每次新增查询对于预先计算来说都需要新增加计算逻辑。随着数据量的增大，预先计算不可避免。</p>
<h5 id="优化查询速度"><a href="#优化查询速度" class="headerlink" title="优化查询速度"></a>优化查询速度</h5><p>运行一段时间后，查询速度明显变慢，查看Hdfs上的hive目录发现数据表内的小文件多达几百上千，这是由于Spark处理完数据并写入Hive会产生非常多的bucket，与数据条数成正比，写入成本低却增加了读数据的成本，这样当数据查询时，由于Hdfs上的小文件非常之多，I/O花费很大，导致整体查询速度下降迅速，这里想办法将文件进行合并，减少文件数量。</p>
<p>通过使用Hive执行compaction，方法比较取巧，就是在每次计算完数据之后，运行Hive脚本，通过复制数据库，Hive会自动将文件数量压缩：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> bi.device_registration_compact <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">from</span> bi.device_registration;</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> bi.device_registration;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> bi.device_registration_compact <span class="keyword">RENAME</span> <span class="keyword">TO</span> bi.device_registration;</span><br></pre></td></tr></table></figure>
<p>将Hdfs上的文件数量降低到个位数，查询也在秒级完成，这种方法只适用于数据量不大的情况，目前记录条数在1M以内的查询速度在秒级，之后依然会考虑使用其它方案改良。</p>
<h3 id="展示"><a href="#展示" class="headerlink" title="展示"></a>展示</h3><p><a href="https://superset.apache.org/" target="_blank" rel="noopener">Superset</a>是Airbnb开源的图表展示工具，不仅支持很多后端查询引擎，并且有许多成熟的图表展示，更可贵的是拥有用户权限管理。</p>
<h4 id="图表的选择"><a href="#图表的选择" class="headerlink" title="图表的选择"></a>图表的选择</h4><ol>
<li><p>Pie Chart<br>占比类数据展示，如品牌占比、操作系统占比等</p>
</li>
<li><p>Big Number<br>新增设备总数等指标</p>
</li>
<li><p>Filter Box<br>用于自定义一些过滤条件，在Dashboard上可以自由筛选数据</p>
</li>
<li><p>Table View<br>例如排行榜，按大小展示一些渠道的新增值</p>
</li>
<li><p>Time Series - Line Chart<br>时序图的形式展现各个渠道的新增</p>
</li>
<li>Mapbox<br>地图的形式更直观地展示各个城市的新增热点</li>
</ol>
<p><img src="/images/androidappos.png" alt="androidappos"><br><img src="/images/androidgeo.png" alt="test2"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>数据处理和展示中，就像一个管道，<strong>数据采集、数据存储、数据处理、数据查询</strong>每一个步骤都不能漏，而且对于这些有周期性的分析，最需要做到的是稳定，每天24个小时都能正确的运行。这只是一个初步的方案，依然有优化的地方，像数据集肯定会越来越大，使用计算中间结果来减少对历史数据的回溯，寻找更稳定和自然的数据压缩的方案。</p>
</div></article></div></main><footer><div class="paginator"><a href="/operation/ansible-frequently-used-commands/" class="prev">上一篇</a><a href="/uncategorized/hive-on-spark-practice/" class="next">下一篇</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'srjiang';
var disqus_identifier = 'spark/spark-on-hive-app-channel-analytics/';
var disqus_title = 'Spark on Hive实现APP渠道分析';
var disqus_url = 'https://songrgg.github.io/spark/spark-on-hive-app-channel-analytics/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//srjiang.disqus.com/count.js" async></script><div class="copyright"><p>© 2015 - 2018 <a href="https://songrgg.github.io">songrgg</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-74431120-1",'auto');ga('send','pageview');</script></body></html>