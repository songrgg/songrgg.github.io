<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog | Songrgg</title>
  
  <subtitle>A programmer who likes travelling and cooking :)</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://songrgg.github.io/"/>
  <updated>2022-09-24T19:52:43.834Z</updated>
  <id>https://songrgg.github.io/</id>
  
  <author>
    <name>songrgg</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Build a production-ready web application Part 1: Python Basics</title>
    <link href="https://songrgg.github.io/programming/python-quickstart-1-basics/"/>
    <id>https://songrgg.github.io/programming/python-quickstart-1-basics/</id>
    <published>2022-09-23T22:00:00.000Z</published>
    <updated>2022-09-24T19:52:43.834Z</updated>
    
    <content type="html"><![CDATA[<p>This article helps the software engineers who have Web development experience in other languages to migrate to Python Web development quickly, it contains several parts like <strong>basics</strong>, <strong>web development part</strong>, etc.</p><span id="more"></span><h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>I’m a developer who used Golang in the recent 4 years, I’m getting used to Golang and its framework, because of my team’s preference, we chose Python 3 as the new project’s language, I wanted to write Python code as well as possible in a short time. Because the core of Web development is the same no matter what language it is, I just need to migrate my Web knowledge to Python 3.8+.</p><p>This is the checklist of all the essential knowledge I sorted out in the last month.</p><h2 id="Python-Basics"><a href="#Python-Basics" class="headerlink" title="Python Basics"></a>Python Basics</h2><p>First, let’s recap the most basic Python syntax. (PS: I’ll mix different languages’ syntax when I switch languages very often, the common case is that I wrote <code>for i in items</code> in Golang)</p><h3 id="Entrypoint"><a href="#Entrypoint" class="headerlink" title="Entrypoint"></a>Entrypoint</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&#x27;hello world&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="If-else-statement"><a href="#If-else-statement" class="headerlink" title="If-else statement"></a>If-else statement</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> a <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nothing&#x27;</span>)</span><br><span class="line"><span class="keyword">elif</span> a == <span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Bingo&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;bye&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="Common-data-structures"><a href="#Common-data-structures" class="headerlink" title="Common data structures"></a>Common data structures</h3><p>It contains array, set, dictionary, tuple.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># array</span></span><br><span class="line">arr = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="number">1</span> <span class="keyword">in</span> arr:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;1 is in the arr&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># set</span></span><br><span class="line">visited = <span class="built_in">set</span>()</span><br><span class="line">visited.add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="number">1</span> <span class="keyword">in</span> visted:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;1 is in visited&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># dict, it will throw error when the key is not found</span></span><br><span class="line">word_mapping = <span class="built_in">dict</span>()</span><br><span class="line">word_mapping[<span class="string">&#x27;Peace&#x27;</span>] = <span class="string">&#x27;Love&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(word_mapping[<span class="string">&#x27;Peace&#x27;</span>]) <span class="comment"># Outputs: Love</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># defaultdict, it will return default value when the key is not found</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">def_value</span>():</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Undefined&quot;</span></span><br><span class="line"></span><br><span class="line">word_mapping = defaultdict(def_value)</span><br><span class="line"><span class="built_in">print</span>(word_mapping[<span class="string">&#x27;no existing key&#x27;</span>]) <span class="comment"># Outputs: Undefined</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># tuple</span></span><br><span class="line">countries = (<span class="string">&quot;China&quot;</span>, <span class="string">&quot;Netherlands&quot;</span>, <span class="string">&quot;Spain&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(countries[<span class="number">0</span>]) <span class="comment"># Outputs: China</span></span><br></pre></td></tr></table></figure><h3 id="Iteration"><a href="#Iteration" class="headerlink" title="Iteration"></a>Iteration</h3><p>To iterate an array, list, set, dictionary, you can always use <code>for … in</code> , also it allows you to create an iterable object which contains the iterable object returned by <code>__iter__</code> and the way to fetch next object by <code>__next__</code> .</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># iterate arr</span></span><br><span class="line">arr = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> arr:</span><br><span class="line">    <span class="built_in">print</span>(k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># iterate dict</span></span><br><span class="line">word_mapping = &#123;<span class="string">&quot;Peace&quot;</span>: <span class="string">&quot;Love&quot;</span>, <span class="string">&quot;Love&quot;</span>: <span class="string">&quot;Peace&quot;</span>&#125;</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> word_mapping:</span><br><span class="line">    <span class="built_in">print</span>(word_mapping[k])</span><br><span class="line"></span><br><span class="line"><span class="comment"># customized iterable objects</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLanguages</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.languages = [<span class="string">&quot;Python&quot;</span>, <span class="string">&quot;Golang&quot;</span>, <span class="string">&quot;Java&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.index &gt;= <span class="built_in">len</span>(self.languages):</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line">        res = self.languages[self.index]</span><br><span class="line">        self.index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">languages = MyLanguages()</span><br><span class="line"><span class="keyword">for</span> language <span class="keyword">in</span> languages:</span><br><span class="line">    <span class="built_in">print</span>(language)</span><br></pre></td></tr></table></figure><h3 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h3><p>It contains traditional function and anonymous function like the other languages.</p><p>Traditional function is the one with <code>def</code> keyword, name of function and function body.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sum_two accepts two int parameters and return the sum of them.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_two</span>(<span class="params">num1: <span class="built_in">int</span>, num2: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">    <span class="keyword">return</span> num1 + num2</span><br></pre></td></tr></table></figure><p>We also want variable parameters sometimes, we can add <code>*</code> before the parameter and the parameter will accept multiple parameters, type type of <code>args</code> is tuple.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sum_all accepts multiple integer parameters and sum them up.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum_all</span>(<span class="params">*args: <span class="built_in">int</span></span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> args:</span><br><span class="line">        <span class="built_in">sum</span> += arg</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line">sum_all(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><p>We want to accept variable name parameters, we can add <code>**</code> before the parameter and the parameter will receive <code>key=value</code> pairs.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_vars</span>(<span class="params">**kwargs</span>):</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> kwargs:</span><br><span class="line">        <span class="built_in">print</span>(k, <span class="string">&quot;=&gt;&quot;</span>, kwargs[k])</span><br><span class="line"></span><br><span class="line">print_vars(name=<span class="string">&quot;songrgg&quot;</span>, hobby=<span class="string">&#x27;cooking&#x27;</span>)</span><br><span class="line"><span class="comment"># name =&gt; songrgg</span></span><br><span class="line"><span class="comment"># hobby =&gt; cooking</span></span><br></pre></td></tr></table></figure><p>Note that the <code>**kwargs</code> parameters should be at the end of the parameter list, otherwise it’s not straightforward for the Python interpreter to parse the parameters afterwards.</p><p>For anonymous functions, we use <code>lambda</code> as the keyword, it can accept multiple parameters but only one expression in the body.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum_two = <span class="keyword">lambda</span> num1, num2: num1 + num2</span><br><span class="line"><span class="built_in">print</span>(sum_two(<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># Output: 3</span></span><br></pre></td></tr></table></figure><p>It’s super useful when you’re using some map, filter, sort, etc and it accepts a lambda function.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># map</span></span><br><span class="line">numbers1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">numbers2 = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">  </span><br><span class="line">result = <span class="built_in">map</span>(<span class="keyword">lambda</span> x, y: x + y, numbers1, numbers2)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(result)) <span class="comment"># Output: [5, 7, 9]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># filter</span></span><br><span class="line">number_list = <span class="built_in">range</span>(-<span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">less_than_zero = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x &lt; <span class="number">0</span>, number_list))</span><br><span class="line"><span class="built_in">print</span>(less_than_zero) <span class="comment"># Output: [-5, -4, -3, -2, -1]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># sort based on the 1-index value asc</span></span><br><span class="line">a = [(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">9</span>, <span class="number">10</span>), (<span class="number">13</span>, -<span class="number">3</span>)]</span><br><span class="line">a.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(a) <span class="comment"># Output: [(13, -3), (4, 1), (1, 2), (9, 10)]</span></span><br></pre></td></tr></table></figure><h3 id="Class-definition"><a href="#Class-definition" class="headerlink" title="Class definition"></a>Class definition</h3><p>The class definition starts with <code>class</code> keyword, the class contains some functions by convention, like the constructor function <code>__init__</code> , method call <code>__call__</code> which allows you to call the class instance like a function.</p><p>The <code>self</code> parameter appears for those instance functions, it’s the <code>this</code> keyword in other languages, a pointer to the instance itself, it’s always as the first parameter.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sample</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Sample init&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Sample is called implicitly by __call__&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sample = Sample()</span><br><span class="line"></span><br><span class="line"><span class="comment"># shorthand for sample.__call__()</span></span><br><span class="line">sample()</span><br></pre></td></tr></table></figure><p>There are also class functions whose scope is the class, the first parameter is <code>cls</code> instance, they will be introduced in the decorators section.</p><h3 id="Decorators"><a href="#Decorators" class="headerlink" title="Decorators"></a>Decorators</h3><p>A decorator is a design pattern in Python that allows a user to add new functionality to an existing object without modifying its structure.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">echo_first</span>(<span class="params">f</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Nothing special, echo first before the method is called &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_f</span>(<span class="params">*args, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;echo&#x27;</span>)</span><br><span class="line">        f(*args, **kwargs)</span><br><span class="line">    <span class="keyword">return</span> new_f</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line"><span class="meta">    @echo_first</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">method</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;method called&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Test().method()</span><br></pre></td></tr></table></figure><p>In this sample, it’s a simple function decorator that print <code>echo</code> first before the method is called.</p><p>There are some common used decorators we can use, <code>@staticmethod</code> prevents the method access to the class or instance, <code>@classmethod</code> limits the access to the class itself, <code>instance_method</code> has the biggest scope.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">static_method</span>():</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I don&#x27;t have access to the class or instance&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">class_method</span>(<span class="params">cls</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I only have access to the class&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">instance_method</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.value = <span class="number">1</span></span><br><span class="line">        Test2.cls_value = <span class="number">2</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;I have access to both class and instance&quot;</span>)</span><br></pre></td></tr></table></figure><p>There is <code>@property</code> decorator to call the setter/getter/deleter of the property in a native way,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PropertyTest</span>:</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">x</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;I am the &#x27;x&#x27; property.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;getter called&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> self._x</span><br><span class="line"></span><br><span class="line"><span class="meta">    @x.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">x</span>(<span class="params">self, value</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;setter called&#x27;</span>)</span><br><span class="line">        self._x = value</span><br><span class="line"></span><br><span class="line"><span class="meta">    @x.deleter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">x</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">del</span> self._x</span><br><span class="line"></span><br><span class="line">pt = PropertyTest()</span><br><span class="line">pt.x = <span class="number">34</span> <span class="comment"># setter called</span></span><br><span class="line"><span class="built_in">print</span>(pt.x)</span><br><span class="line"><span class="comment"># Output: getter called</span></span><br><span class="line"><span class="comment"># 4</span></span><br><span class="line"><span class="keyword">del</span> pt.x</span><br></pre></td></tr></table></figure><h3 id="Error-handling"><a href="#Error-handling" class="headerlink" title="Error handling"></a>Error handling</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>: </span><br><span class="line">  …</span><br><span class="line"><span class="keyword">except</span> (ValueError, ZeroDivisionError):</span><br><span class="line">  …</span><br><span class="line"><span class="keyword">else</span>: </span><br><span class="line">  <span class="comment"># no exceptions raised</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">  <span class="comment"># cleanup code </span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Raising exceptions </span></span><br><span class="line"><span class="keyword">if</span> x &lt; <span class="number">1</span>:     </span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">&quot;…&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h3><blockquote><p>Coroutines are very similar to <a href="https://en.wikipedia.org/wiki/Thread_(computing)">threads</a>. However, coroutines are <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">cooperatively</a> multitasked, whereas threads are typically <a href="https://en.wikipedia.org/wiki/Preemptive_multitasking">preemptively</a> <a href="https://en.wikipedia.org/wiki/Computer_multitasking">multitasked</a>. Coroutines provide <a href="https://en.wikipedia.org/wiki/Concurrency_(computer_science)">concurrency</a> but not <a href="https://en.wikipedia.org/wiki/Parallel_computing">parallelism</a>. The advantages of coroutines over threads are that they may be used in a <a href="https://en.wikipedia.org/wiki/Hard_realtime">hard-realtime</a> context (<a href="https://en.wikipedia.org/wiki/Context_switch">switching</a> between coroutines need not involve any <a href="https://en.wikipedia.org/wiki/System_calls">system calls</a> or any <a href="https://en.wikipedia.org/wiki/Blocking_(computing)">blocking</a> calls whatsoever), there is no need for synchronization primitives such as <a href="https://en.wikipedia.org/wiki/Mutex">mutexes</a>, semaphores, etc. in order to guard <a href="https://en.wikipedia.org/wiki/Critical_sections">critical sections</a>, and there is no need for support from the operating system.</p></blockquote><p>The Python doc gives several examples of how to define coroutines and execute them,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">say_after</span>(<span class="params">delay, what</span>):</span></span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(delay)</span><br><span class="line">    <span class="built_in">print</span>(what)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;started at <span class="subst">&#123;time.strftime(<span class="string">&#x27;%X&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">await</span> say_after(<span class="number">1</span>, <span class="string">&#x27;hello&#x27;</span>)</span><br><span class="line">    <span class="keyword">await</span> say_after(<span class="number">2</span>, <span class="string">&#x27;world&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;finished at <span class="subst">&#123;time.strftime(<span class="string">&#x27;%X&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br><span class="line"><span class="comment"># it will take around 3 seconds for they&#x27;re running in sequence</span></span><br></pre></td></tr></table></figure><p>They can’t be executed as the normal methods, if you call <code>main()</code> directly, it returns a coroutine object, to execute it you need pass it to <a href="http://asyncio.run/">asyncio.run</a>.</p><p>To run the coroutines concurrently, you can wrap the coroutine to task by <code>asyncio.create_task</code> ,</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    task1 = asyncio.create_task(say_after(<span class="number">2</span>, <span class="string">&quot;hello&quot;</span>))</span><br><span class="line">    task2 = asyncio.create_task(async_method(<span class="number">2</span>, <span class="string">&quot;world&quot;</span>))</span><br><span class="line">    <span class="keyword">await</span> task1</span><br><span class="line">    <span class="keyword">await</span> task2</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br><span class="line"><span class="comment"># it will take around 2 seconds for they&#x27;re running concurrently</span></span><br></pre></td></tr></table></figure><p>It will run for around 2 seconds instead of 4 seconds.</p><p><strong>Awaitables</strong></p><blockquote><p>We say that an object is an <strong>awaitable</strong> object if it can be used in an <code>[await](https://docs.python.org/3/reference/expressions.html#await)</code> expression.</p></blockquote><ul><li>Coroutines: the <code>async def</code> functions</li><li>Tasks: used to schedule coroutines concurrently, created by <code>asyncio.create_task</code></li><li>Futures: A <a href="https://docs.python.org/3/library/asyncio-future.html#asyncio.Future">Future</a> is a special <strong>low-level</strong> awaitable object that represents an <strong>eventual result</strong> of an asynchronous operation.</li></ul><h2 id="End"><a href="#End" class="headerlink" title="End"></a>End</h2><p>Next Artitlce contains the toolkit of setting up the Web application using FastAPI framework, also it will contain the code format, linter, docker image, etc.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article helps the software engineers who have Web development experience in other languages to migrate to Python Web development quickly, it contains several parts like &lt;strong&gt;basics&lt;/strong&gt;, &lt;strong&gt;web development part&lt;/strong&gt;, etc.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="python" scheme="https://songrgg.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>How to set up a reasonable memory limit for Java applications in Kubernetes</title>
    <link href="https://songrgg.github.io/operation/how-to-setup-java-application-memory-limit-in-kubernetes/"/>
    <id>https://songrgg.github.io/operation/how-to-setup-java-application-memory-limit-in-kubernetes/</id>
    <published>2021-11-28T19:11:50.000Z</published>
    <updated>2021-11-28T20:37:10.611Z</updated>
    
    <content type="html"><![CDATA[<p>This article introduces some discovery of the Java memory usage in Kubernetes and how to set up a reasonable memory request/limit based on the Java heap requirement and the memory usage of the application.</p><span id="more"></span><h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>The trigger for me to look up the memory usage of Java applications in Kubernets is the increased OOM events in production, after investigation, it was not caused by JVM heap shortage, so I need to investigate where the non-heap memory goes.<br>(If you’re not familiar with the OOM events, you can check the article “<a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart &amp; OOMKilled in Kubernetes</a>“)</p><h2 id="Container-Metrics"><a href="#Container-Metrics" class="headerlink" title="Container Metrics"></a>Container Metrics</h2><p>There are several metrics for memory usage in Kubernetes,</p><ol><li><code>container_memory_rss</code> (<a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">cadvisor</a>)<br>The amount of anonymous and swap cache memory (includes transparent hugepages).</li><li><code>container_memory_working_set_bytes</code> (<a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">cadvisor</a>)<br>The amount of working set memory, this includes recently accessed memory, dirty memory, and kernel memory. Working set is &lt;= “usage” and it equals to Usage minus total_inactive_file.</li><li><code>resident set size</code><br>It is container_memory_rss + file_mapped (file_mapped is accounted only when the memory CGroup is owner of page cache)</li></ol><p>For Kubernetes, it depends on <code>container_memory_working_set_bytes</code> to oom-kill the container which exceeds the memory limit, we’ll use this metric in the following sections.</p><h2 id="Heap-Usage-lt-lt-Memory-Limit"><a href="#Heap-Usage-lt-lt-Memory-Limit" class="headerlink" title="Heap Usage &lt;&lt; Memory Limit"></a>Heap Usage &lt;&lt; Memory Limit</h2><p>After we noticed several OOMs in the production, it’s time to figure out the root cause. According to the JVM metrics, I found the heap size was way less than the Kubernetes memory usage, let’s check an sample, its memory usage upper limit is as high as 90% of the total memory size.</p><p>initial and max heap size is 1.5G Set by <code>XX:InitialHeapSize=1536m -XX:MaxHeapSize=1536m -XX:MaxGCPauseMillis=50</code><br>Kubernetes request and memory limit is 3G set by deployment.yaml,</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">resources:</span><br><span class="line">  limits:</span><br><span class="line">    memory: 3Gi</span><br><span class="line">  requests:</span><br><span class="line">    memory: 3Gi</span><br></pre></td></tr></table></figure><p>In the monitoring dashboard, Kubernetes memory usage is close to 90% of the memory limit which is 2.7G</p><p>In other words, the non-heap memory took 2.7G-1.5G = 1.2G.</p><h2 id="A-close-up-on-Java-memory"><a href="#A-close-up-on-Java-memory" class="headerlink" title="A close-up on Java memory"></a>A close-up on Java memory</h2><p>JVM contains heap and non-heap memory, let’s take a sample. The data is from an application with <code>XX:InitialHeapSize=1536m -XX:MaxHeapSize=1536m -XX:MaxGCPauseMillis=50</code></p><h3 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h3><p>If we set the max size of the heap, we can consider the upper limit is fixed and heap size is 1.5G, we can divide the heap memory into Eden, Survivor, Old regions if we were using G1 as our GC algorithm.</p><p>We can check heap info by <code>jcmd</code>, as we can see the used heap 593M is way less than the committed size <code>1.5G</code>, so we are good with the heap usage.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bash-4.2$ jcmd 99 GC.heap_info</span><br><span class="line">99:</span><br><span class="line"> garbage-first heap   total 1572864K, used 608214K [0x00000000a0000000, 0x0000000100000000)</span><br><span class="line">  region size 1024K, 255 young (261120K), 1 survivors (1024K)</span><br><span class="line"> Metaspace       used 82997K, capacity 85390K, committed 89168K, reserved 1126400K</span><br><span class="line">  class space    used 9600K, capacity 10640K, committed 11980K, reserved 1048576K</span><br><span class="line">Non-Heap Analysis with NMT</span><br></pre></td></tr></table></figure><p>To get more debug information, I enabled the <code>native memory tracking</code> (switch on Native memory tracking by adding XX:NativeMemoryTracking=[off | summary | detail] to the Java options) in the app, I chose <code>detail</code> to show more details of the memory usage.</p><p>After the application ran for 5 days, the memory usage was increasing slowly to 78.29% of the memory limit (3G), namely 2.35G.</p><p>Let’s use jcmd to show where the memory went,</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">bash-4.2$ jcmd 99 VM.native_memory</span><br><span class="line">99:</span><br><span class="line"></span><br><span class="line">Native Memory Tracking:</span><br><span class="line"></span><br><span class="line">Total: reserved=3597274KB, committed=2291546KB</span><br><span class="line">-                 Java Heap (reserved=1572864KB, committed=1572864KB)</span><br><span class="line">                            (mmap: reserved=1572864KB, committed=1572864KB)</span><br><span class="line"></span><br><span class="line">-                     Class (reserved=1128971KB, committed=91739KB)</span><br><span class="line">                            (classes <span class="comment">#13083)</span></span><br><span class="line">                            (  instance classes <span class="comment">#12390, array classes #693)</span></span><br><span class="line">                            (malloc=2571KB <span class="comment">#40364)</span></span><br><span class="line">                            (mmap: reserved=1126400KB, committed=89168KB)</span><br><span class="line">                            (  Metadata:   )</span><br><span class="line">                            (    reserved=77824KB, committed=77188KB)</span><br><span class="line">                            (    used=73396KB)</span><br><span class="line">                            (    free=3792KB)</span><br><span class="line">                            (    waste=0KB =0.00%)</span><br><span class="line">                            (  Class space:)</span><br><span class="line">                            (    reserved=1048576KB, committed=11980KB)</span><br><span class="line">                            (    used=9601KB)</span><br><span class="line">                            (    free=2379KB)</span><br><span class="line">                            (    waste=0KB =0.00%)</span><br><span class="line"></span><br><span class="line">-                    Thread (reserved=73325KB, committed=7621KB)</span><br><span class="line">                            (thread <span class="comment">#71)</span></span><br><span class="line">                            (stack: reserved=72960KB, committed=7256KB)</span><br><span class="line">                            (malloc=252KB <span class="comment">#428)</span></span><br><span class="line">                            (arena=113KB <span class="comment">#140)</span></span><br><span class="line"></span><br><span class="line">-                      Code (reserved=250907KB, committed=48115KB)</span><br><span class="line">                            (malloc=3219KB <span class="comment">#15038)</span></span><br><span class="line">                            (mmap: reserved=247688KB, committed=44896KB)</span><br><span class="line"></span><br><span class="line">-                        GC (reserved=131736KB, committed=131736KB)</span><br><span class="line">                            (malloc=40392KB <span class="comment">#703266)</span></span><br><span class="line">                            (mmap: reserved=91344KB, committed=91344KB)</span><br><span class="line"></span><br><span class="line">-                  Compiler (reserved=965KB, committed=965KB)</span><br><span class="line">                            (malloc=832KB <span class="comment">#1061)</span></span><br><span class="line">                            (arena=133KB <span class="comment">#5)</span></span><br><span class="line"></span><br><span class="line">-                  Internal (reserved=371646KB, committed=371646KB)</span><br><span class="line">                            (malloc=371614KB <span class="comment">#2010417)</span></span><br><span class="line">                            (mmap: reserved=32KB, committed=32KB)</span><br><span class="line"></span><br><span class="line">-                     Other (reserved=899KB, committed=899KB)</span><br><span class="line">                            (malloc=899KB <span class="comment">#70)</span></span><br><span class="line"></span><br><span class="line">-                    Symbol (reserved=18735KB, committed=18735KB)</span><br><span class="line">                            (malloc=16042KB <span class="comment">#163964)</span></span><br><span class="line">                            (arena=2693KB <span class="comment">#1)</span></span><br><span class="line"></span><br><span class="line">-    Native Memory Tracking (reserved=46557KB, committed=46557KB)</span><br><span class="line">                            (malloc=513KB <span class="comment">#7270)</span></span><br><span class="line">                            (tracking overhead=46044KB)</span><br><span class="line"></span><br><span class="line">-               Arena Chunk (reserved=178KB, committed=178KB)</span><br><span class="line">                            (malloc=178KB)</span><br><span class="line"></span><br><span class="line">-                   Logging (reserved=4KB, committed=4KB)</span><br><span class="line">                            (malloc=4KB <span class="comment">#187)</span></span><br><span class="line"></span><br><span class="line">-                 Arguments (reserved=24KB, committed=24KB)</span><br><span class="line">                            (malloc=24KB <span class="comment">#493)</span></span><br><span class="line"></span><br><span class="line">-                    Module (reserved=208KB, committed=208KB)</span><br><span class="line">                            (malloc=208KB <span class="comment">#1919)</span></span><br><span class="line"></span><br><span class="line">-              Synchronizer (reserved=246KB, committed=246KB)</span><br><span class="line">                            (malloc=246KB <span class="comment">#2070)</span></span><br><span class="line"></span><br><span class="line">-                 Safepoint (reserved=8KB, committed=8KB)</span><br><span class="line">                            (mmap: reserved=8KB, committed=8KB)</span><br></pre></td></tr></table></figure><p>As the output said, the total committed memory is <strong>2.18G</strong>, committed heap size is the same as we specified, <strong>1.5G</strong>.</p><p>For the other sections, <code>Internal</code> took <strong>362M</strong> (371646KB), <code>GC</code> took <strong>128M</strong> (131736KB), <code>Class</code> took <strong>89M</strong> (91739KB), <code>Code</code> took 47M (48115KB), <code>Symbol</code> took 18M (18735KB), <code>Thread</code> took 7M, …</p><p>(Didn’t take Native Memory Tracking into account because it was the overhead of the tracing, not the real situation in production.)</p><p>Since I set an NMT baseline early, we can run <code>jcmd &lt;process-id&gt; VM.native_memory detail.diff</code> to know which method consumed the memory.</p><p>As the output below (full output), I omitted some sections which didn’t increase a lot. Compared to the baseline, the total committed memory increased <strong>437M</strong> (448201KB), the Internal section increased the most, <strong>361M</strong> (373425KB).</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Native Memory Tracking:</span><br><span class="line"></span><br><span class="line">Total: reserved=3599409KB +443893KB, committed=2293681KB +448201KB</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">-                      Code (reserved=250907KB +1KB, committed=48115KB +4321KB)</span><br><span class="line">                            (malloc=3219KB +1KB #15038 +444)</span><br><span class="line">                            (mmap: reserved=247688KB, committed=44896KB +4320KB)</span><br><span class="line"></span><br><span class="line">-                        GC (reserved=131889KB +31893KB, committed=131889KB +31893KB)</span><br><span class="line">                            (malloc=40545KB +31893KB #706519 +672802)</span><br><span class="line">                            (mmap: reserved=91344KB, committed=91344KB)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">-                  Internal (reserved=373425KB +369869KB, committed=373425KB +369869KB)</span><br><span class="line">                            (malloc=373393KB +369869KB #2020176 +2003461)</span><br><span class="line">                            (mmap: reserved=32KB, committed=32KB)</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">[0x00007ff2b5ab0cb1] GCNotifier::pushNotification(GCMemoryManager*, char const*, char const*)+0x71</span><br><span class="line">[0x00007ff2b5e099ce] GCMemoryManager::gc_end(bool, bool, bool, bool, GCCause::Cause, bool)+0x27e</span><br><span class="line">[0x00007ff2b5e0b95a] TraceMemoryManagerStats::~TraceMemoryManagerStats()+0x2a</span><br><span class="line">[0x00007ff2b5a537f8] G1CollectedHeap::do_collection_pause_at_safepoint(double)+0x8a8</span><br><span class="line">                             (malloc=31508KB type=Internal +31303KB #672175 +667804)</span><br><span class="line"></span><br><span class="line">[0x00007ff2b5e091b9] GCStatInfo::GCStatInfo(int)+0x29</span><br><span class="line">[0x00007ff2b5ab0c8d] GCNotifier::pushNotification(GCMemoryManager*, char const*, char const*)+0x4d</span><br><span class="line">[0x00007ff2b5e099ce] GCMemoryManager::gc_end(bool, bool, bool, bool, GCCause::Cause, bool)+0x27e</span><br><span class="line">[0x00007ff2b5e0b95a] TraceMemoryManagerStats::~TraceMemoryManagerStats()+0x2a</span><br><span class="line">                             (malloc=168044KB type=Internal +166951KB #672175 +667804)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>You can find out the memory in Internal was consumed by <code>TraceMemoryManagerStats::~TraceMemoryManagerStats()</code> which is related to GC, so it seems GC will create some GC data and the data size is slowly increasing. GC+Internal consumed 493M. So now we know where the non-heap memory goes.</p><h2 id="G1-Tuning"><a href="#G1-Tuning" class="headerlink" title="G1 Tuning?"></a>G1 Tuning?</h2><p>Java 11 uses <a href="https://docs.oracle.com/en/java/javase/11/gctuning/garbage-first-garbage-collector-tuning.html#GUID-0BB3B742-A985-4D5E-A9C5-433A127FE0F6">G1</a> as the default GC algorithm, <a href="https://docs.oracle.com/en/java/javase/11/gctuning/concurrent-mark-sweep-cms-collector.html#GUID-FF8150AC-73D9-4780-91DD-148E63FA1BFF">CMS</a> (Concurrent Mark Sweep) is deprecated and Java 11 mentioned</p><blockquote><p>The general recommendation is to use G1 with its default settings, eventually giving it a different pause-time goal and setting a maximum Java heap size by using -Xmx if desired.</p></blockquote><p>So that means by using G1, a complicated configuration is not that necessary, you just need to make a wish and G1 will try its best to implement it. It also indicates a bit why G1 will consume more and more memory, it might gather some information about the memory behavior to optimize the memory allocation.</p><p>To fit a Java application to the Kubernetes, we need to specify several things:</p><h3 id="InitialHeapSize-and-MaxHeapSize"><a href="#InitialHeapSize-and-MaxHeapSize" class="headerlink" title="InitialHeapSize and MaxHeapSize"></a>InitialHeapSize and MaxHeapSize</h3><p>Setting this is to limit the heap memory, setting them to the same value will reduce the heap resizing. You can either set the MaxHeapSize to a static value based on the usage or to a ratio of the memory limit like 50%, 60% depending on your real usage. So these two goals will conflict, in most cases, we set our goal of the pause time and G1 will configure based on the goal.</p><h3 id="MaxGCPauseMillis"><a href="#MaxGCPauseMillis" class="headerlink" title="MaxGCPauseMillis"></a>MaxGCPauseMillis</h3><p>The default value of it is 200, G1 will try to balance the throughout and the pause time based on this value. There are two directions in GC tuning:“Increase the throughout” means reducing the overall GC time.<br>“Improve the GC pause time” means doing GC more frequently, for example, it will reduce the size of Young region (eden, survivor region) to trigger the young GC more often.</p><h2 id="Calculate-the-required-memory-based-on-monitoring"><a href="#Calculate-the-required-memory-based-on-monitoring" class="headerlink" title="Calculate the required memory based on monitoring"></a>Calculate the required memory based on monitoring</h2><p>As the memory analysis showed, <code>the required memory = the max heap size + JVM non-heap (GC, Metaspace, Code, etc.)</code>, considering the application might need more native memory when using JNI APIs, like <code>java.util.zip.Inflater</code> will allocate some native memory for (de)compression.</p><p><strong>It’s hard to give an exact memory limit at first, we can always start with a loose limit and leave more room for the non-heap. After the application runs in the production for some time and the metrics are in place, we can adjust the memory limit based on the monitoring data.</strong></p><p>To help the developers to realize if the memory limit is reasonable, we can set some thresholds for the application resource usage, if the app falls into these holes, we will generate some warnings to the developers.</p><p>Memory Request is too high = 0.6 &gt;= mem_usage(p95) / mem_request<br>Memory Request is too low = 0.9 &lt;= mem_usage(p95) / mem_request<br>Memory Limit is too low = 0.85 &lt;= mem_usage(p95) / mem_limit</p><p>The prometheus we use is memory usage P95 in last 7 days.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">quantile_over_time(</span><br><span class="line">    0.95,</span><br><span class="line">    max by (namespace, container) (container_memory_working_set_bytes&#123;namespace=~&quot;&lt;namespace&gt;.*&quot;, container=&quot;&lt;container&gt;&quot;, pod=~&quot;&lt;pod&gt;-.+&quot;&#125;)[7d:]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>You can put the metrics on the monitoring dashboard and trigger alerts of warning level to the responsive team and iterate the memory limit accordingly, when you have more data I think this can also be automated.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>For Java applications, we recommend set the max heap with either a static value or a reasonable ratio (40% ~ 60%) based on the heap usage, make sure to leave enough space for GC and other native memory usage.</p><p>For other applications, we can set up the required memory based on the monitoring data, we should always give enough free memory for the application, a good start is the three limitations we set above.</p><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/">Implement zero downtime HTTP service rollout on Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/how-does-prometheus-query-works/">How does Prometheus query work? - Part 1, Step, Query and Range</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article introduces some discovery of the Java memory usage in Kubernetes and how to set up a reasonable memory request/limit based on the Java heap requirement and the memory usage of the application.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
      <category term="jvm" scheme="https://songrgg.github.io/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>How to alert for Pod Restart &amp; OOMKilled in Kubernetes</title>
    <link href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/"/>
    <id>https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/</id>
    <published>2021-06-26T08:27:50.000Z</published>
    <updated>2021-07-14T12:34:14.719Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>This article introduces how to set up alerts for monitoring Kubernetes Pod restarts and more importantly, when the Pods are OOMKilled we can be notified.</p></blockquote><span id="more"></span><h2 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h2><p>Recently, we noticed some containers’ restart counts were high, and found they were caused by OOMKill (the process is out of memory and the operating system kills it). No existing alerts are reporting the container restarts and OOMKills so far. Although some OOMs may not affect the SLIs of the applications, it may still cause some requests to be interrupted, more severely, when some of the Pods were down the capacity of the application will be under expected, it might cause cascading resource fatigue.</p><h2 id="Data-source"><a href="#Data-source" class="headerlink" title="Data source"></a>Data source</h2><p><a href="https://github.com/google/cadvisor">cadvisor</a> &amp; <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md">kube-state-metrics</a> expose the k8s metrics, Prometheus and other metric collection system will scrape the metrics from them.</p><p>Here’s the list of cadvisor k8s metrics when using <a href="https://github.com/google/cadvisor/blob/master/docs/storage/prometheus.md">Prometheus</a>.</p><h2 id="Container-Restart-Metric"><a href="#Container-Restart-Metric" class="headerlink" title="Container Restart Metric"></a>Container Restart Metric</h2><p>For monitoring the container restarts, kube-state-metrics exposes the metrics to Prometheus as</p><ul><li>kube_pod_container_status_restarts_total → Count<br>The number of container restarts per container.</li></ul><p>We can use the increase of Pod container restart count in the last 1h to track the restarts.</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">increase(kube_pod_container_status_restarts_total[1h])</span><br></pre></td></tr></table></figure><h2 id="OOMKilled-Metric"><a href="#OOMKilled-Metric" class="headerlink" title="OOMKilled Metric"></a>OOMKilled Metric</h2><p>When the containers were killed because of OOMKilled, the container’s exit reason will be populated as OOMKilled and meanwhile it will emit a gauge <code>kube_pod_container_status_last_terminated_reason &#123; reason: &quot;OOMKilled&quot;, container: &quot;some-container&quot; &#125;</code> , </p><ul><li>kube_pod_container_status_last_terminated_reason → Gauge<br>Describes the last reason the container was in the terminated state.</li></ul><p>In Prometheus, we can use <code>kube_pod_container_status_last_terminated_reason&#123;reason=&quot;OOMKilled&quot;&#125;</code> to filter the <code>OOMKilled</code> metrics and build the graph.</p><p>However, as <a href="https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters/">Guide to OOMKill Alerting in Kubernetes Clusters</a> said, this metric will not be emitted when the OOMKill comes from the child process instead of the main process, so a more reliable way is to listen to the Kubernetes OOMKill events and build metrics based on that.</p><p>Fortunately, cadvisor provides such <code>container_oom_events_total</code> which represents “Count of out of memory events observed for the container” after v0.39.1</p><ul><li>container_oom_events_total → counter<br>Describes the container’s OOM events.</li></ul><p>cadvisor notices logs started with <code>invoked oom-killer:</code> from <code>/dev/kmsg</code> and emits the metric.</p><p>The kernel will oomkill the container when</p><ul><li>free memory is under the low limit</li><li>memory fragment, when allocating memory greater than <SIZE> and there is no contiguous memory available.</li></ul><h2 id="Alerting"><a href="#Alerting" class="headerlink" title="Alerting"></a>Alerting</h2><p>We want to get notified when the service is below capacity or restarted unexpectedly so the team can start to find the root cause.</p><h3 id="low-capacity-alerts"><a href="#low-capacity-alerts" class="headerlink" title="low-capacity alerts"></a>low-capacity alerts</h3><p>This alert notifies when the capacity of your application is below the threshold. The threshold is related to the service and its total pod count. For example, if an application has 10 pods and 8 of them can hold the normal traffic, 80% can be an appropriate threshold. In another case, if the total pod count is low, the alert can be how many pods should be alive.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Use Prometheus as data source</span><br><span class="line">kube_deployment_status_replicas_available&#123;namespace=&quot;$PROJECT&quot;&#125; / kube_deployment_spec_replicas&#123;namespace=&quot;$PROJECT&quot;&#125;</span><br></pre></td></tr></table></figure><p>This alert can be highly critical when your service is critical and out of capacity.</p><h3 id="Pod-container-restart-rate-too-high"><a href="#Pod-container-restart-rate-too-high" class="headerlink" title="Pod container restart rate too high"></a>Pod container restart rate too high</h3><p>This alert triggers when your pod’s container restarts frequently. It can be critical when several pods restart at the same time so that not enough pods are handling the requests. This alert can be low urgent for the applications which have a proper retry mechanism and fault tolerance. When a request is interrupted by pod restart, it will be retried later. Otherwise, this can be critical to the application.</p><p>We can use the pod container restart count in the last 1h and set the alert when it exceeds the threshold.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prometheus</span></span><br><span class="line">increase(kube_pod_container_status_restarts_total&#123;namespace=<span class="string">&quot;<span class="variable">$PROJECT</span>&quot;</span>, pod=~<span class="string">&quot;.*<span class="variable">$APP</span>.*&quot;</span>&#125;[1h])</span><br></pre></td></tr></table></figure><p>For this alert, it can be low critical and sent to the development channel for the team on-call to check.</p><h3 id="OOMEvents"><a href="#OOMEvents" class="headerlink" title="OOMEvents"></a>OOMEvents</h3><p>OOMEvents is a useful metric for complementing the pod container restart alert, it’s clear and straightforward, currently we can get the OOMEvents from <code>kube_pod_container_status_last_terminated_reason</code> exposed by cadvisor.`</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prometheus, fetch the counter of the containers OOM events.</span></span><br><span class="line">container_oom_events_total&#123;name=<span class="string">&quot;&lt;some-container&gt;&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># OR if your cadvisor is below v3.9.1</span></span><br><span class="line"><span class="comment"># prometheus, fetch the gauge of the containers terminated by OOMKilled in the specific namespace.</span></span><br><span class="line">kube_pod_container_status_last_terminated_reason&#123;reason=<span class="string">&quot;OOMKilled&quot;</span>,namespace=<span class="string">&quot;<span class="variable">$PROJECT</span>&quot;</span>&#125;</span><br></pre></td></tr></table></figure><p>For this alert, it can be low critical and sent to the development channel for the team on-call to check.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>By using these metrics you will have a better understanding of your k8s applications, a good idea will be to create a grafana template dashboard of these metrics, any team can fork this dashboard and build their own.</p><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/">Implement zero downtime HTTP service rollout on Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/how-does-prometheus-query-works/">How does Prometheus query work? - Part 1, Step, Query and Range</a></li><li><a href="https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/">How to check and monitor SSL certificates expiration with Telegraf</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;This article introduces how to set up alerts for monitoring Kubernetes Pod restarts and more importantly, when the Pods are OOMKilled we can be notified.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="prometheus" scheme="https://songrgg.github.io/tags/prometheus/"/>
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
  </entry>
  
  <entry>
    <title>Use Traffic Control to Simulate Network Chaos in Bare metal &amp; Kubernetes</title>
    <link href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/"/>
    <id>https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/</id>
    <published>2021-05-31T22:00:00.000Z</published>
    <updated>2021-07-29T11:17:19.737Z</updated>
    
    <content type="html"><![CDATA[<p>This article explains how to use traffic control to simulate network chaos in Bare metal &amp; Kubernetes, the network chaos can test the resilience of your service under a specified network condition such as packet loss, latency increase, etc.</p><span id="more"></span><h2 id="What’s-Linux-traffic-control"><a href="#What’s-Linux-traffic-control" class="headerlink" title="What’s Linux traffic control?"></a>What’s Linux traffic control?</h2><p>Linux traffic control consists of shaping, scheduling, policing, dropping the traffic, it can be used to network administration, for example, rate limit the user traffic, setup the traffic priority.</p><h2 id="How-does-traffic-control-work"><a href="#How-does-traffic-control-work" class="headerlink" title="How does traffic control work?"></a>How does traffic control work?</h2><p><a href="https://man7.org/linux/man-pages/man8/tc.8.html#:~:text=Tc%20is%20used%20to%20configure,traffic%20for%20better%20network%20behaviour.">tc</a> is the user-space utility program used to configure the Linux kernel packet scheduler, it supports rich functionality for the users to setup the traffic control.</p><p>Let’s start from a network chaos sample, suppose we have a news website which consists of a bunch of microservices and the news detail API from news service (which is used to render the news page) depends on the comment API from comment service, we want to test the application’s resilience when the comment API is down.</p><p>We want to use tc to block the <strong>egress</strong> traffic to the comment service, we’ll run it on the nodes of news service, the command will be </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tc qdisc add dev eth0 root handle 1:0 prio</span><br><span class="line">tc qdisc add dev eth0 parent 1:3 netem loss 100%</span><br><span class="line">tc filter add dev eth0 parent 1:0 protocol ip prio 3 u32 match ip dst &lt;comment-service-ip&gt; flowid 1:3</span><br></pre></td></tr></table></figure><p>To explain these commands, there are several components needed to be clarified,</p><ul><li><a href="https://man7.org/linux/man-pages/man8/tc.8.html#QDISCS">qdisc</a><br>qdisc is short for ‘queueing discipline’ and it is elementary to understanding traffic control. Whenever the kernel needs to send a packet to an interface, it isenqueuedto the qdisc configured for that interface. Immediately afterwards, the kernel tries to get as many packets as possible from the qdisc, for giving them to the network adaptor driver.</li><li><a href="https://man7.org/linux/man-pages/man8/tc.8.html#CLASSES">class</a><br>Some qdiscs can contain classes, which contain further qdiscs - traffic may then be enqueued in any of the inner qdiscs, which are within the classes.  When the kernel tries to dequeue a packet from such a classful qdisc it can come from any of the classes. A qdisc may for example prioritize certain kinds of traffic by trying to dequeue from certain classes before others.</li><li><a href="https://man7.org/linux/man-pages/man8/tc.8.html#FILTERS">filter</a><br>A filter is used by a classful qdisc to determine in which class a packet will be enqueued. Whenever traffic arrives at a class with subclasses, it needs to be classified. Various methods may be employed to do so, one of these are the filters. All filters attached to the class are called, until one of them returns with a verdict. If no verdict was made, other criteria may be available. This differs per qdisc.</li></ul><p>The above commands can be interpreted as the tree below, </p><p><img src="/images/chaostesting/traffic_control_packet_loss.svg" alt="Traffic control packet loss"></p><ul><li>ID<br>Each node in the tree has a unique ID, it consists of two parts, “{major}:{minor}”.<br>For the qdisc, its major part must be unique in the whole tree, its minor part is usually 0 and can be omitted in the tc command.<br>For the class, its ID’s major part is the same as its parent major; its minor part should not be the same as its siblings.</li><li>Root qdisc<br>The first command <code>tc qdisc add dev eth0 root handle 1:0 prio</code> set <strong>priority qdisc</strong> for the root device eth0, as the name says, the packets are sent in prioritized order.  Its ID is 1:0 which must be unique and 1:0 is reserved for the root qdisc.</li><li>3 classes<br>The 3 classes are created by the prio qdisc by default, the packets are “routed” to one of them based on the priority. Their IDs are decided by the parent ID, in this case, major part must be the same as its parent <strong>1</strong>, minor part is from 1 to 3.</li><li>Leaf qdiscs<br>The first 2 leaf qdiscs from left are fifo qdiscs which is set for prio qdisc by default. The third one is specified by the command and it overrides the default fifo qdisc, it uses netem qdisc to create 100% packet loss on class 1:3, so any packet sent to this class will be abandoned.</li><li>Filter<br>There’s only 1 filter in the tree, it routed the packets whose destination IP is comment service to the class 1:3, it will then abandon 100% of them.</li></ul><p>As a result, these 3 commands will help create 100% packet loss from news service to comment service as network chaos.</p><h2 id="How-does-tc-cooperate-with-Docker"><a href="#How-does-tc-cooperate-with-Docker" class="headerlink" title="How does tc cooperate with Docker?"></a>How does tc cooperate with Docker?</h2><p>Suppose I want to run the network chaos for a docker container like above, we have 2 ways:</p><h3 id="Run-tc-within-the-target-container"><a href="#Run-tc-within-the-target-container" class="headerlink" title="Run tc within the target container"></a>Run tc within the target container</h3><p>You can run tc within the docker container with <code>NET_ADMIN</code> capability, otherwise you’ll face <code>Operation not permitted</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm --cap-add=NET_ADMIN &lt;service-image&gt; &lt;start-command&gt;</span><br></pre></td></tr></table></figure><p>One more point is that the target container must have tc command, then you can use <code>docker exec</code> to modify the traffic control within the container.</p><p>However, containers are not always started with <code>NET_ADMIN</code>, so this method is limited in many cases.</p><h3 id="Run-tc-on-the-host-machine"><a href="#Run-tc-on-the-host-machine" class="headerlink" title="Run tc on the host machine"></a>Run tc on the host machine</h3><p>Another way to modify it is to do it on the host machine where the container runs. As we know, the container’s network is isolated from the host machine by <a href="http://songrgg.github.io/programming/linux-namespace-part01-uts-pid/">Linux namespace</a>, so we can enter the container’s network namespace and modify the traffic control. </p><p>Here’s the workflow:</p><ul><li>First, we should get the docker container’s ID.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps</span><br><span class="line">CONTAINER ID   IMAGE              COMMAND       CREATED        STATUS        PORTS     NAMES</span><br><span class="line">7d357060fe32   ubuntu:14:04       <span class="string">&quot;/bin/bash&quot;</span>   5 weeks ago    Up 5 weeks              adoring_engelbart</span><br></pre></td></tr></table></figure><ul><li>Second, extract the PID of the container.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect 7d357060fe32 | jq <span class="string">&#x27;.[].State.Pid&#x27;</span></span><br><span class="line">14902</span><br></pre></td></tr></table></figure><ul><li>Finally, modify the traffic control on the host.</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add prio qdisc to the root qdisc of the container</span></span><br><span class="line">$ sudo nsenter -t 14902 -n tc qdisc add dev eth0 root handle 1:0 prio</span><br><span class="line"><span class="comment"># qdisc exists!</span></span><br><span class="line">$ sudo nsenter -t 14902 -n tc qdisc show dev eth0</span><br><span class="line">qdisc prio 1: root refcnt 2 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1</span><br></pre></td></tr></table></figure><h2 id="How-does-tc-cooperate-with-Kubernetes"><a href="#How-does-tc-cooperate-with-Kubernetes" class="headerlink" title="How does tc cooperate with Kubernetes?"></a>How does tc cooperate with Kubernetes?</h2><p>For Kubernetes, the mechanism is the same as docker one, the difference is that target containers are distributed in the cluster now, so you need to run the query first to locate the target containers and then run the tc (as we mentioned above) on the host machines where the target containers are running.</p><p>There are open source chaos testing solutions if you’re interested, like <a href="https://docs.litmuschaos.io/docs/getstarted/">Litmus</a>, <a href="https://chaos-mesh.org/">Chaos Mesh</a>, etc.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Traffic control is a powerful tool to manipulate the packets and it’s not a frequently used tool for most of us don’t need to administrate the network :) But since chaos testing is more and more adopted by the big companies and different chaos scenarios occur, it’s a good time to understand the technical details for more confidence on the tool.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://man7.org/linux/man-pages/man8/tc.8.html">Traffic control Manual</a></li><li><a href="https://www.net.t-labs.tu-berlin.de/teaching/ss08/RL_labcourse/docs/08-lartc.pdf">Linux Advanced Routing &amp; Traffic Control HOWTO</a></li><li><a href="http://marco.uminho.pt/disciplinas/ST/st0607/traffic_control_on_linux.pdf">Linux Network Trac Control | Implementation Overview</a></li><li><a href="https://github.com/ze-phyr-us/tcviz">Traffic control Visualisation</a></li></ul><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/">Implement zero downtime HTTP service rollout on Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/practice-datacenter-failover-in-production/">Practice datacenter failover in production</a></li><li><a href="https://songrgg.github.io/operation/hackathon-spinnaker/">My first Hackathon: bring Spinnaker to my company</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article explains how to use traffic control to simulate network chaos in Bare metal &amp;amp; Kubernetes, the network chaos can test the resilience of your service under a specified network condition such as packet loss, latency increase, etc.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="chaos engineering" scheme="https://songrgg.github.io/tags/chaos-engineering/"/>
    
      <category term="traffic control" scheme="https://songrgg.github.io/tags/traffic-control/"/>
    
  </entry>
  
  <entry>
    <title>Implement zero downtime HTTP service rollout on Kubernetes</title>
    <link href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/"/>
    <id>https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/</id>
    <published>2020-09-16T22:00:00.000Z</published>
    <updated>2020-09-25T15:46:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>You might have encountered some 5xx errors during http service rollout on Kubernetes and wonder how to make it more reliable without these errors, this article will first explain where this errors come from and how to fix them and implement zero downtime.</p><span id="more"></span><h2 id="Sometimes-you-can’t-see-downtime-because-it’s-hidden"><a href="#Sometimes-you-can’t-see-downtime-because-it’s-hidden" class="headerlink" title="Sometimes you can’t see downtime because it’s hidden"></a>Sometimes you can’t see downtime because it’s hidden</h2><p>First, I would like to share an interesting case before we setup the zero downtime rollout, the client is accessing the service through envoy and fortunately we have <a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_filters/router_filter#x-envoy-retry-on">x-envoy-retry-on</a> on <code>connect-failure</code> and <code>gateway-error</code> in envoy, so the client didn’t see any 500 or 503 caused by the service rollout, envoy did all the work to “hide” these errors.</p><p>We don’t spend too much time solving the real rollout issue thanks to Envoy, but it’s not a liable solution, the errors are just hidden by some retries. When the envoy configuration is not set correctly, the client will suffer from this.</p><h2 id="When-does-it-respond-5xx"><a href="#When-does-it-respond-5xx" class="headerlink" title="When does it respond 5xx?"></a>When does it respond 5xx?</h2><p>According to the Pod lifecycle, there will be two moments when the service can return 5xx (it may be 503 or 500).</p><ul><li>The moment when the old Pod is killed.</li><li>The moment when the new Pod is provisioned.</li></ul><h3 id="500-error"><a href="#500-error" class="headerlink" title="500 error"></a>500 error</h3><p>When a new Pod is created and it receives traffic before it’s ready, it will respond 500 to the clients. In this case, we need an accurate readiness check on the Pod, only if the readiness is okay, the Pod starts taking traffic.</p><h4 id="Ensure-application-container-is-ready"><a href="#Ensure-application-container-is-ready" class="headerlink" title="Ensure application container is ready"></a>Ensure application container is ready</h4><p>The application pod has readiness check, the developer needs to implement a good readiness to ensure the application can start to serve traffic.</p><p><img src="/images/unready-pod-500.webp" alt="Unready pod returns 500"></p><p>A basic readiness can be the application HTTP server is started, you can also check the hard dependencies of the application are ready. For example, MySQL instances are connected, Redis, Cassandra, Kafka are healthy to connect.</p><figure class="highlight yaml"><figcaption><span>k8s-deployment.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">readinessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/healthcheck</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8080</span> <span class="comment"># you application port</span></span><br><span class="line">    <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">    <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure><p>It means when the application is ready, it will wait for initialDelaySeconds (5 seconds in this case) and test the healthcheck API, if it’s healthy then the Pod will be marked ready and it will receive traffic.</p><h4 id="Ensure-the-sidecars-are-ready"><a href="#Ensure-the-sidecars-are-ready" class="headerlink" title="Ensure the sidecars are ready."></a>Ensure the sidecars are ready.</h4><p>The readiness of the sidecar container is needed and should be set up the same way as the application container.<br>Some service mesh frameworks, like Istio, every Pod has an Envoy sidecar, all of the outbound requests will go through it and Envoy is ready when its route configuration is fetched from Istio controlplane, more importantly, it must be ready before the application. </p><p><strong>If your application needs to initialize resources by calling envoy, you might ensure envoy is ready before the application.</strong></p><h3 id="503-error"><a href="#503-error" class="headerlink" title="503 error"></a>503 error</h3><p>When the pod is killed it may still in the load balancer pool for a short time then it will still receive some requests, or it’s processing some in-flight requests which reached the pod before the pod is killed.</p><p><img src="/images/killed-pod-503.webp" alt="Killed pod interrupts the in-flight requests and returns 503"></p><p>To solve this, we can roughly let the pod wait until it is removed from the LB pool and it finishes all (or most) of the in-flight requests, then it’s safe to shutdown.</p><figure class="highlight yaml"><figcaption><span>k8s-deployment.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">lifecycle:</span></span><br><span class="line">    <span class="attr">preStop:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">&#x27;-c&#x27;</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">sleep</span> <span class="number">15</span><span class="string">;</span></span><br></pre></td></tr></table></figure><p>This means before the application exits, it will wait for 15 seconds, after that Kubernetes will send SIGTERM to the container. During this 15 seconds, it will have time to handle the in-flight requests instead of returning 503. 15 second is only a generic duration which we consider it’s enough for the application to finish all the requests, it could be shorter or longer according to the reality.</p><p>More advanced case is your application needs to implement some graceful shutdown, for example, recycle the resources, close the MySQL connections or other tasks, this is something implemented in the application code.</p><h2 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h2><p>Before we deploy the Kubernetes configuration to the production environment, we can test in the testing environment. Use loadtest tool to simulate a bunch of requests to the Kubernetes application, randomly kill the pod during the test. After the new pod is ready, check if the responses contain 500 or 503.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.youtube.com/watch?v=0o5C12kzEDI&ab_channel=CNCF%5BCloudNativeComputingFoundation%5D">The Gotchas of Zero-Downtime Traffic /w Kubernetes</a></li><li><a href="https://blog.gruntwork.io/delaying-shutdown-to-wait-for-pod-deletion-propagation-445f779a8304">Delaying shutdown to wait for pod deletion propagation</a></li></ol><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/hackathon-spinnaker/">My first Hackathon: bring Spinnaker to my company</a></li><li><a href="https://songrgg.github.io/architecture/deeper-understanding-to-envoy/">Anatomy of envoy proxy: the architecture of envoy and how it works</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;You might have encountered some 5xx errors during http service rollout on Kubernetes and wonder how to make it more reliable without these errors, this article will first explain where this errors come from and how to fix them and implement zero downtime.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="rollout" scheme="https://songrgg.github.io/tags/rollout/"/>
    
  </entry>
  
  <entry>
    <title>How does Prometheus query work? - Part 1, Step, Query and Range</title>
    <link href="https://songrgg.github.io/operation/how-does-prometheus-query-works/"/>
    <id>https://songrgg.github.io/operation/how-does-prometheus-query-works/</id>
    <published>2020-05-31T08:27:50.000Z</published>
    <updated>2020-09-25T13:28:43.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://prometheus.io/">Prometheus</a> is an opensource time series database, commonly used to gather and calculate monitoring metrics, this article explains how the query works with /query_range API.</p><span id="more"></span><h2 id="Start-a-Prometheus"><a href="#Start-a-Prometheus" class="headerlink" title="Start a Prometheus"></a>Start a Prometheus</h2><p>According to the Prometheus doc, a prometheus server has been started and listens at <code>localhost:9090</code>.</p><p>Prometheus browser is a WEB UI that is used to query the metrics for testing, the path is <code>http://localhost:9090/graph</code>, there are two APIs used to query the metrics, the first one is /query (which is used to see the metric value in a specified time point, the other one is <strong>/query_range</strong> used to query the metric during a period.</p><h2 id="Metric-types"><a href="#Metric-types" class="headerlink" title="Metric types"></a>Metric types</h2><p>Before we start analyzing a query, we need to know the metric types Prometheus provides:</p><h3 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h3><p>Indicates an cumulative number of the observable, for example the total http request number. This metric value is increasing monotonically increasing. For instance, <code>http_request_total</code> records the total count of HTTP requests the server serves.</p><h3 id="Gauge"><a href="#Gauge" class="headerlink" title="Gauge"></a>Gauge</h3><p>A gauge is a metric that represents a single numerical value that can arbitrarily go up and down. For instance, the instance’s CPU usage, it’s changeable all the time.</p><h3 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h3><p>A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values.<br>The <a href="https://prometheus.io/docs/practices/histograms/">Prometheus Histograms</a> gives an example, <code>http_request_duration_seconds</code>, consider we have an SLO requirement, 95% requests’ response time is within 300ms, so the straightforward way is to divide the bucket into several segments, for example, 300ms, 1s, 5s, 10s, +inf, and each bucket contains its <strong>counter</strong> metric which counts the total number of the requests within this bucket,</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http_request_duration_bucket</span><br><span class="line">[0 - 300ms]</span><br><span class="line">[0 - 1s]</span><br><span class="line">[0 - 5s]</span><br><span class="line">[0 - 10s]</span><br><span class="line">[0 - +inf]</span><br></pre></td></tr></table></figure><p>You’ll see the bucket is divided and each segment starts from 0 seconds, it means [0 - 1s] will include the [0 - 300ms]. As we said, each bucket metric is of <strong>counter</strong> type, it records the total requests number within that response time and there’s a total count metric called <code>http_request_duration_seconds_count</code>.</p><p>To calculate how much does 300ms occupy, we can calculate with <code>http_request_duration_seconds_bucket&#123;le=&quot;0.3&quot;&#125;/http_request_duration_seconds_count</code>, it calculates the instant value of the moment, but if we only use the instant value of that moment, the data will be not smooth and the graph might be spiky, so we’d better use duration to gather more data, <code>sum(rate(http_request_duration_seconds_bucket&#123;le=&quot;0.3&quot;&#125;[5m]))/sum(rate(http_request_duration_seconds_count[5m]))</code>.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Similar to a histogram, a summary samples observations (usually things like request durations and response sizes). While it also provides a total count of observations and a sum of all observed values, it calculates configurable quantiles over a sliding time window.  </p><h2 id="How-does-query-work"><a href="#How-does-query-work" class="headerlink" title="How does query work?"></a>How does query work?</h2><p>When we use Prometheus to calculate a query, normally we’re using the <strong>query_range</strong> functionality, after a time range and step is specified, the query will be applied to every step and a point will be put into the results.</p><p>Let’s see an entire query API:<br><a href="http://localhost:9090/api/v1/query_range?query=prometheus_target_interval_length_seconds&amp;start=1590830727.588&amp;end=1590834327.588&amp;step=14">http://localhost:9090/api/v1/query_range?query=prometheus_target_interval_length_seconds&amp;start=1590830727.588&amp;end=1590834327.588&amp;step=14</a></p><p>it might be a little messy, let’s break it down into parameters,</p><ul><li>query<br>query is the metric formula that needs to be calculated</li><li>Time range (start and end)<br>It is easy to understand, we can specify when should the metrics start and end, I want to see the last 30 minutes or last 7 days, it’s set by the start and end parameters, their format is unix timestamp.</li><li>step<br>It is used to decide how many data points we need by setting each data points’ interval and its format is second.</li></ul><p>The result is too much, I would only paste part of it:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;status&quot;</span>: <span class="string">&quot;success&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;data&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;resultType&quot;</span>: <span class="string">&quot;matrix&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;result&quot;</span>: [&#123;</span><br><span class="line">            <span class="attr">&quot;metric&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;__name__&quot;</span>: <span class="string">&quot;prometheus_target_interval_length_seconds&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;instance&quot;</span>: <span class="string">&quot;localhost:9090&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;interval&quot;</span>: <span class="string">&quot;15s&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;job&quot;</span>: <span class="string">&quot;prometheus&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;quantile&quot;</span>: <span class="string">&quot;0.01&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;values&quot;</span>: [</span><br><span class="line">                [<span class="number">1590830727.588</span>, <span class="string">&quot;14.996369259&quot;</span>],</span><br><span class="line">                [<span class="number">1590830741.588</span>, <span class="string">&quot;14.996369259”]</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">        &#125;]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><ul><li>status marks the calculation is successful or not</li><li>result.metric shows the original metric</li><li>result.values shows the actual data points we need, the left value is the timestamp, the right one is the metric value.<br>Each result value’s interval is exactly the step we set, in the previous example, it’s 14 seconds. It means every 14 second, the query will be calculated and one data point is generated.</li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>I explored the query_range API a bit in this article, in the next article, I’ll explore some frequent Prometheus functions like rate, irate, histogram_percentile, etc.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://prometheus.io/docs/concepts/metric_types/">Prometheus - Metric types</a></li><li><a href="https://prometheus.io/docs/prometheus/latest/getting_started/">Prometheus - Get started</a></li></ul><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/">How to check and monitor SSL certificates expiration with Telegraf</a></li><li><a href="https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/">Generate monitoring dashboards & alertings using Grafana API</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://prometheus.io/&quot;&gt;Prometheus&lt;/a&gt; is an opensource time series database, commonly used to gather and calculate monitoring metrics, this article explains how the query works with /query_range API.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="prometheus" scheme="https://songrgg.github.io/tags/prometheus/"/>
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
  </entry>
  
  <entry>
    <title>Linux namespace in Go - Part 3, Cgroups resource limit</title>
    <link href="https://songrgg.github.io/programming/linux-namespace-part03-cgroups/"/>
    <id>https://songrgg.github.io/programming/linux-namespace-part03-cgroups/</id>
    <published>2020-05-21T18:21:50.000Z</published>
    <updated>2020-09-25T15:48:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>In the <a href="/programming/linux-namespace-part02-uid-mount/">previous article</a>, I did two experiments on what isolation it brings with UID and Mount, this article explains how to limit the container’s resource by using Cgroups, for instance, CPU, memory resources.</p><span id="more"></span><p>The series of Linux namespace in Go:  </p><ul><li><a href="/programming/linux-namespace-part01-uts-pid">Linux namespace in Go - Part 1, UTS and PID</a></li><li><a href="/programming/linux-namespace-part02-uid-mount">Linux namespace in Go - Part 2, UID and Mount</a></li><li><a href="/programming/linux-namespace-part03-cgroups">Linux namespace in Go - Part 3, Cgroups resource limit</a></li></ul><h2 id="Cgroups"><a href="#Cgroups" class="headerlink" title="Cgroups"></a>Cgroups</h2><blockquote><p>Control groups, usually referred to as cgroups, are a Linux kernel feature which allow processes to be organized into hierarchical groups whose usage of various types of resources can then be limited and monitored. The kernel’s cgroup interface is provided through a pseudo-filesystem called cgroupfs.  Grouping is implemented in the core cgroup kernel code, while resource tracking and limits are implemented in a set of per-resource-type subsystems (memory, CPU, and so on).</p></blockquote><p>We can use cgroups to control the container’s resource usage, it’s necessary when we have many containers running in a host machine, it prevents some container from consuming too much resources therefore the other containers would run out of CPU, memory, etc. The interface we setup the resource limit is Linux I/O interface, you can simply write to the cgroups configuration files and it will take effect immediately.</p><h2 id="How-to-setup-cgroup-limit"><a href="#How-to-setup-cgroup-limit" class="headerlink" title="How to setup cgroup limit?"></a>How to setup cgroup limit?</h2><p>Cgroup configuration is organized by file system hierachy, for convention, the cgroup directory is mounted under <code>/sys/fs/cgroup</code>, the separate resource configuration directories are placed under some paths like <code>/sys/fs/cgroup/cpu/user/user1</code>, this is the configuration for user1’s processes.<br>Cgroup configuration is applied to the processes, if the parent process’s resource is limited, its child processes are also automatically limited according to its parent cgroup limit. The process list is stored under <code>/sys/fs/cgroup/cpu/user/user1/cgroup.procs</code>, after you add the process ID to the file, the processes it spawns will be added to the file automatically.</p><h2 id="Resource-Types"><a href="#Resource-Types" class="headerlink" title="Resource Types"></a>Resource Types</h2><p>There are different resource types that you can specify for your process, they’re called <code>controllers</code>.</p><ul><li><p>cpu<br>You’re allowed to setup both soft and hard limits to the CPU shares your processes can use, soft means if the CPU is not busy, it would specify more CPU shares to the process otherwise it would not. Hard means no matter the CPU is busy or not, the process could not use more that the specified limit.</p></li><li><p>cpuacct<br>The CPU accounting controller is used to group tasks using cgroups and<br>account the CPU usage of these groups of tasks.</p></li></ul><p>The CPU accounting controller supports multi-hierarchy groups. An accounting<br>group accumulates the CPU usage of all of its child groups and the tasks<br>directly present in its group.</p><ul><li><p>cpuset<br>This cgroup can be used to bind the processes in a cgroup to a specified set of CPUs and NUMA nodes.</p></li><li><p>memory<br>The memory controller supports reporting and limiting of process memory, kernel memory, and swap used by cgroups.</p></li><li><p>devices<br>This supports controlling which processes may create (mknod)<br>devices as well as open them for reading or writing.  The<br>policies may be specified as allow-lists and deny-lists.<br>Hierarchy is enforced, so new rules must not violate existing<br>rules for the target or ancestor cgroups.</p></li><li><p>freezer<br>The freezer cgroup can suspend and restore (resume) all processes in a cgroup.  Freezing a cgroup /A also causes its<br>children, for example, processes in /A/B, to be frozen.</p></li><li><p>net_cls<br>This places a classid, specified for the cgroup, on network<br>packets created by a cgroup.  These classids can then be used<br>in firewall rules, as well as used to shape traffic using<br>tc(8).  This applies only to packets leaving the cgroup, not<br>to traffic arriving at the cgroup.</p></li><li><p>blkio<br>The blkio cgroup controls and limits access to specified block devices by applying IO control in the form of throttling and upper limits against leaf nodes and intermediate nodes in the storage hierarchy.</p></li><li><p>perf_event<br>This controller allows perf monitoring of the set of processes grouped in a cgroup.</p></li><li><p>net_prio<br>This allows <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/net_prio.txt">priorities</a> to be specified, per network interface, for cgroups.</p></li><li><p>hugetlb<br>This supports limiting the use of huge pages by cgroups.</p></li><li><p>pids<br>This controller permits limiting the number of process that may be created in a cgroup.</p></li><li><p>rdma<br>The RDMA controller permits limiting the use of RDMA/IB-specific resources per cgroup.</p></li></ul><p>I would take CPU and memory controllers as example in the following exercises.</p><h2 id="CPU-controller"><a href="#CPU-controller" class="headerlink" title="CPU controller"></a>CPU controller</h2><p>This introduces how to setup CPU limits for the process, in this case, I wanna limit the CPU hard limit to 0.5 cores.</p><p>First, we need to create an isolated group for this CPU limit, as I said before, the configuration is usually under <code>/sys/fs/cgroup</code>, let’s create a new folder for this, we call this <code>/sys/fs/cgroup/cpu/mycontainer</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /sys/fs/cgroup/cpu/mycontainer</span><br></pre></td></tr></table></figure><p>Then, we set the CPU hard limit to 0.5 cores, there are two parameters</p><ul><li>cpu.cfs_period_us<br>the total available run-time within a period (in microseconds)</li><li>cpu.cfs_quota_us<br>the length of a period (in microseconds)</li></ul><p>The actual schedule run-time of the process will be <code>cpu.cfs_quota_us</code> microseconds of <code>cpu.cfs_period_us</code> microsends, so to use only 0.5 cores, we can specify 5000 out of 10000.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line"><span class="built_in">echo</span> 10000 &gt; /sys/fs/cgroup/cpu/mycontainer/cpu.cfs_period_us</span><br><span class="line"><span class="built_in">echo</span> 5000  &gt; /sys/fs/cgroup/cpu/mycontainer/cpu.cfs_quota_us</span><br></pre></td></tr></table></figure><p>Finally, we put the process of a Bash script to the <code>cgroup.procs</code> file,</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bash</span><br><span class="line"><span class="built_in">echo</span> $$ &gt; /sys/fs/cgroup/cpu/mycontainer/cgroup.procs</span><br></pre></td></tr></table></figure><p>You can test the CPU usage with <code>yes &gt; /dev/null</code> and use htop to monitor the current CPU usage, it will be around 0.5 core used by the <code>yes</code> command.</p><h2 id="Memory-Controller"><a href="#Memory-Controller" class="headerlink" title="Memory Controller"></a>Memory Controller</h2><p>Similar to the CPU controller, let’s have a look at the memory cgroup configurations.</p><ul><li>tasks                 # attach a task(thread) and show list of threads</li><li>cgroup.procs             # show list of processes</li><li>cgroup.event_control         # an interface for event_fd()</li><li>memory.usage_in_bytes         # show current usage for memory</li><li>memory.memsw.usage_in_bytes     # show current usage for memory+Swap</li><li>memory.limit_in_bytes         # set/show limit of memory usage</li><li>memory.memsw.limit_in_bytes     # set/show limit of memory+Swap usage</li><li>… For more details, check <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">Memory Cgroup</a></li></ul><p>To setup the memory hard limit for the process, first we create a cgroup folder for this and write to the <code>memory.limit_in_bytes</code>. After that, we added the process ID to the <code>cgroup.procs</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /sys/fs/cgroup/memory/mycontainer</span><br><span class="line">sudo su</span><br><span class="line"><span class="built_in">echo</span> 10000000 &gt; /sys/fs/cgroup/memory/mycontainer/memory.limit_in_bytes</span><br><span class="line"><span class="built_in">echo</span> &lt;process-id&gt; &gt; /sys/fs/cgroup/memory/mycontainer/cgroup.procs</span><br></pre></td></tr></table></figure><h2 id="Cgroups-in-Golang"><a href="#Cgroups-in-Golang" class="headerlink" title="Cgroups in Golang"></a>Cgroups in Golang</h2><p><a href="https://github.com/songrgg/namespace-demo/blob/master/README.md#cgroups">Cgroup in Golang</a> is equivalent to the commands I have executed before, the example code you can access in the <a href="https://github.com/songrgg/namespace-demo/blob/master/exercise05/main.go">exercise05</a>.</p><figure class="highlight go"><figcaption><span>cgroup cpu & memory setup</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">addProcessToCgroup</span><span class="params">(filepath <span class="keyword">string</span>, pid <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">file, err := os.OpenFile(filepath, os.O_WRONLY, <span class="number">0644</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(err)</span><br><span class="line">os.Exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> file.Close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> _, err := file.WriteString(fmt.Sprintf(<span class="string">&quot;%d&quot;</span>, pid)); err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;failed to setup cgroup for the container: &quot;</span>, err)</span><br><span class="line">os.Exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">cgroupSetup</span><span class="params">(pid <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, c := <span class="keyword">range</span> []<span class="keyword">string</span>&#123;<span class="string">&quot;cpu&quot;</span>, <span class="string">&quot;memory&quot;</span>&#125; &#123;</span><br><span class="line">cpath := fmt.Sprintf(<span class="string">&quot;/sys/fs/cgroup/%s/mycontainer/&quot;</span>, c)</span><br><span class="line"><span class="keyword">if</span> err := os.MkdirAll(cpath, <span class="number">0644</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;failed to create cpu cgroup for my container: &quot;</span>, err)</span><br><span class="line">os.Exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">addProcessToCgroup(cpath+<span class="string">&quot;cgroup.procs&quot;</span>, pid)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The update to cgroup directories needs root permission, we not only need to use <code>sudo</code> to run the program, but also need to modify the <code>SysProcIDMap</code>, use the command line arguments to setup the UID and GID mapping to the root user &amp; group in the container, in my case it’s the current non-root user I use, so I use <code>-uid=1000 -gid=1000</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo NEWROOT=/home/srjiang/Downloads/alpine_root go run exercise05/main.go -uid=1000 -gid=1000</span><br></pre></td></tr></table></figure><p>After you run the program, you’ll find the process of the program in the <code>/sys/fs/cgroup/cpu/mycontainer/cgroup.procs</code>, it’s up to you to modify the cgroup configuration like CPU limits and memory limits on your own.</p><h2 id="What’s-Next"><a href="#What’s-Next" class="headerlink" title="What’s Next?"></a>What’s Next?</h2><p>We’ve had a container with its own file system, isolated user namespace and PID namespace, and we can limit the resource of this container, next, we want to bring the network to this container.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">Cgroups Linux Manual</a></li><li><a href="https://drill.apache.org/docs/configuring-cgroups-to-control-cpu-usage/#set-the-cpu-limit-for-the-drillbit-service">Drill Set the CPU limit for the Service</a></li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">Memory Cgroup</a></li></ol><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/programming/linux-namespace-part02-uid-mount/">Linux namespace in Go - Part 2, UID and Mount</a></li><li><a href="https://songrgg.github.io/programming/linux-namespace-part01-uts-pid/">Linux namespace in Go - Part 1, UTS and PID</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In the &lt;a href=&quot;/programming/linux-namespace-part02-uid-mount/&quot;&gt;previous article&lt;/a&gt;, I did two experiments on what isolation it brings with UID and Mount, this article explains how to limit the container’s resource by using Cgroups, for instance, CPU, memory resources.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="linux" scheme="https://songrgg.github.io/tags/linux/"/>
    
      <category term="namespace" scheme="https://songrgg.github.io/tags/namespace/"/>
    
      <category term="cgroups" scheme="https://songrgg.github.io/tags/cgroups/"/>
    
  </entry>
  
  <entry>
    <title>Linux namespace in Go - Part 2, UID and Mount</title>
    <link href="https://songrgg.github.io/programming/linux-namespace-part02-uid-mount/"/>
    <id>https://songrgg.github.io/programming/linux-namespace-part02-uid-mount/</id>
    <published>2020-05-09T08:27:50.000Z</published>
    <updated>2020-09-25T13:05:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>In the <a href="/programming/linux-namespace-part01-uts-pid/">previous article</a>, I did two experiments on what isolation it brings with PID and UTS, this article explains UID and Mount namespace. </p><span id="more"></span><p>The series of Linux namespace in Go:  </p><ul><li><a href="/programming/linux-namespace-part01-uts-pid">Linux namespace in Go - Part 1, UTS and PID</a></li><li><a href="/programming/linux-namespace-part02-uid-mount">Linux namespace in Go - Part 2, UID and Mount</a></li><li><a href="/programming/linux-namespace-part03-cgroups">Linux namespace in Go - Part 3, Cgroups resource limit</a></li></ul><h2 id="UID-namespace"><a href="#UID-namespace" class="headerlink" title="UID namespace"></a>UID namespace</h2><p>As Linux man page described, </p><blockquote><p>User namespaces isolate security-related identifiers and attributes,<br>in particular, user IDs and group IDs (see credentials(7)), the root directory, keys (see keyrings(7)), and capabilities (see capabilities(7)).  A process’s user and group IDs can be different inside and outside a user namespace.  In particular, a process can have a normal unprivileged user ID outside a user namespace while at the same time having a user ID of 0 inside the namespace; in other words, the process has full privileges for operations inside the user namespace, but is unprivileged for operations outside the namespace.</p></blockquote><p>The key point is that the unprivileged user outside the namespace can be mapped to the root-user inside the new namespace by creating a UID namespace with UID mappings.</p><p>Let’s take an example, on my Ubuntu I want to create a user namespace and use non-root user to run the process, as tested in my previous article, I can’t run the Go program without root permission. But with user namespace, I can map non-root user, in this case, </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> id</span></span><br><span class="line">uid=1000(srjiang) gid=1000(srjiang) groups=1000(srjiang),</span><br></pre></td></tr></table></figure><p>to the root user in the container, </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;os&quot;</span></span><br><span class="line">    <span class="string">&quot;os/exec&quot;</span></span><br><span class="line">    <span class="string">&quot;syscall&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    cmd := exec.Command(<span class="string">&quot;/bin/bash&quot;</span>)</span><br><span class="line"></span><br><span class="line">    cmd.Stdin = os.Stdin</span><br><span class="line">    cmd.Stdout = os.Stdout</span><br><span class="line">    cmd.Stderr = os.Stderr</span><br><span class="line"></span><br><span class="line">    cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWUSER,</span><br><span class="line">        UidMappings: []syscall.SysProcIDMap&#123;</span><br><span class="line">            &#123;</span><br><span class="line">                ContainerID: <span class="number">0</span>,</span><br><span class="line">                HostID:      os.Getuid(),</span><br><span class="line">                Size:        <span class="number">1</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        GidMappings: []syscall.SysProcIDMap&#123;</span><br><span class="line">            &#123;</span><br><span class="line">                ContainerID: <span class="number">0</span>,</span><br><span class="line">                HostID:      os.Getgid(),</span><br><span class="line">                Size:        <span class="number">1</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;Error running the exec.Command - %s\n&quot;</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>UidMappings</strong> implements the user mapping between host and container, it will map the user id in the host to the user id in the container, the size parameter indicates it’s a contiguous range mapping. If size is 10 and containerID is 0, HostID is 1000, it means 1000-1010 will be mapped to 0-10.</p><p><strong>GidMappings</strong> is the same mechanism as UidMappings, it represents Group id.</p><p>Now, we’re root in the container but non-root in the host, how does the permission look like in the container?</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># id</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root),65534(nogroup)</span><br><span class="line">(container) <span class="comment"># touch /testmypermission</span></span><br><span class="line">touch: cannot touch <span class="string">&#x27;/testmypermission&#x27;</span>: Permission denied</span><br></pre></td></tr></table></figure><p>You can find out that although I’m the root user in the container, I still don’t have the permission to<br>create a file under root directory, because to the host, I’m actually a non-root user <em>srjiang</em>, I can only manipulate the files that <em>srjiang</em> can. If I run the golang program with sudo, I can operate on the root directory as I wish.</p><h2 id="What-about-ps-ef"><a href="#What-about-ps-ef" class="headerlink" title="What about ps -ef?"></a>What about ps -ef?</h2><p>Remember in the previous article, I left a question how to list the processes only visible within this namespace, here comes the answer: <strong>mount a new /proc</strong>.</p><p>The proc filesystem is a pseudo-filesystem which provides an interface to kernel data structures. It is commonly mounted at /proc.<br>As name explained, the process information is stored under /proc folder, most of the files in the proc filesystem are read-only, they’re dynamic and stored in memory.</p><p>By default, everybody may access all /proc/[pid] directories, besides process information you can also update the process configuration.</p><p>To isolate the container’s process list from the host, we need to mount a new /proc directory instead of sharing the host’s /proc, we can implement this by</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># mount -t proc proc /proc</span></span><br></pre></td></tr></table></figure><p>After mounting the /proc, </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># ps -ef</span></span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">root          1      0  0 09:08 pts/1    00:00:00 /bin/bash</span><br><span class="line">root         74      1  0 09:56 pts/1    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><p>You’ll only see the processes within the container.</p><h2 id="One-step-forward"><a href="#One-step-forward" class="headerlink" title="One step forward"></a>One step forward</h2><p>For now, we have our own <code>/proc</code> directory that supports standalone process information, but we still share other filesystem with the host, if we want to have a totally fresh filesystem, we need to prepare a new root filesystem and replace the default root filesystem with the new one.</p><h3 id="Download-the-alpine-root-filesystem"><a href="#Download-the-alpine-root-filesystem" class="headerlink" title="Download the alpine root filesystem"></a>Download the alpine root filesystem</h3><p>Alpine OS is popular and secure, tiny OS, I choose it as this experiment’s OS, the files (mini root filesystem) can be downloaded from <a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a>, after that we need to consider how to let the process use this root filesystem, we’ll pivot_root here to change the root filesystem.<br>pivot_root takes two main parameters, the first one is new_root which is where your new root filesystem is, in this case, ~/Downloads/alpine_root/; the second one put_old which is the location you want to put your current root filesystem.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># mount -B ~/Downloads/alpine_root/ ~/Downloads/alpine_root/</span></span><br><span class="line">(container) <span class="comment"># pivot_root ~/Downloads/alpine_root/ ~/Downloads/alpine_root/old_root</span></span><br><span class="line">(container) <span class="comment"># cd /</span></span><br><span class="line">(container) <span class="comment"># ls</span></span><br><span class="line">bin       brook     dev       etc       home      lib       media     mnt       old_root  opt       proc      root      run       sbin      srv       sys       tmp       usr       var</span><br></pre></td></tr></table></figure><p>The reader might be asking “why do we need to mount the new root filesystem again?”,  read the pivot_root man page, you will see new_root must be a path to a mount point, but can’t be “/“, so mounting itself ensures it’s a mount point.</p><p>After you run the commands in the container, you have set the alpine root filesystem now.</p><h3 id="What-about-old-root"><a href="#What-about-old-root" class="headerlink" title="What about old_root?"></a>What about old_root?</h3><p>We almost forget old_root, it’s the previous root filesystem, we don’t want to see it in the container, so let’s umount it.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># umount /old_root</span></span><br><span class="line">umount: can<span class="string">&#x27;t unmount /old_root: Resource busy</span></span><br></pre></td></tr></table></figure><p>Who’s using old_root now? I remember, the shell we use now is still under /old_root, we need to use alpine’s shell, so, the final workflow of the program is:</p><ol><li>mount alpine root filesystem</li><li>mount /proc</li><li>use pivot_root to use alpine</li><li>chdir to the root directory</li><li>umount the old root filesystem</li><li>run the alpine’s shell (or whatever you like)</li></ol><p>For the Golang implementation, it’s here: <a href="https://github.com/songrgg/namespace-demo#mount-a-new-root-filesystem">https://github.com/songrgg/namespace-demo#mount-a-new-root-filesystem</a></p><h2 id="What’s-Next"><a href="#What’s-Next" class="headerlink" title="What’s Next?"></a>What’s Next?</h2><p>Until now, we have setup an Alpine container that has separate UTS, UID, PID namespaces, we’ll create the networking namespace in the next experiment.<br>Also, in the future we can test how to limit the container resource.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://man7.org/linux/man-pages/man5/proc.5.html">Linux Manual - proc</a><br><a href="https://www.slashroot.in/proc-file-system-linux-explained">Linux /proc explained</a><br><a href="https://linux.die.net/man/8/pivot_root">Pivot_root</a><br><a href="http://man7.org/linux/man-pages/man2/pivot_root.2.html">Pivot_root2</a></p><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/programming/linux-namespace-part03-cgroups/">Linux namespace in Go - Part 3, Cgroups resource limit</a></li><li><a href="https://songrgg.github.io/programming/linux-namespace-part01-uts-pid/">Linux namespace in Go - Part 1, UTS and PID</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In the &lt;a href=&quot;/programming/linux-namespace-part01-uts-pid/&quot;&gt;previous article&lt;/a&gt;, I did two experiments on what isolation it brings with PID and UTS, this article explains UID and Mount namespace. &lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="linux" scheme="https://songrgg.github.io/tags/linux/"/>
    
      <category term="namespace" scheme="https://songrgg.github.io/tags/namespace/"/>
    
  </entry>
  
  <entry>
    <title>Linux namespace in Go - Part 1, UTS and PID</title>
    <link href="https://songrgg.github.io/programming/linux-namespace-part01-uts-pid/"/>
    <id>https://songrgg.github.io/programming/linux-namespace-part01-uts-pid/</id>
    <published>2020-05-02T14:27:50.000Z</published>
    <updated>2020-09-25T13:05:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>This article starts some <a href="https://github.com/songrgg/namespace-demo">Golang experiments</a> on Linux namespace and provides context for Container technology. Linux namespace is an important foundation of container technology, it provides lightweight isolation between processes with Linux kernel support, therefore, different services can share the same machine with better resource utilization, great security.</p><span id="more"></span><p>The series of Linux namespace in Go:  </p><ul><li><a href="/programming/linux-namespace-part01-uts-pid">Linux namespace in Go - Part 1, UTS and PID</a></li><li><a href="/programming/linux-namespace-part02-uid-mount">Linux namespace in Go - Part 2, UID and Mount</a></li><li><a href="/programming/linux-namespace-part03-cgroups">Linux namespace in Go - Part 3, Cgroups resource limit</a></li></ul><h2 id="Linux-namespace"><a href="#Linux-namespace" class="headerlink" title="Linux namespace"></a>Linux namespace</h2><p>There’s a definition from Linux manual introducing Linux namespace:</p><blockquote><p>A namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. Changes to the global resource are visible to other processes that are members of the namespace, but are invisible to other processes.</p></blockquote><p>So, Linux namespace is the key that we can control the resources the processes can access.</p><h3 id="Namespace-types"><a href="#Namespace-types" class="headerlink" title="Namespace types"></a>Namespace types</h3><p>What kind of isolation could we control is decided by the namespace types.</p><ul><li>UTS<br>Hostname and NIS domain name</li><li>Cgroup<br>Controls the system resources (like CPU, Memory…) the process can use.</li><li>IPC<br>POSIX message queues</li><li>Network<br>Network devices, stacks, ports, etc.</li><li>Mount<br>Mount points</li><li>PID<br>Process IDs</li><li>Time<br>Boot and monotonic clocks</li><li>User<br>User and group IDs</li></ul><h2 id="“Go”-through-these-types"><a href="#“Go”-through-these-types" class="headerlink" title="“Go” through these types"></a>“Go” through these types</h2><p>Note that Linux namespace is only available in Linux distributions, I use Ubuntu 20.04 and Golang 1.14.2 here to run the experiments. If you’re using other OS, you might find the Linux namespace libraries missing, go and find a Linux machine and Ubuntu is recommended.</p><p><strong>Note: The experiments code can be found in <a href="https://github.com/songrgg/namespace-demo">https://github.com/songrgg/namespace-demo</a></strong></p><h3 id="UTS-Namespace"><a href="#UTS-Namespace" class="headerlink" title="UTS Namespace"></a>UTS Namespace</h3><p>UTS will isolate the hostname for the forked process from its caller.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// folder v1</span></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">&quot;fmt&quot;</span></span><br><span class="line"><span class="string">&quot;os&quot;</span></span><br><span class="line"><span class="string">&quot;os/exec&quot;</span></span><br><span class="line"><span class="string">&quot;syscall&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">exec.Command(<span class="string">&quot;/bin/bash&quot;</span>)</span><br><span class="line">cmd := exec.Cmd&#123;</span><br><span class="line">Path:   <span class="string">&quot;/bin/bash&quot;</span>,</span><br><span class="line">Stdin:  os.Stdin,</span><br><span class="line">Stdout: os.Stdout,</span><br><span class="line">Stderr: os.Stderr,</span><br><span class="line">SysProcAttr: &amp;syscall.SysProcAttr&#123;</span><br><span class="line">Cloneflags: syscall.CLONE_NEWUTS,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This script needs <code>sudo</code> permission, run <code>sudo go run main.go</code> and it will create a new bash process with a new UTS namespace, you could modify hostname within this namespace and it won’t change the outside’s hostname.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[sojiang@ namespace-demo]$ hostname</span><br><span class="line">sojiang.local</span><br><span class="line">[sojiang@ namespace-demo]$ sudo go run exercise01/main.go</span><br><span class="line">[root@ namespace-demo]<span class="comment"># hostname</span></span><br><span class="line">sojiang.local</span><br><span class="line">[root@ namespace-demo]<span class="comment"># hostname test.local</span></span><br><span class="line">[root@ namespace-demo]<span class="comment"># hostname</span></span><br><span class="line">test.local</span><br><span class="line">[root@ namespace-demo]<span class="comment"># exit</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line">[sojiang@ namespace-demo]$ hostname</span><br><span class="line">sojiang.local</span><br></pre></td></tr></table></figure><h3 id="PID-namespace"><a href="#PID-namespace" class="headerlink" title="PID namespace"></a><a href="http://man7.org/linux/man-pages/man7/pid_namespaces.7.html">PID namespace</a></h3><p>PID namespace would create a new namespace for the process where the process ID is the same as the parent process, but note that you can only operate the processes under your namespace and can’t operate the processes in the parent namespace, in the opposite, the parent namespace has permission to operate the processes under the child namespaces.</p><p>Create a PID namespace simply by adding a <code>CLONE_NEWPID</code> flag:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SysProcAttr: &amp;syscall.SysProcAttr&#123;</span><br><span class="line">    Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID,</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>Run the process again, </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[sojiang@ namespace-demo]$ sudo go run exercise02/main.go</span><br><span class="line">[root@ namespace-demo]$ ps -ef</span><br><span class="line">sojiang  6820  4062 0 06:44 ? /bin/zsh -i</span><br><span class="line">root     7561  ... sudo go run exercise02/main.go</span><br><span class="line">[root@ namespace-demo]$ <span class="built_in">kill</span> -9 6820</span><br><span class="line">bash: <span class="built_in">kill</span>: (6820) - No such process</span><br></pre></td></tr></table></figure><p>In the <code>ps -ef</code> output, we could see <code>zsh</code> which runs in the parent namespace and <code>go run exercise02/main.go</code> is running in the process’s namespace. We call the parent namespace <code>P</code> and the child namespace <code>C</code>, if we run <code>sleep 100</code> in <code>P</code>, use <code>ps -ef</code> to get the process id and run <code>kill -9 &lt;process-id&gt;</code> in <code>C</code>, it will output “process not exist”. In the opposite, we could kill the process in <code>C</code>, that’s because the process visibility is in a single direction, only parent namespace could see all the processes in both <code>P</code> and <code>C</code>.</p><p>Like the following picture, pid 1 is in the parent namespace of pid Namespace x, so pid 1 could see all the processes, pid 3 could only see pid 3, pid 5 and pid 5.<br><img src="/images/linux_namespace_pid.webp" alt="Process hierachy"></p><h2 id="What’s-next"><a href="#What’s-next" class="headerlink" title="What’s next?"></a>What’s next?</h2><p>Here I did experiments on Linux UTS and PID namespaces, we know the isolation mechanism of them. I still have several questions,</p><ul><li>How to run the program as other user instead of root?</li><li>I can still see the process list by <code>ps -ef</code> in the child namespace, however, most of the processes are in the parent namespace, there’s no need for me to see them, how to hide them or have my own process list?</li></ul><p>The answer is in the <a href="/programming/linux-namespace-part02-uid-mount/">Linux namespace in Go - Part 2, UID and Mount</a>.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://medium.com/@teddyking/linux-namespaces-850489d3ccf">Linux Namespaces by Ed King</a></li><li><a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">Linux Programmer’s Manual Namespaces(7)</a></li><li><a href="https://golang.org/pkg/os/exec/">Golang exec package</a></li></ul><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/programming/linux-namespace-part03-cgroups/">Linux namespace in Go - Part 3, Cgroups resource limit</a></li><li><a href="https://songrgg.github.io/programming/linux-namespace-part02-uid-mount/">Linux namespace in Go - Part 2, UID and Mount</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article starts some &lt;a href=&quot;https://github.com/songrgg/namespace-demo&quot;&gt;Golang experiments&lt;/a&gt; on Linux namespace and provides context for Container technology. Linux namespace is an important foundation of container technology, it provides lightweight isolation between processes with Linux kernel support, therefore, different services can share the same machine with better resource utilization, great security.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="linux" scheme="https://songrgg.github.io/tags/linux/"/>
    
      <category term="namespace" scheme="https://songrgg.github.io/tags/namespace/"/>
    
  </entry>
  
  <entry>
    <title>Setup OAuth2 client for Django in 5 minutes</title>
    <link href="https://songrgg.github.io/programming/django-oauth-client-setup/"/>
    <id>https://songrgg.github.io/programming/django-oauth-client-setup/</id>
    <published>2020-04-12T22:00:00.000Z</published>
    <updated>2020-09-25T13:03:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>This article explains how to setup OAuth2 client for Django in 5 minutes, it’s used for Web service which requires user to login by OAuth2, especially for those who are familiar with OAuth2.0 but unfamiliar with Django.</p><p>If you have no idea about OAuth2.0 workflow, please visit <a href="https://oauth.net/2/">OAuth2 net</a></p><span id="more"></span><p>The example here introduces Web service implements the OAuth2 workflow, the user must login first then he can see the web content. The Web Framework is Python Django, the OAuth library we use is <code>Authlib==0.14.1</code>. It supports user session persistence and auto-refresh access_token.</p><h2 id="OAuth-configuration"><a href="#OAuth-configuration" class="headerlink" title="OAuth configuration"></a>OAuth configuration</h2><p>If we consider using Github as the authorization server, first you need to <a href="https://github.com/settings/applications/new">register a new OAuth application in Github</a>, then you’ll have you credentials.<br>Secondly, setup OAuth settings in <code>settings.py</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># OAuth Settings</span></span><br><span class="line">OAUTH_URL_WHITELISTS = []</span><br><span class="line"></span><br><span class="line">OAUTH_CLIENT_NAME = <span class="string">&#x27;github&#x27;</span></span><br><span class="line"></span><br><span class="line">OAUTH_CLIENT = &#123;</span><br><span class="line">    <span class="string">&#x27;client_id&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;client_secret&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;access_token_url&#x27;</span>: <span class="string">&#x27;https://github.com/login/oauth/access_token&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;authorize_url&#x27;</span>: <span class="string">&#x27;https://github.com/login/oauth/authorize&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;api_base_url&#x27;</span>: <span class="string">&#x27;https://api.github.com/&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;redirect_uri&#x27;</span>: <span class="string">&#x27;https://songrgg.com/oauth/callback&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;client_kwargs&#x27;</span>: &#123;</span><br><span class="line">        <span class="string">&#x27;scope&#x27;</span>: <span class="string">&#x27;profile email&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;token_placement&#x27;</span>: <span class="string">&#x27;header&#x27;</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&#x27;userinfo_endpoint&#x27;</span>: <span class="string">&#x27;user&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Pay attention, the redirect uri should be the one your server will use to fetch access token and setup user session, I setup <code>/oauth/callback</code> here, the logic will be introduced in middleware.</p><h2 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h2><p>For each user request, the server will check user’s session and see if user has logined, in both Django or other Web frameworks, we could setup middleware to handle user requests.</p><h3 id="Initialize-the-OAuth-client"><a href="#Initialize-the-OAuth-client" class="headerlink" title="Initialize the OAuth client"></a>Initialize the OAuth client</h3><p>Use the OAuth configuration to initialize the OAuth client.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_token</span>(<span class="params">token, refresh_token, access_token</span>):</span></span><br><span class="line">    request.session[<span class="string">&#x27;token&#x27;</span>] = token</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">sso_client = self.oauth.register(</span><br><span class="line">    settings.OAUTH_CLIENT_NAME, overwrite=<span class="literal">True</span>, **settings.OAUTH_CLIENT, update_token=update_token</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>update_token</code> parameter is used to refresh the access_token when it’s expired.</p><h3 id="Process-OAuth-callback"><a href="#Process-OAuth-callback" class="headerlink" title="Process OAuth callback"></a>Process OAuth callback</h3><p>After the user authorizes the login, our server should fetch the access_token from the authorization server and store it in user session.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> request.path.startswith(<span class="string">&#x27;/oauth/callback&#x27;</span>):</span><br><span class="line">    self.clear_session(request)</span><br><span class="line">    request.session[<span class="string">&#x27;token&#x27;</span>] = sso_client.authorize_access_token(request)</span><br><span class="line">    <span class="keyword">if</span> self.get_current_user(sso_client, request) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        redirect_uri = request.session.pop(<span class="string">&#x27;redirect_uri&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> redirect_uri <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> redirect(redirect_uri)</span><br><span class="line">        <span class="keyword">return</span> redirect(views.index)</span><br></pre></td></tr></table></figure><h3 id="Fetch-user-info"><a href="#Fetch-user-info" class="headerlink" title="Fetch user info"></a>Fetch user info</h3><p>After the <code>access_token</code> is ready, fetch the user info from the resource API, otherwise redirect user to the authorization page.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_current_user</span>(<span class="params">sso_client, request</span>):</span></span><br><span class="line">    token = request.session.get(<span class="string">&#x27;token&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> token <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="string">&#x27;access_token&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> token:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> OAuth2Token.from_dict(token).is_expired() <span class="keyword">and</span> <span class="string">&#x27;user&#x27;</span> <span class="keyword">in</span> request.session:</span><br><span class="line">        <span class="keyword">return</span> request.session[<span class="string">&#x27;user&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = sso_client.get(settings.OAUTH_CLIENT[<span class="string">&#x27;userinfo_endpoint&#x27;</span>], token=OAuth2Token(token))</span><br><span class="line">        <span class="keyword">if</span> res.ok:</span><br><span class="line">            request.session[<span class="string">&#x27;user&#x27;</span>] = res.json()</span><br><span class="line">            <span class="keyword">return</span> res.json()</span><br><span class="line">    <span class="keyword">except</span> OAuthError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="Put-the-middleware"><a href="#Put-the-middleware" class="headerlink" title="Put the middleware"></a>Put the middleware</h3><p>In <code>settings.py</code>, put the middleware class to the array.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MIDDLEWARE = [</span><br><span class="line">    <span class="string">&#x27;oauth_demo.middleware.oauth.OAuthMiddleware&#x27;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><p>We use Django session module and the default storage is <code>sqlite3</code>, you can simply change it to other backends like <code>redis</code> by modifying <code>settings.py</code>.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The full repository is located at <a href="https://github.com/songrgg/oauth-demo">https://github.com/songrgg/oauth-demo</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article explains how to setup OAuth2 client for Django in 5 minutes, it’s used for Web service which requires user to login by OAuth2, especially for those who are familiar with OAuth2.0 but unfamiliar with Django.&lt;/p&gt;
&lt;p&gt;If you have no idea about OAuth2.0 workflow, please visit &lt;a href=&quot;https://oauth.net/2/&quot;&gt;OAuth2 net&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="django" scheme="https://songrgg.github.io/tags/django/"/>
    
      <category term="oauth2" scheme="https://songrgg.github.io/tags/oauth2/"/>
    
  </entry>
  
  <entry>
    <title>InfluxDB command cheatsheet</title>
    <link href="https://songrgg.github.io/operation/influxdb-command-cheatsheet/"/>
    <id>https://songrgg.github.io/operation/influxdb-command-cheatsheet/</id>
    <published>2020-03-17T23:11:50.000Z</published>
    <updated>2020-09-25T13:05:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>This article is InfluxDB command cheatsheet about how to interact with influxDB server and query the metrics. The InfluxDB version I tested is <a href="https://docs.influxdata.com/influxdb/v1.7/">v1.7.10</a></p><span id="more"></span><h2 id="Connect-amp-Start"><a href="#Connect-amp-Start" class="headerlink" title="Connect &amp; Start"></a>Connect &amp; Start</h2><p>Connect to InfluxDB server and select the database.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ influx -host 127.0.0.1 -port 8086</span><br><span class="line">&gt; SHOW DATABASES;</span><br><span class="line">name: databases</span><br><span class="line">name</span><br><span class="line">----</span><br><span class="line">_internal</span><br><span class="line">&gt; CREATE DATABASE <span class="built_in">test</span>;</span><br><span class="line">&gt; USE <span class="built_in">test</span>;</span><br><span class="line">Using database <span class="built_in">test</span></span><br><span class="line">&gt; --- fill the database with some points</span><br><span class="line">&gt; INSERT temperature,machine=unit42,<span class="built_in">type</span>=assembly external=25,internal=37</span><br><span class="line">&gt; INSERT temperature,machine=unit43,<span class="built_in">type</span>=assembly external=25,internal=37</span><br><span class="line">&gt; INSERT temperature,machine=unit43,<span class="built_in">type</span>=not_assembly external=25,internal=37</span><br></pre></td></tr></table></figure><h2 id="Show-everything"><a href="#Show-everything" class="headerlink" title="Show everything"></a>Show everything</h2><p><strong>Show</strong> is a helpful command that will help you find all the schemas you may use.</p><h3 id="Show-common-information"><a href="#Show-common-information" class="headerlink" title="Show common information"></a>Show common information</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- list all databases</span><br><span class="line">&gt; SHOW DATABASES</span><br><span class="line">&gt; --- show all measurements</span><br><span class="line">&gt; SHOW MEASUREMENTS</span><br><span class="line">&gt; --- show measurements <span class="built_in">where</span> machine tag = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">&gt; SHOW MEASUREMENTS WHERE <span class="string">&quot;machine&quot;</span> = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">&gt; --- show measurements that start with <span class="string">&#x27;temp&#x27;</span></span><br><span class="line">&gt; SHOW MEASUREMENTS WITH MEASUREMENT =~ /temp.*/</span><br><span class="line">&gt; --- show all running queries</span><br><span class="line">&gt; SHOW QUERIES</span><br><span class="line">&gt; --- show all retention policies on a database</span><br><span class="line">&gt; SHOW RETENTION POLICIES ON <span class="string">&quot;test&quot;</span></span><br><span class="line">&gt; --- show all users <span class="keyword">in</span> InfluxDB</span><br><span class="line">&gt; SHOW USERS</span><br></pre></td></tr></table></figure><h3 id="Show-series"><a href="#Show-series" class="headerlink" title="Show series"></a>Show series</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- show all series</span><br><span class="line">&gt; show series from temperature</span><br><span class="line">key</span><br><span class="line">---</span><br><span class="line">temperature,machine=unit42,<span class="built_in">type</span>=assembly</span><br><span class="line">temperature,machine=unit43,<span class="built_in">type</span>=assembly</span><br><span class="line">temperature,machine=unit43,<span class="built_in">type</span>=not_assembly</span><br><span class="line">&gt; --- show series from machine unit42</span><br><span class="line">&gt; SHOW SERIES FROM temperature WHERE machine = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">key</span><br><span class="line">---</span><br><span class="line">temperature,machine=unit42,<span class="built_in">type</span>=assembly</span><br><span class="line">&gt; -- show estimated cardinality of the series on current database</span><br><span class="line">&gt; SHOW SERIES CARDINALITY</span><br><span class="line">-- show estimated cardinality of the series on specified database</span><br><span class="line">&gt; SHOW SERIES CARDINALITY ON mydb</span><br><span class="line">cardinality estimation</span><br><span class="line">----------------------</span><br><span class="line">3</span><br></pre></td></tr></table></figure><h3 id="Show-tag"><a href="#Show-tag" class="headerlink" title="Show tag"></a>Show tag</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- show tag keys</span><br><span class="line">&gt; SHOW TAG KEYS</span><br><span class="line">name: temperature</span><br><span class="line">tagKey</span><br><span class="line">------</span><br><span class="line">machine</span><br><span class="line"><span class="built_in">type</span></span><br><span class="line">&gt; --- show all tag keys from the temperature measurement</span><br><span class="line">&gt; SHOW TAG KEYS FROM <span class="string">&quot;temperature&quot;</span></span><br><span class="line">&gt; --- show all tag keys <span class="built_in">where</span> the machine key = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">&gt; SHOW TAG KEYS WHERE <span class="string">&quot;machine&quot;</span> = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">&gt; --- show all tag values across all measurements <span class="keyword">for</span> the machine tag</span><br><span class="line">&gt; SHOW TAG VALUES WITH KEY = <span class="string">&quot;machine&quot;</span></span><br><span class="line">name: temperature</span><br><span class="line">key     value</span><br><span class="line">---     -----</span><br><span class="line">machine unit42</span><br><span class="line">machine unit43</span><br><span class="line">&gt; --- show tag values <span class="keyword">for</span> a specific database and measurement</span><br><span class="line">&gt; SHOW TAG VALUES ON <span class="built_in">test</span> FROM temperature WITH KEY = <span class="string">&quot;machine&quot;</span></span><br></pre></td></tr></table></figure><h3 id="Show-field"><a href="#Show-field" class="headerlink" title="Show field"></a>Show field</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; SHOW FIELD KEYS ON <span class="built_in">test</span></span><br><span class="line">name: temperature</span><br><span class="line">fieldKey fieldType</span><br><span class="line">-------- ---------</span><br><span class="line">external <span class="built_in">float</span></span><br><span class="line">internal <span class="built_in">float</span></span><br></pre></td></tr></table></figure><h3 id="Show-cardinality"><a href="#Show-cardinality" class="headerlink" title="Show cardinality"></a>Show cardinality</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; SHOW MEASUREMENT CARDINALITY</span><br><span class="line">cardinality estimation</span><br><span class="line">----------------------</span><br><span class="line">1</span><br><span class="line">&gt; SHOW MEASUREMENT EXACT CARDINALITY ON <span class="built_in">test</span></span><br><span class="line">count</span><br><span class="line">-----</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h2 id="Measurement"><a href="#Measurement" class="headerlink" title="Measurement"></a>Measurement</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- create a temperature point</span><br><span class="line">&gt; INSERT temperature,machine=unit42,<span class="built_in">type</span>=assembly external=26,internal=38</span><br><span class="line">&gt; --- select temperature <span class="keyword">for</span> unit42</span><br><span class="line">&gt; SELECT * FROM temperature WHERE <span class="string">&quot;machine&quot;</span> = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">&gt; --- select specific fields and tags from measurement, NOTE: at least one field must be included</span><br><span class="line">&gt; SELECT <span class="string">&quot;internal&quot;</span>::field, <span class="string">&quot;machine&quot;</span>::tag FROM temperature WHERE <span class="string">&quot;machine&quot;</span> = <span class="string">&#x27;unit42&#x27;</span></span><br><span class="line">&gt; --- delete metrics from temperature measurement</span><br><span class="line">&gt; DELETE FROM <span class="string">&quot;temperature&quot;</span> WHERE time &lt; <span class="string">&#x27;2000-01-01T00:00:00Z&#x27;</span></span><br><span class="line">&gt; --- drop the temperature measurement</span><br><span class="line">&gt; DROP MEASUREMENT <span class="string">&quot;temperature&quot;</span></span><br></pre></td></tr></table></figure><h2 id="Query-analysis"><a href="#Query-analysis" class="headerlink" title="Query analysis"></a>Query analysis</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- explain the logic behind the query</span><br><span class="line">&gt; EXPLAIN SELECT * FROM temperature</span><br><span class="line">QUERY PLAN</span><br><span class="line">----------</span><br><span class="line">EXPRESSION: &lt;nil&gt;</span><br><span class="line">AUXILIARY FIELDS: external::<span class="built_in">float</span>, internal::<span class="built_in">float</span>, machine::tag, <span class="built_in">type</span>::tag</span><br><span class="line">NUMBER OF SHARDS: 1</span><br><span class="line">NUMBER OF SERIES: 3</span><br><span class="line">CACHED VALUES: 0</span><br><span class="line">NUMBER OF FILES: 6</span><br><span class="line">NUMBER OF BLOCKS: 6</span><br><span class="line">SIZE OF BLOCKS: 204</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.influxdata.com/influxdb/v1.7/query_language/spec/#query-engine-internals">InfluxDB 1.7 Query language</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article is InfluxDB command cheatsheet about how to interact with influxDB server and query the metrics. The InfluxDB version I tested is &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.7/&quot;&gt;v1.7.10&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="influxdb" scheme="https://songrgg.github.io/tags/influxdb/"/>
    
  </entry>
  
  <entry>
    <title>how to build the smallest docker image as fast as you can</title>
    <link href="https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/"/>
    <id>https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/</id>
    <published>2020-03-15T19:11:50.000Z</published>
    <updated>2020-09-25T13:04:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>I’ll use an example to introduce how to build the smallest docker image to your best, a light image will accelerate image rollout and the fast build process will speed up your development cycle.</p><span id="more"></span><h2 id="A-Golang-sample"><a href="#A-Golang-sample" class="headerlink" title="A Golang sample"></a>A Golang sample</h2><p>It’s quite common that we use golang to implement microservice, for example tens of golang service docker images are deployed to the Kubernetes.</p><p>Consider we need to make our first golang service image, it runs the following code as an HTTP server.</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">&quot;net/http&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  http.HandleFunc(<span class="string">&quot;/&quot;</span>, test)</span><br><span class="line">  http.ListenAndServe(<span class="string">&quot;:8080&quot;</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">  w.Header().Set(<span class="string">&quot;Service&quot;</span>, <span class="string">&quot;Test&quot;</span>)</span><br><span class="line">  w.WriteHeader(<span class="number">200</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Docker-it"><a href="#Docker-it" class="headerlink" title="Docker it!"></a>Docker it!</h3><p>The intuitive solution is to run <code>go run main.go</code> in the docker, so let’s use golang image as a base image.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span>.<span class="number">0</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/songrgg/testservice/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [ <span class="string">&quot;go&quot;</span>, <span class="string">&quot;run&quot;</span>, <span class="string">&quot;main.go&quot;</span> ]</span></span><br></pre></td></tr></table></figure><p>Run <code>docker build .</code> and it shows</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/4 : FROM golang:1.14.0-alpine</span><br><span class="line"> ---&gt; 51e47ee4db58</span><br><span class="line">Step 2/4 : WORKDIR /go/src/github.com/songrgg/testservice/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8dc325ca7ca6</span><br><span class="line">Step 3/4 : COPY main.go .</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; c46c5f5bfda8</span><br><span class="line">Step 4/4 : CMD [ <span class="string">&quot;go&quot;</span>, <span class="string">&quot;run&quot;</span>, <span class="string">&quot;main.go&quot;</span> ]</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; acc5a6d462f5</span><br><span class="line">Successfully built acc5a6d462f5</span><br><span class="line"></span><br><span class="line">$ docker image inspect acc5a6d462f5 --format=<span class="string">&#x27;&#123;&#123;.Size&#125;&#125;&#x27;</span></span><br><span class="line">369193951</span><br></pre></td></tr></table></figure><p>It’s 369193951 bytes near <strong>370MB</strong>.</p><h3 id="Reduce-the-unnecessary-files"><a href="#Reduce-the-unnecessary-files" class="headerlink" title="Reduce the unnecessary files"></a>Reduce the unnecessary files</h3><p>Golang is a compilation language which can be packed into a binary, we can reduce the size by only putting the binary into the image.</p><p>We know that the latest docker supports multi-stage builds which can eliminate the intermediate layers effectively, the revised dockerfile looks like this:</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span>.<span class="number">0</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/songrgg/testservice/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:latest</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache add ca-certificates</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/github.com/songrgg/testservice/app .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;./app&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>Let’s see the layers it generates.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ docker build .</span><br><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/9 : FROM golang:1.14.0-alpine</span><br><span class="line"> ---&gt; 51e47ee4db58</span><br><span class="line">Step 2/9 : WORKDIR /go/src/github.com/songrgg/testservice/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8dc325ca7ca6</span><br><span class="line">Step 3/9 : COPY main.go .</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; c46c5f5bfda8</span><br><span class="line">Step 4/9 : RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> be3bdce1ec48</span><br><span class="line">Removing intermediate container be3bdce1ec48</span><br><span class="line"> ---&gt; 9c3470f9e73d</span><br><span class="line">Step 5/9 : FROM alpine:latest</span><br><span class="line"> ---&gt; 053cde6e8953</span><br><span class="line">Step 6/9 : RUN apk --no-cache add ca-certificates</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 6acd18e2d2ba</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/1) Installing ca-certificates (20161130-r3)</span><br><span class="line">Executing busybox-1.26.2-r7.trigger</span><br><span class="line">Executing ca-certificates-20161130-r3.trigger</span><br><span class="line">OK: 5 MiB <span class="keyword">in</span> 12 packages</span><br><span class="line">Removing intermediate container 6acd18e2d2ba</span><br><span class="line"> ---&gt; 7b4ee3222013</span><br><span class="line">Step 7/9 : WORKDIR /root/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 336a8a2115a6</span><br><span class="line">Removing intermediate container 336a8a2115a6</span><br><span class="line"> ---&gt; 77fa1196ab2f</span><br><span class="line">Step 8/9 : COPY --from=0 /go/src/github.com/songrgg/testservice/app .</span><br><span class="line"> ---&gt; c6bc47f614af</span><br><span class="line">Step 9/9 : CMD [<span class="string">&quot;./app&quot;</span>]</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> f77053027c4b</span><br><span class="line">Removing intermediate container f77053027c4b</span><br><span class="line"> ---&gt; d327f978f1d8</span><br><span class="line">Successfully built d327f978f1d8</span><br><span class="line"></span><br><span class="line">$ docker inspect d327f978f1d8 --format=<span class="string">&#x27;&#123;&#123;.Size&#125;&#125;&#x27;</span></span><br><span class="line">11924648</span><br></pre></td></tr></table></figure><p>We could notice there are several intermediate containers removed, they’re layers from the first stage and prepare the executable for the second stage.</p><p>Most importantly, the docker image size is below <strong>12MB</strong>.</p><p>The most important factor is we changed the FROM image to alpine which is only <strong>4.2MB</strong>, so the extra size is almost the size of the golang process.</p><h3 id="From-scratch"><a href="#From-scratch" class="headerlink" title="From scratch?"></a>From scratch?</h3><p>Yeah, the base image could be smaller, <code>FROM scratch</code> is a base image that will make the next command to be the first layer in your image.</p><p>I changed the <code>FROM alpine:latest</code> to <code>FROM scratch</code>, the image size is <strong>7MB</strong> now, but I would suggest using alpine because it’ll be hard for you in scratch if you want to debug within the container. So you’ll need a balance between the image size and functionality :)</p><h2 id="Some-pitfalls-you-may-face"><a href="#Some-pitfalls-you-may-face" class="headerlink" title="Some pitfalls you may face"></a>Some pitfalls you may face</h2><h3 id="Unnecessary-large-build-context"><a href="#Unnecessary-large-build-context" class="headerlink" title="Unnecessary large build context"></a>Unnecessary large build context</h3><p>Docker build will send the build context to docker daemon at first, the context is default to the current directory, so please be sure the files in the current directory is necessary or is small enough. If the file size is big, it will affect docker build speed terribly.</p><h3 id="Wrong-command-order"><a href="#Wrong-command-order" class="headerlink" title="Wrong command order"></a>Wrong command order</h3><p>Just remember to put the stable layers before the changeable layers, because docker will cache the layers if they are not changed, it’s calculated by the hash value of their content.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> changeable.txt .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ...</span></span><br></pre></td></tr></table></figure><p>In the above example, every time the changeable.txt is changed, it will rerun every commands after it and waste time doing the things it could prevent. Just turn to the following form.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ...</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> changeable.txt .</span></span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Best practises for writing Dockerfile</a></li></ol><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/install-spinnaker-on-centos/">How to install Spinnaker on CentOS 7</a></li><li><a href="https://songrgg.github.io/life/raspberry3-docker/">Raspberry 3安装docker</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ll use an example to introduce how to build the smallest docker image to your best, a light image will accelerate image rollout and the fast build process will speed up your development cycle.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="docker" scheme="https://songrgg.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>How to check and monitor SSL certificates expiration with Telegraf</title>
    <link href="https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/"/>
    <id>https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/</id>
    <published>2020-02-11T21:11:50.000Z</published>
    <updated>2020-09-25T13:04:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>As a developer or operator of a Website, the certificate expiration could happen and make the services not work. I’ll introduce how to monitor certificates like SSL,JKS,P12 using Telegraf.</p><p>Certificates are broadly used for security reasons, they can be used within internal service or public service communication. The most common certificate is TLS used for verifying the identity of the HTTPS service. To increase security, the certificate will not be always valid because of expiration. To prevent the certificate expiry, we should rotate them periodically and meanwhile monitor them and alert if expired. Telegraf is a popular metric collecting tool to implement this.</p><span id="more"></span><h2 id="Overview-for-certificate-types"><a href="#Overview-for-certificate-types" class="headerlink" title="Overview for certificate types"></a>Overview for certificate types</h2><ol><li>.csr<br>Certificate Signing Request used to request a certificate from the certificate authority.</li><li>.pem<br>This is a container format that may include just the public certificate or may include an entire certificate chain including public key, private key, and root certificates. Confusingly, it may also encode a CSR (e.g. as used here) as the PKCS10 format can be translated into PEM.</li><li>.key<br>This is a PEM formatted file containing just the private-key of a specific certificate and is merely a conventional name and not a standardized one.</li><li>.pkcs12 .pfx .p12<br>This is a passworded container format that contains both public and private certificate pairs. Unlike .pem files, this container is fully encrypted. Openssl can turn this into a .pem file with both public and private keys.</li><li>.cert .cer .crt<br>A .pem (or rarely .der) formatted file with a different extension, one that is recognized by Windows Explorer as a certificate, which .pem is not.</li><li>.jks<br>A Java KeyStore (JKS) is a repository of security certificates – either authorization certificates or public key certificates – plus corresponding private keys, used for instance in SSL encryption.</li></ol><h2 id="Check-certificate-expiry-time"><a href="#Check-certificate-expiry-time" class="headerlink" title="Check certificate expiry time"></a>Check certificate expiry time</h2><ol><li><p>check the JKS expiry time</p> <figure class="highlight bash"><figcaption><span>check_jks.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to check keystore.jks expiry time</span></span><br><span class="line">keytool -list -v -keystore keystore.jks -storepass <span class="string">&quot;pass&quot;</span> | grep until</span><br></pre></td></tr></table></figure></li><li><p>check the PKCS#12 expiry time</p> <figure class="highlight bash"><figcaption><span>check_p12.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to check certicate.p12 expiry time</span></span><br><span class="line">openssl pkcs12 -<span class="keyword">in</span> certicate.p12 -nokeys | openssl x509 -noout -enddate</span><br></pre></td></tr></table></figure></li></ol><h2 id="Customize-telegraf-plugin"><a href="#Customize-telegraf-plugin" class="headerlink" title="Customize telegraf plugin"></a>Customize telegraf plugin</h2><p>In this case, we can use a bash script to collect the metrics and output it as <a href="https://docs.influxdata.com/influxdb/v1.7/write_protocols/line_protocol_tutorial/">influxDB line protocol</a>, it does not need you to use influxDB, you can use any kind of monitoring backend that can read from telegraf, for example, Prometheus.</p><p><a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a> is a daemon that can be running on servers to collect system metrics, it supports multiple input plugins to collect metrics. <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec"><code>intput.exec</code></a> is an input plugin which will run the specified script, the output of the script will be treated as a data point.</p><h3 id="Bash-script-to-generate-the-metric"><a href="#Bash-script-to-generate-the-metric" class="headerlink" title="Bash script to generate the metric"></a>Bash script to generate the metric</h3><p>We can write a bash script to generate an influxDB line formatted metric, the script will use <code>openssl</code> to resolve the certificate.</p><ol><li><p>This is a script used to resolve PKCS#12 files.</p> <figure class="highlight bash"><figcaption><span>generate_p12_metric.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">FILE_PATH=<span class="string">&quot;path-to-pkcs#12-cert&quot;</span></span><br><span class="line">P12_UNTIL=$(openssl pkcs12 -<span class="keyword">in</span> <span class="variable">$FILE_PATH</span> -nokeys 2&gt;/dev/null | openssl x509 -text -noout 2&gt;/dev/null | grep After | sed <span class="string">&#x27;s/.*After : //&#x27;</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># return 1 year when there&#x27;s no existing file</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$P12_UNTIL</span>&quot;</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="subst">$((360*24*60*60)</span>)&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">P12_UNTIL_EPOCH=$(date +%s --date=<span class="string">&quot;<span class="variable">$P12_UNTIL</span>&quot;</span>)</span><br><span class="line">NOW_EPOCH=$(date +%s)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;pkcs12_cert,source=<span class="variable">$FILE_PATH</span> expiry=<span class="subst">$(($P12_UNTIL_EPOCH-$NOW_EPOCH)</span>) <span class="variable">$&#123;NOW_EPOCH&#125;</span>000000000&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>Another script to resolve the JKS file</p> <figure class="highlight bash"><figcaption><span>generate_jks_metric.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">FILE_PATH=<span class="string">&quot;path-to-jks-cert&quot;</span></span><br><span class="line">KEYSTORE_UNTIL=$(<span class="built_in">echo</span> <span class="string">&#x27;dummydummy&#x27;</span> | keytool -list -v -keystore <span class="variable">$FILE_PATH</span> 2&gt;/dev/null | grep -i Until  | sed <span class="string">&#x27;s/.*until: //&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This may be caused by unexistent file, return 1 year to skip checking.</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$KEYSTORE_UNTIL</span>&quot;</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="subst">$((360*24*60*60)</span>)&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">KEYSTORE_UNTIL_EPOCH=$(date +%s --date=<span class="string">&quot;<span class="variable">$KEYSTORE_UNTIL</span>&quot;</span>)</span><br><span class="line">NOW_EPOCH=$(date +%s)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;jks_cert,source=<span class="variable">$FILE_PATH</span> expiry=<span class="subst">$(($KEYSTORE_UNTIL_EPOCH-$NOW_EPOCH)</span>) <span class="variable">$&#123;NOW_EPOCH&#125;</span>000000000&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>X509 Cert<br>There’s an <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/x509_cert">X509 Cert Input Plugin</a> already there.</p></li></ol><h3 id="Telegraf-configuration"><a href="#Telegraf-configuration" class="headerlink" title="Telegraf configuration"></a>Telegraf configuration</h3><p>Put the <code>jks_cert.conf</code> under the telegraf’s configuration folder, restart telegraf and it will take effect.</p><figure class="highlight toml"><figcaption><span>jks_cert.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[[inputs.exec]]</span></span><br><span class="line">  <span class="attr">commands</span> = [ <span class="string">&quot;/usr/local/bin/jks_certificate_metric.sh&quot;</span> ]</span><br><span class="line"></span><br><span class="line">  <span class="attr">data_format</span> = <span class="string">&quot;influx&quot;</span></span><br></pre></td></tr></table></figure><h3 id="What’s-next"><a href="#What’s-next" class="headerlink" title="What’s next"></a>What’s next</h3><p>Connect the data Telegraf collected to Time series database like Prometheus, InfluxDB, Graphite, and show them with Grafana.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file">What is a pem file and how does it differ from other OpenSSL generated key files?</a></li><li><a href="https://pingtool.org/openssl-check-p12-expiration-date/">OpenSSL check p12 expiration date</a></li><li><a href="https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file">What is a PEM file and how does it differ from other OpenSSL generated key file</a></li><li><a href="https://en.wikipedia.org/wiki/PKCS_12">pkcs#12</a></li><li><a href="https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs">OpenSSL essentials</a></li><li><a href="https://www.digitalocean.com/community/tutorials/java-keytool-essentials-working-with-java-keystores">Java keytool essentials</a></li><li><a href="https://en.wikipedia.org/wiki/Java_KeyStore">Java KeyStore</a></li></ol><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/how-does-prometheus-query-works/">How does Prometheus query work? - Part 1, Step, Query and Range</a></li><li><a href="https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/">Generate monitoring dashboards & alertings using Grafana API</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;As a developer or operator of a Website, the certificate expiration could happen and make the services not work. I’ll introduce how to monitor certificates like SSL,JKS,P12 using Telegraf.&lt;/p&gt;
&lt;p&gt;Certificates are broadly used for security reasons, they can be used within internal service or public service communication. The most common certificate is TLS used for verifying the identity of the HTTPS service. To increase security, the certificate will not be always valid because of expiration. To prevent the certificate expiry, we should rotate them periodically and meanwhile monitor them and alert if expired. Telegraf is a popular metric collecting tool to implement this.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
      <category term="certificate" scheme="https://songrgg.github.io/tags/certificate/"/>
    
  </entry>
  
  <entry>
    <title>Practice datacenter failover in production</title>
    <link href="https://songrgg.github.io/operation/practice-datacenter-failover-in-production/"/>
    <id>https://songrgg.github.io/operation/practice-datacenter-failover-in-production/</id>
    <published>2019-12-12T23:00:00.000Z</published>
    <updated>2020-09-25T13:02:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>Distributed system is like human body, it will have issues and break. There’s a theory that we feed it with issues deliberately and constantly, the body will be more and more stable and robust. It’s the same to system, put some issues to datacenters and let them failover automatically.</p><span id="more"></span><h3 id="Multiple-data-centers"><a href="#Multiple-data-centers" class="headerlink" title="Multiple data centers"></a>Multiple data centers</h3><p>Companies use data center redundancy to implement service’s high availability, there will be multiple data centers existing with 3 main deployments:</p><ol><li>Disaster Recovery<br>You will have your live traffic served in the primary data center, meanwhile disaster recovery data center is a backup to recover when the primary is down. Usually, it doesn’t allow you to run normal operations in the disaster recovery one.</li><li>Hot Standby<br>The primary data center is taking traffic, the hot standby data center is almost equivalent to primary but doesn’t take traffic. You can switch to hot standby anytime the primary data center is down.</li><li>Live traffic handling<br>There are multiple data centers and they’re taking traffic simultaneously.</li></ol><h3 id="What-is-DC-failover"><a href="#What-is-DC-failover" class="headerlink" title="What is DC failover?"></a>What is DC failover?</h3><p>When dc ( data center ) failure happens, the most emergent thing is to use the backup dc to replace the primary one and ensures the business keeps running, so the technical team will failover the data center to backup one.</p><!-- more --><h3 id="Why-do-we-need-to-do-failover-often"><a href="#Why-do-we-need-to-do-failover-often" class="headerlink" title="Why do we need to do failover often?"></a>Why do we need to do failover often?</h3><p>In the deployments mentioned before, there will be one or more data centers serving user, once the primary one is down the backup one needs to take over as soon as possible, but it’s not often that the primary data center is down, as the time flies, likely, backup datacenter cannot replace the primary or is hard to replace.<br>To keep the backup dc up-to-date, we should do dc failover often regardless manually or automatically.</p><h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><h3 id="Define-the-impact"><a href="#Define-the-impact" class="headerlink" title="Define the impact"></a>Define the impact</h3><p>Service is always for customers, although failover is a long-term project that will improve the service’s availability, it’s better not to interrupt the customer’s experience all of a sudden, so according to different company’s considerations, they need to define the impact they can undertake.</p><h3 id="Define-the-scope"><a href="#Define-the-scope" class="headerlink" title="Define the scope"></a>Define the scope</h3><p>After the company decides to practice data center failover in production, there will be a lot of questions to answer, “What’s the scale of this failover?”, “Is it global or partial?”, “What consequences can I bear or how much budget do we have?”, “who should participate in”…<br>Such questions can define the scope of the failover, how many business lines should participate in it, how many teams, how many people will join.</p><h3 id="Define-the-goal"><a href="#Define-the-goal" class="headerlink" title="Define the goal"></a>Define the goal</h3><p>Also, define the goal clearly, it’s a long term project that ensures there will be always multiple available data centers online, this failover is the first time and will repeat very soon, finally, it’ll be continuous and automatic like chaos engineering.</p><h3 id="Team-as-unit"><a href="#Team-as-unit" class="headerlink" title="Team as unit"></a>Team as unit</h3><p>Every team involved should take care of the servers, services… they need to failover when the failover day comes, the team is the minimal unit.</p><h3 id="Deadline"><a href="#Deadline" class="headerlink" title="Deadline"></a>Deadline</h3><p>“Deadline is the first productivity”, since the failover may not seem to be important to everyone, teams may not put them to the priority, so the deadline is a clear signal it will happen sooner or later.</p><h3 id="From-an-SRE’s-perspective"><a href="#From-an-SRE’s-perspective" class="headerlink" title="From an SRE’s perspective"></a>From an SRE’s perspective</h3><p>As an SRE, I play a vital role in this failover and will execute the operations.</p><ul><li>You should have a full list of your services.</li><li>Get your operation documentation ready, for example, the operation commands and monitoring dashboard addresses.</li><li>Mini failovers can be done gradually before the entire one.</li></ul><h2 id="When-the-day-comes"><a href="#When-the-day-comes" class="headerlink" title="When the day comes"></a>When the day comes</h2><h3 id="A-clear-agenda"><a href="#A-clear-agenda" class="headerlink" title="A clear agenda"></a>A clear agenda</h3><p>A clear agenda is a precondition that everything is under control even if something unexpected happens. Take the unexpected into consideration and make the agenda more flexible.</p><h3 id="Instant-communication"><a href="#Instant-communication" class="headerlink" title="Instant communication"></a>Instant communication</h3><p>For the team, the progress must be understood by every team member and their clients.<br>Also, it’s necessary to put everything unexpected into a global channel and everyone is aware of it.</p><h3 id="Roles-we-play"><a href="#Roles-we-play" class="headerlink" title="Roles we play"></a>Roles we play</h3><p>The coordinator is the one who’s responsible for connecting all the team players, (s)he’s responsible for recording the matters happening including success and failure, other team players should report what they’ve done and seen to the coordinator.</p><h2 id="After-the-failover"><a href="#After-the-failover" class="headerlink" title="After the failover"></a>After the failover</h2><p>After the failover, teams involved in this failover should look back and check what’s the good part and what needs to be improved.<br>Against the weakness, we can make some plans and put them into the backlog, we’ll be more confident facing the next failover.<br>I will spend more time on chaos engineering which is the continuous accidents injection to production and will bring production more resilience.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://blog.serverdensity.com/multi-data-center-redundancy-application-considerations/">Multiple data center redundancy</a></li><li><a href="https://principlesofchaos.org/?lang=ENcontent">Principles of Chaos Engineering</a> </li></ol><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/programming/rate-limiter-for-distributed-system/">分布式系统频次限制实现</a></li><li><a href="https://songrgg.github.io/programming/mit-distributed-system-01/">Mit分布式系统课程-Lab2-PartB</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Distributed system is like human body, it will have issues and break. There’s a theory that we feed it with issues deliberately and constantly, the body will be more and more stable and robust. It’s the same to system, put some issues to datacenters and let them failover automatically.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="distributed system" scheme="https://songrgg.github.io/tags/distributed-system/"/>
    
      <category term="data center failover" scheme="https://songrgg.github.io/tags/data-center-failover/"/>
    
      <category term="resilience" scheme="https://songrgg.github.io/tags/resilience/"/>
    
      <category term="chaos engineering" scheme="https://songrgg.github.io/tags/chaos-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Generate monitoring dashboards &amp; alertings using Grafana API</title>
    <link href="https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/"/>
    <id>https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/</id>
    <published>2019-09-22T22:00:00.000Z</published>
    <updated>2020-09-25T13:02:36.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://grafana.com/">Grafana</a> has been adopted as a common monitoring dashboard by more and more companies, in many cases, when operators need to create dashboard repeatedly they either choose to use template variables or create dashboards one by one. I think it’s very useful to leverage the <a href="https://grafana.com/docs/http_api/">Grafana API</a> to generate the monitoring dashboards automatically from template.</p><span id="more"></span><h2 id="My-thought-on-dashboard-automation"><a href="#My-thought-on-dashboard-automation" class="headerlink" title="My thought on dashboard automation"></a>My thought on dashboard automation</h2><p>There’s a common use case, if you need to create a lot of similar dashboard (like system stats) for different services, the dashboard skeleton may always be the same, you can use template variables to make the difference. However, you can not create alertings on the graphs which use template variables, so in these situations you have to create graphs without variables.</p><p>So we can create a template dashboard first with variables in Grafana, then use scripts to read from the template and render them with variables we specify, finally call Grafana APIs to create/update dashboards.</p><ol><li><p>Listen to what dashboards we need to create/update, collect metadata first.<br>For example, if it’s for server stats, we need to get the server info from cloud provider or other infrastructure.</p></li><li><p>Trigger the change to the dashboard</p><ul><li>Create the template of dashboard with template variables, it’s okay, we’ll replace the template later.</li><li>Render the template with the metadata we collected.</li><li>Add the graphs using CRUD APIs.</li></ul></li></ol><h2 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h2><p>Metadata is what you need to generate dashboards, basically it contains:</p><ol><li>How many dashboards you want to create?</li><li>What are each dashboard’s variables?<br>If you use public cloud providers, cloud APIs can be used otherwise you have your own infrastructure management APIs.</li></ol><h2 id="Template-dashboard"><a href="#Template-dashboard" class="headerlink" title="Template dashboard"></a>Template dashboard</h2><p><a href="https://grafana.com/docs/reference/templating/">Grafana Variables</a> is a good functionality for monitor a great number of servers or application, defining the template dashboard with variables is good for rendering because you can not only view the effect on the template but also the variable is easy to replace for the format is <code>$VARIABLE</code> or <code>[[VARIABLE]]</code>, string replacement is enough for this.<br><img src="/images/grafana_variables_dashboard.webp" alt="Grafana Variables"></p><h3 id="Grafana-dashboard-CRUD-API"><a href="#Grafana-dashboard-CRUD-API" class="headerlink" title="Grafana dashboard CRUD API"></a>Grafana dashboard CRUD API</h3><p>Grafana provides enough HTTP APIs to do this, once you create the template dashboard it already has the graphs and alertings, so <a href="https://grafana.com/docs/http_api/dashboard/">Grafana dashboard API</a> is enough for most cases.</p><p>For authentication, you can create a service account for automating the dashboards and use API token to call APIs.</p><p>The automation scripts can maintain a relationship between the dashboard UID and dashboard name and you can also do the change comparison before updating the dashboards.<br>Delete the dashboards when some of them are deprecated.</p><h3 id="Run-your-automation"><a href="#Run-your-automation" class="headerlink" title="Run your automation"></a>Run your automation</h3><p>It’s okay to run automation scripts as cronjobs.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li><a href="https://grafana.com/docs/http_api/dashboard/">Grafana dashboard API</a></li><li><a href="https://grafana.com/docs/http_api/alerting/">Grafana alerting API</a> is only used to get alerts, if you need to modify the alerts using dashboard API</li><li><a href="https://grafana.com/docs/tutorials/api_org_token_howto/">Grafana API token</a></li><li><a href="https://github.com/grafana-tools/sdk">Grafana SDK</a></li><li><a href="https://grafana.com/docs/reference/dashboard/">Grafana dashboard reference</a></li></ul><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/how-does-prometheus-query-works/">How does Prometheus query work? - Part 1, Step, Query and Range</a></li><li><a href="https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/">How to check and monitor SSL certificates expiration with Telegraf</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://grafana.com/&quot;&gt;Grafana&lt;/a&gt; has been adopted as a common monitoring dashboard by more and more companies, in many cases, when operators need to create dashboard repeatedly they either choose to use template variables or create dashboards one by one. I think it’s very useful to leverage the &lt;a href=&quot;https://grafana.com/docs/http_api/&quot;&gt;Grafana API&lt;/a&gt; to generate the monitoring dashboards automatically from template.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
      <category term="grafana" scheme="https://songrgg.github.io/tags/grafana/"/>
    
      <category term="automation" scheme="https://songrgg.github.io/tags/automation/"/>
    
      <category term="alerting" scheme="https://songrgg.github.io/tags/alerting/"/>
    
  </entry>
  
  <entry>
    <title>How to install Spinnaker on CentOS 7</title>
    <link href="https://songrgg.github.io/operation/install-spinnaker-on-centos/"/>
    <id>https://songrgg.github.io/operation/install-spinnaker-on-centos/</id>
    <published>2019-09-18T22:00:00.000Z</published>
    <updated>2020-09-25T13:05:10.000Z</updated>
    
    <content type="html"><![CDATA[<p>Spinnaker doesn’t support installation on CentOS machine, this article introduces how to use Docker to install Spinnaker components on CentOS directly.</p><p>As we know, according to the spinnaker’s official documentation, spinnaker provides a tool for installing the spinnaker cluster in Kubernetes cluster or debian/ubuntu bare metal machine, but there’s not an option to install it on CentOS or other common operating systems. Althogh the <a href="https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose">spinnaker</a> provides a way to start Spinnaker with <a href="https://docs.docker.com/compose/">Docker Compose</a>, but it’s out of date. So I created a new <a href="https://github.com/songrgg/spinnaker-compose">docker-compose project</a> to quickstart a spinnaker cluster on any kind of os.</p><span id="more"></span><h2 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart</h2><p>Provision a machine with at least 16GB memory and 4 cores, it may need more than this since my macbook pro(4cores, 16GB) was stuck when I started spinnaker.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo curl -L <span class="string">&quot;https://github.com/docker/compose/releases/download/1.24.1/docker-compose-<span class="subst">$(uname -s)</span>-<span class="subst">$(uname -m)</span>&quot;</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/songrgg/spinnaker-compose</span><br><span class="line"><span class="built_in">cd</span> spinnaker-compose</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><h2 id="To-access-the-spinnaker"><a href="#To-access-the-spinnaker" class="headerlink" title="To access the spinnaker"></a>To access the spinnaker</h2><p>Visit <code>http://localhost:9000</code> in browser if you run spinnaker on local machine.</p><p>Otherwise you can use ssh to create tunnel on local machine. Spinnaker exposes two ports, 9000 for web, 8084 for api gateway.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 8084:localhost:8084 &lt;remote-host&gt;</span><br><span class="line">ssh -L 9000:localhost:9000 &lt;remote-host&gt;</span><br></pre></td></tr></table></figure><h2 id="Add-clouddriver"><a href="#Add-clouddriver" class="headerlink" title="Add clouddriver"></a>Add clouddriver</h2><p>You need to edit <code>config/clouddriver.yml</code> to open multiple clouddrivers, it’s not easy to integrate since we don’t have the <code>halyard</code> to do this stuff, but if you already have the clouddriver.yml, it’s easier to make it work.</p><p>Since clouddriver will need credentials, you need to modify the <code>docker-compose.yml</code> to mount the credential files on the docker containers.</p><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/">how to build the smallest docker image as fast as you can</a></li><li><a href="https://songrgg.github.io/operation/hackathon-spinnaker/">My first Hackathon: bring Spinnaker to my company</a></li><li><a href="https://songrgg.github.io/life/raspberry3-docker/">Raspberry 3安装docker</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spinnaker doesn’t support installation on CentOS machine, this article introduces how to use Docker to install Spinnaker components on CentOS directly.&lt;/p&gt;
&lt;p&gt;As we know, according to the spinnaker’s official documentation, spinnaker provides a tool for installing the spinnaker cluster in Kubernetes cluster or debian/ubuntu bare metal machine, but there’s not an option to install it on CentOS or other common operating systems. Althogh the &lt;a href=&quot;https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose&quot;&gt;spinnaker&lt;/a&gt; provides a way to start Spinnaker with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker Compose&lt;/a&gt;, but it’s out of date. So I created a new &lt;a href=&quot;https://github.com/songrgg/spinnaker-compose&quot;&gt;docker-compose project&lt;/a&gt; to quickstart a spinnaker cluster on any kind of os.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="spinnaker" scheme="https://songrgg.github.io/tags/spinnaker/"/>
    
      <category term="docker" scheme="https://songrgg.github.io/tags/docker/"/>
    
      <category term="centos" scheme="https://songrgg.github.io/tags/centos/"/>
    
  </entry>
  
  <entry>
    <title>How to host Swagger documentation using yaml/json configuration files?</title>
    <link href="https://songrgg.github.io/operation/host-swagger-documentation-with-yaml-json-files/"/>
    <id>https://songrgg.github.io/operation/host-swagger-documentation-with-yaml-json-files/</id>
    <published>2019-09-12T19:11:50.000Z</published>
    <updated>2020-09-25T13:04:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>Maintain the swagger documentation by <a href="https://editor.swagger.io/">Swagger Editor</a> and then you can use the yaml files to generate online swagger documentation easily with <a href="https://spring.io/projects/spring-boot">Spring boot</a>.</p><span id="more"></span><h2 id="Workflow-for-Swagger-documentation"><a href="#Workflow-for-Swagger-documentation" class="headerlink" title="Workflow for Swagger documentation"></a>Workflow for Swagger documentation</h2><ol><li>Update swagger documentation with Swagger Editor, export the yaml files</li><li>Update the yaml files in Spring boot project</li><li>Redeploy the Spring boot project</li></ol><h2 id="How-to-setup-in-Spring-boot"><a href="#How-to-setup-in-Spring-boot" class="headerlink" title="How to setup in Spring boot?"></a>How to setup in Spring boot?</h2><p>Swagger provides swagger-ui and some jars to host a documentation, you can use Java annotations or yaml files to autogenerate the swagger documentation. The example below is using static yaml files to generate documentation.</p><p>Demo project: <a href="https://github.com/songrgg/swaggerdemo">https://github.com/songrgg/swaggerdemo</a></p><p>The static yaml file is fetched from Swagger Editor, put it under the resources directory.</p><figure class="highlight yaml"><figcaption><span>src/main/resources/static/swagger-apis/api1/swagger.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">swagger:</span> <span class="string">&quot;2.0&quot;</span></span><br><span class="line"><span class="attr">info:</span></span><br><span class="line">  <span class="attr">description:</span> <span class="string">&quot;This is a sample server Petstore server.  You can find out more about     Swagger at [http://swagger.io](http://swagger.io) or on [irc.freenode.net, #swagger](http://swagger.io/irc/).      For this sample, you can use the api key `special-key` to test the authorization     filters.&quot;</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">&quot;1.0.0&quot;</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">&quot;Swagger Petstore&quot;</span></span><br><span class="line">  <span class="attr">termsOfService:</span> <span class="string">&quot;http://swagger.io/terms/&quot;</span></span><br><span class="line">  <span class="attr">contact:</span></span><br><span class="line">    <span class="attr">email:</span> <span class="string">&quot;apiteam@swagger.io&quot;</span></span><br><span class="line">  <span class="attr">license:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">&quot;Apache 2.0&quot;</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">&quot;http://www.apache.org/licenses/LICENSE-2.0.html&quot;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><figcaption><span>Application.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableSwagger2</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SwaggerDemoApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SwaggerDemoApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Docket <span class="title">swagger</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Docket(SWAGGER_2)</span><br><span class="line">            .select()</span><br><span class="line">            .apis(RequestHandlerSelectors.any())</span><br><span class="line">            .paths(PathSelectors.any())</span><br><span class="line">            .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Read the static yaml files:<br><code>src/main/resources/swagger-apis/api1/swagger.yaml</code> and <code>src/main/resources/swagger-apis/api2/swagger.yaml</code>.</p><figure class="highlight java"><figcaption><span>SwaggerSpecConfig.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SwaggerSpecConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SwaggerResourcesProvider <span class="title">swaggerResourcesProvider</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        InMemorySwaggerResourcesProvider defaultResourcesProvider)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> () -&gt; &#123;</span><br><span class="line">            List&lt;SwaggerResource&gt; resources = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            Arrays.asList(<span class="string">&quot;api1&quot;</span>, <span class="string">&quot;api2&quot;</span>)</span><br><span class="line">                .forEach(resourceName -&gt; resources.add(loadResource(resourceName)));</span><br><span class="line">            <span class="keyword">return</span> resources;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> SwaggerResource <span class="title">loadResource</span><span class="params">(String resource)</span> </span>&#123;</span><br><span class="line">        SwaggerResource wsResource = <span class="keyword">new</span> SwaggerResource();</span><br><span class="line">        wsResource.setName(resource);</span><br><span class="line">        wsResource.setSwaggerVersion(<span class="string">&quot;2.0&quot;</span>);</span><br><span class="line">        wsResource.setLocation(<span class="string">&quot;/swagger-apis/&quot;</span> + resource + <span class="string">&quot;/swagger.yaml&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> wsResource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger-ui<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Run the spring boot server and access <code>&lt;hostname&gt;/swagger-ui.html</code> to see the documentation.</p><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/programming/spring-data-redis-issuse/">Spring data redis的一个bug</a></li><li><a href="https://songrgg.github.io/programming/spring-boot-database-read-write-split/">Spring boot实现数据库读写分离</a></li><li><a href="https://songrgg.github.io/programming/jedis-utf8/">解决Jedis数据读取乱码问题</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Maintain the swagger documentation by &lt;a href=&quot;https://editor.swagger.io/&quot;&gt;Swagger Editor&lt;/a&gt; and then you can use the yaml files to generate online swagger documentation easily with &lt;a href=&quot;https://spring.io/projects/spring-boot&quot;&gt;Spring boot&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="swagger" scheme="https://songrgg.github.io/tags/swagger/"/>
    
      <category term="spring boot" scheme="https://songrgg.github.io/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>My first Hackathon: bring Spinnaker to my company</title>
    <link href="https://songrgg.github.io/operation/hackathon-spinnaker/"/>
    <id>https://songrgg.github.io/operation/hackathon-spinnaker/</id>
    <published>2019-09-11T21:11:50.000Z</published>
    <updated>2020-09-25T13:04:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>I’ve joined my first Hackathon and worked on a project about using <a href="https://www.spinnaker.io/">Spinnaker</a> as CI/CD tool within company. The biggest challenge is to install Spinnaker on CentOS 7 with <a href="https://docs.docker.com/compose/">docker-compose</a>.</p><h2 id="Why-Spinnaker"><a href="#Why-Spinnaker" class="headerlink" title="Why Spinnaker?"></a>Why Spinnaker?</h2><ul><li>Spinnaker is dedicated to deploy services across multiple cloud providers and the integration with AWS, GCP, Azure is out of box.</li><li>It’s focused on deploy stably, support full control of workflow, developers can customize the deployment flow to improve the quality of deployment, also it’s automatic.</li><li>You will have a Web UI.</li></ul><span id="more"></span><h2 id="How-to-use-Spinnaker"><a href="#How-to-use-Spinnaker" class="headerlink" title="How to use Spinnaker?"></a>How to use Spinnaker?</h2><p>Spinnaker can integrate with VCS like Github, Gitlab, Gitbucket, docker registry.<br>For example the workflow of deploy golang github project to Kubernetes cluster.</p><ol><li>A developer pushes code to Github repository, it triggers the Travis-CI that starts the test, build, package stages, a docker image is pushed to Docker repository finally.</li><li>Spinnaker has a trigger on the Docker repository and starts to deploy that image to a Kubernetes cluster in some cloud provider.</li><li>The deployment workflow includes Deploy to staging, Canary Deployment, Deploy to production.</li></ol><h2 id="Details-of-this-hackathon"><a href="#Details-of-this-hackathon" class="headerlink" title="Details of this hackathon"></a>Details of this hackathon</h2><p>Our goal is to start a Spinnaker cluster and create a pipeline that can deploy the Git project to AWS and our own Kubernetes cluster.<br>There’re some contraints for this hackathon, I’m still new to the company so maybe it’s because of my limited information.</p><ol><li>I don’t have a Kuberntes cluster with API server’s access right, that means I can’t deploy Spinnaker cluster to Kubernetes.</li><li>I don’t have a Debian/Ubuntu machine, that means I can’t start Spinnaker on a bare metal with <a href="https://www.spinnaker.io/setup/install/halyard/">Halyard</a>.</li><li>The Spinnaker need to be deployed within company’s infrastructure which is not any cloud provider, otherwise it can’t communicate with other infrastructure.</li></ol><p>And what does Spinnaker need? It needs Halyard to configure the Spinnaker cluster, it will control where Spinnaker cluster is deployed, as we know Spinnaker itself is composed of microservices, hard to deploy on bare metal. Especially for its cloud provider settings, so Spinnaker relies on Halyard heavily, and every time the Spinnaker cluster update and upgrade can be managed safely.</p><p>Sadly, Halyard is only used for deploying Spinnaker itself to Kubernetes or  some cloud providers and Debian/Ubuntu single machine. Then according to our constraints above, we lose every chance to use that tool. Maybe it’s time to give up :(</p><p>We didn’t give up, choose to install Spinnaker cluster the hardest way. Install Spinnaker cluster on Bare metal machine which is CentOS 7, for running the cluster easier, we use Docker to start each components.</p><p><img src="/images/spin-dependencies.webp" alt="Spinnaker microservice dependencies"></p><p>My colleague found <code>docker-compose.yml</code> in <a href="https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose">Spinnaker</a>, but the latest modification time was 4 years ago. After trying so many times we still couldn’t make it, I tried to give up actually, and also it was far away from quickstart and wasted so much time.</p><p>Actually I didn’t give up, I returned home and thought if the Spinnaker cluster can be deployed in Kubernetes, it can be deployed with Docker compose, since they didn’t have any difference.</p><p>So I chose the most stupid method, I created a Spinnaker cluster on GCP with far less time and rewrote the <code>docker-compose.yml</code> according to:</p><ol><li>Check each Kubernetes Pod’s yaml file to get the environment variables, image name, arguments…</li><li>Login to the containers to fetch the mounted configuration files like clouddriver.yml, front50.yml, gate.yml… Yes, they’re generated by Halyard where the comment says <code>DONT&#39;T EDIT THIS FILE, IT&#39;S AUTOGENERATED BY...</code>.</li></ol><p>After another X hours, without ignoring every details, I migrated all the Kubernetes configuration to <code>docker-compose.yml</code>, the second when I ran the <code>docker-compose up -d</code> and every microservice was labeled <code>DONE</code> and <code>http://localhost:9000</code> worked.</p><h2 id="Reflection-of-this-hackathon"><a href="#Reflection-of-this-hackathon" class="headerlink" title="Reflection of this hackathon"></a>Reflection of this hackathon</h2><p>Yes, it’s not a happy ending for my first hackathon, our team didn’t reach our goal, there’s some experience for this time.</p><p><strong>Gain</strong></p><ol><li>The hardest way to know how the Spinnaker configuration works, how it deploys.</li><li>I felt some joy when the installation was successful :)</li><li>Some knowledge about the GCP (first time to use GCP)</li></ol><p><strong>Improvements next time</strong></p><ol><li>Team member can be closer, whatever the seat we sit or the communication channel we talked, time is presious, we need check our progress frequently.</li><li>Fail fast, although this time I worked out the installation, but it was not a great result, next time we should help the team member to tackle the most important task.</li><li>Prepare enough, time is precious, if you want to make it in the Hackathon project, do some preparations, it’s not cheat!</li></ol><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/">Implement zero downtime HTTP service rollout on Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/install-spinnaker-on-centos/">How to install Spinnaker on CentOS 7</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ve joined my first Hackathon and worked on a project about using &lt;a href=&quot;https://www.spinnaker.io/&quot;&gt;Spinnaker&lt;/a&gt; as CI/CD tool within company. The biggest challenge is to install Spinnaker on CentOS 7 with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;docker-compose&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Why-Spinnaker&quot;&gt;&lt;a href=&quot;#Why-Spinnaker&quot; class=&quot;headerlink&quot; title=&quot;Why Spinnaker?&quot;&gt;&lt;/a&gt;Why Spinnaker?&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Spinnaker is dedicated to deploy services across multiple cloud providers and the integration with AWS, GCP, Azure is out of box.&lt;/li&gt;
&lt;li&gt;It’s focused on deploy stably, support full control of workflow, developers can customize the deployment flow to improve the quality of deployment, also it’s automatic.&lt;/li&gt;
&lt;li&gt;You will have a Web UI.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="sre" scheme="https://songrgg.github.io/tags/sre/"/>
    
      <category term="cicd" scheme="https://songrgg.github.io/tags/cicd/"/>
    
      <category term="spinnaker" scheme="https://songrgg.github.io/tags/spinnaker/"/>
    
      <category term="docker-compose" scheme="https://songrgg.github.io/tags/docker-compose/"/>
    
  </entry>
  
  <entry>
    <title>Anatomy of envoy proxy: the architecture of envoy and how it works</title>
    <link href="https://songrgg.github.io/architecture/deeper-understanding-to-envoy/"/>
    <id>https://songrgg.github.io/architecture/deeper-understanding-to-envoy/</id>
    <published>2019-08-13T22:00:00.000Z</published>
    <updated>2020-09-25T13:03:52.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.envoyproxy.io/">Envoy</a> has become more and more popular, the basic functionality is quite similar to <a href="https://www.nginx.com/">Nginx</a>, working as a high performace Web server, proxy. But Enovy imported a lot of features that was related to <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">SOA</a> or <a href="https://en.wikipedia.org/wiki/Microservices">Microservice</a> like Service Discovery, Circuit Breaker, Rate limiting and so on. </p><p>A lot of developers know the roles envoy plays, and the basic functionality it will implement, but don’t know how it organize the architecture and how we understand its configuration well. For me, it’s not easy to understand envoy’s architecture and its configuration since it has a lot of terminology, but if the developer knew how the user traffic goes, he could understand the design of envoy.</p><span id="more"></span><h3 id="Envoy-In-Servicemesh"><a href="#Envoy-In-Servicemesh" class="headerlink" title="Envoy In Servicemesh"></a>Envoy In Servicemesh</h3><p>Recently, more and more companies take Service Mesh to solve the communication problem among backend services, it’s a typical use case for envoy to work as a basic component for building a service mesh, envoy plays an important role and one of the service mesh solution <a href="https://istio.io/">Istio</a> uses Envoy as the core of the networking.</p><p><img src="/images/envoy-in-service-mesh.webp" alt="envoy in service mesh"></p><p>As pictured, the Envoy is deployed beside every application, this kind of application we call it <code>Sidecar</code>.</p><p>Let’s analyze how the user traffic moves.</p><ol><li>The user hits the website and the browser tries to query an API, the api gateway receives the user request.</li><li>The API Gateway redirects the request to the backend server1 (in Kubernetes, it can be a Pod)</li><li>The envoy on backend server receives this HTTP request and resolves it to the destination server and forwards the request to the local destination port which APP1 listens at.</li><li>The APP1 receives requests, processes the bussiness logic and tries to call a dependent RPC service in APP2, the request first is sent to local envoy.</li><li>The local envoy resolves the RPC service APP2’s IP address and port according to the management server and sends the RPC request to APP2 server.</li><li>The server where the RPC service located at recevies the request,  to be clear, it’s the envoy receiving the request, after the same logic like step 3.</li><li>The APP2 processes the request and returns.</li><li>The envoy forwards the response to server1.</li><li>There’re two forwards being ignored, envoy(1) to APP1, APP1 to envoy(1). Then the envoy(1) returns the reponse to API gateway.</li><li>The API gateway returns to the user.</li></ol><p>The management server is responsible for telling envoy how to process the requests and where to forward.<br>Service discovery is where applications register themselves.</p><h4 id="Ingress-and-Egress"><a href="#Ingress-and-Egress" class="headerlink" title="Ingress and Egress"></a>Ingress and Egress</h4><p>As you can see, there’re two kinds of traffic within a server: ingress and egress.</p><ul><li>Any traffic sent to server, it’s ingress.</li><li>Any traffic sent from server, it’s egress.</li></ul><p>How to implement this transparently?</p><ul><li><p>Setup <strong>IPtables</strong> to redirect any traffic to this server to the envoy service first, then envoy redirects the traffic to the real application on this server.</p></li><li><p>Setup <strong>IPtables</strong> to redirect any traffic from this server to the envoy service first and envoy resolves the destination service using Service Discovery, redirects the request to the destination server.</p></li></ul><p>By intercepting the inbound and outbound traffic, envoy can implement the service discovery, circuit breaker, rate limiting, monitoring transparently, the developers don’t need to care about the details or integrate libraries.</p><h3 id="Anatomy-of-envoy-proxy-configuration"><a href="#Anatomy-of-envoy-proxy-configuration" class="headerlink" title="Anatomy of envoy proxy configuration"></a>Anatomy of envoy proxy configuration</h3><p>The first important role of envoy in the service mesh is <strong>proxy</strong>, it receives requests and forwards requests.<br>To see the components that make the proxy work, we can start with a request flow.</p><p><img src="/images/envoy-config.webp" alt="How Envoy Configuration works"></p><ol><li>A request reaches a port on the server which envoy listens at, we call this part <strong>listener</strong>.</li><li>Envoy receives the request and tries to process this request according to some rule, the rule is <strong>route</strong>.</li><li>The route processes the request based on the request’s metadata and tries to request the specific backend servers, the backend servers are called <strong>cluster</strong>.</li><li>The concrete server IP:port behind cluster is called <strong>endpoint</strong>.</li></ol><p>It’s the main part of envoy components in most of the proxy cases, similar to Nginx, you’re allowed to setup all the configuration by static files.</p><p>Here is an example with static configuration, you can see the full file <a href="https://github.com/envoyproxy/envoy/blob/master/examples/front-proxy/front-envoy.yaml">here</a>.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">static_resources:</span></span><br><span class="line">  <span class="attr">listeners:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span></span><br><span class="line">      <span class="attr">socket_address:</span></span><br><span class="line">        <span class="attr">address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">port_value:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">filter_chains:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">filters:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">envoy.http_connection_manager</span></span><br><span class="line">        <span class="attr">typed_config:</span></span><br><span class="line">          <span class="string">&quot;@type&quot;</span><span class="string">:</span> <span class="string">type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager</span></span><br><span class="line">          <span class="attr">codec_type:</span> <span class="string">auto</span></span><br><span class="line">          <span class="attr">stat_prefix:</span> <span class="string">ingress_http</span></span><br><span class="line">          <span class="attr">route_config:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">local_route</span></span><br><span class="line">            <span class="attr">virtual_hosts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">backend</span></span><br><span class="line">              <span class="attr">domains:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">&quot;*&quot;</span></span><br><span class="line">              <span class="attr">routes:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">                  <span class="attr">prefix:</span> <span class="string">&quot;/service/1&quot;</span></span><br><span class="line">                <span class="attr">route:</span></span><br><span class="line">                  <span class="attr">cluster:</span> <span class="string">service1</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">                  <span class="attr">prefix:</span> <span class="string">&quot;/service/2&quot;</span></span><br><span class="line">                <span class="attr">route:</span></span><br><span class="line">                  <span class="attr">cluster:</span> <span class="string">service2</span></span><br><span class="line">          <span class="attr">http_filters:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">envoy.router</span></span><br><span class="line">            <span class="attr">typed_config:</span> &#123;&#125;</span><br><span class="line">  <span class="attr">clusters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">strict_dns</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">round_robin</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">service1</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="string">service1</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">strict_dns</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">round_robin</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">service2</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="string">service2</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>Don’t be nervous, you can understand this configuration easily by order:</p><ul><li>listener<br>It says the envoy listens at 0.0.0.0:80</li><li>route<br>It tells how to process request, there’s a route named local_route, a rule matching wildcard domain and forwards the request to <code>service1</code> cluster if the request path’s prefix matches <code>/service/1</code>, else forwards to <code>service2</code> cluster if the request path’s prefix matches <code>service/2</code>.</li><li>cluster<br>Finally, the <code>service1</code> cluster memtioned before is resolved to several endpoints, it’s the real address of the server, the address is <code>service1:80</code>.</li></ul><p>So the basic structure of the configuration is quite straightforward and easy to understand, if you want to manipulate the configuration and don’t know where to start, you can refer to this sample and every data model inside can be found in envoy documentation.</p><p>But most importantly, it’s allowed to use <strong>dynamic configuration</strong> which is mostly used in SOA and Microservice, it fits the situations where the service’s endpoints and route rules may change anytime.</p><p>For using dynamic resources, envoy supports setting an API server and divides the above components into different APIs or different resources within an API.</p><ul><li>LDS: listener<br>The listener discovery service (LDS) is an optional API that Envoy will call to dynamically fetch listeners. Envoy will reconcile the API response and add, modify, or remove known listeners depending on what is required.</li><li>RDS: route<br>The route discovery service (RDS) API is an optional API that Envoy will call to dynamically fetch route configurations. A route configuration includes both HTTP header modifications, virtual hosts, and the individual route entries contained within each virtual host.</li><li>CDS: cluster<br>The cluster discovery service (CDS) is an optional API that Envoy will call to dynamically fetch cluster manager members. Envoy will reconcile the API response and add, modify, or remove known clusters depending on what is required.</li><li>EDS: endpoint<br>The endpoint discovery service is a xDS management server based on gRPC or REST-JSON API server used by Envoy to fetch cluster members. The cluster members are called “endpoint” in Envoy terminology. For each cluster, Envoy fetch the endpoints from the discovery service.</li></ul><p>The concept is equal to the static configuration, you can initialize the configuration by</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">admin:</span></span><br><span class="line">  <span class="attr">access_log_path:</span> <span class="string">/tmp/admin_access.log</span></span><br><span class="line">  <span class="attr">address:</span></span><br><span class="line">    <span class="attr">socket_address:</span> &#123; <span class="attr">address:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>, <span class="attr">port_value:</span> <span class="number">9901</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="attr">dynamic_resources:</span></span><br><span class="line">  <span class="attr">lds_config:</span></span><br><span class="line">    <span class="attr">api_config_source:</span></span><br><span class="line">      <span class="attr">api_type:</span> <span class="string">GRPC</span></span><br><span class="line">      <span class="attr">grpc_services:</span></span><br><span class="line">        <span class="attr">envoy_grpc:</span></span><br><span class="line">          <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line">  <span class="attr">cds_config:</span></span><br><span class="line">    <span class="attr">api_config_source:</span></span><br><span class="line">      <span class="attr">api_type:</span> <span class="string">GRPC</span></span><br><span class="line">      <span class="attr">grpc_services:</span></span><br><span class="line">        <span class="attr">envoy_grpc:</span></span><br><span class="line">          <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line"></span><br><span class="line"><span class="attr">static_resources:</span></span><br><span class="line">  <span class="attr">clusters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">xds_cluster</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">STATIC</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">ROUND_ROBIN</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">upstream_connection_options:</span></span><br><span class="line">      <span class="comment"># configure a TCP keep-alive to detect and reconnect to the admin</span></span><br><span class="line">      <span class="comment"># server in the event of a TCP socket half open connection</span></span><br><span class="line">      <span class="attr">tcp_keepalive:</span> &#123;&#125;</span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">5678</span></span><br></pre></td></tr></table></figure><p>The only static resource is the xds_cluster which is the management server cluster which provides <strong>a GRPC streaming API</strong> answering the LDS, CDS, EDS, RDS configuration.<br>As you notice, there’re only lds_config and cds_config inside the config file, that’s because rds is included in lds and eds is included in cds.</p><p>In Service Mesh architecture, the management server is the most important module, it always connects to a distributed service discovery system which can be <a href="https://etcd.io/">Etcd</a>, <a href="https://zookeeper.apache.org/">Zookeeper</a>, <a href="https://www.consul.io/">Consul</a>, <a href="https://github.com/Netflix/eureka">Eureka</a> or the Kubernetes(Kubernetes often used Etcd as their service discovery component), and provide some interfaces to manipulate the configuration to implement near-realtime configuration change.</p><h2 id="Conclustion"><a href="#Conclustion" class="headerlink" title="Conclustion"></a>Conclustion</h2><p>Understanding how the user traffic flows makes it easier for me to understand the component design of envoy and have a first glimpse of the envoy configuration, then you can start with more features later.</p><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/">Implement zero downtime HTTP service rollout on Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/hackathon-spinnaker/">My first Hackathon: bring Spinnaker to my company</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.envoyproxy.io/&quot;&gt;Envoy&lt;/a&gt; has become more and more popular, the basic functionality is quite similar to &lt;a href=&quot;https://www.nginx.com/&quot;&gt;Nginx&lt;/a&gt;, working as a high performace Web server, proxy. But Enovy imported a lot of features that was related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot;&gt;SOA&lt;/a&gt; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot;&gt;Microservice&lt;/a&gt; like Service Discovery, Circuit Breaker, Rate limiting and so on. &lt;/p&gt;
&lt;p&gt;A lot of developers know the roles envoy plays, and the basic functionality it will implement, but don’t know how it organize the architecture and how we understand its configuration well. For me, it’s not easy to understand envoy’s architecture and its configuration since it has a lot of terminology, but if the developer knew how the user traffic goes, he could understand the design of envoy.&lt;/p&gt;
    
    </summary>
    
    
      <category term="architecture" scheme="https://songrgg.github.io/categories/architecture/"/>
    
    
      <category term="envoy" scheme="https://songrgg.github.io/tags/envoy/"/>
    
      <category term="service mesh" scheme="https://songrgg.github.io/tags/service-mesh/"/>
    
      <category term="architecture" scheme="https://songrgg.github.io/tags/architecture/"/>
    
      <category term="request analysis" scheme="https://songrgg.github.io/tags/request-analysis/"/>
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Istio Version Control On Kubernetes</title>
    <link href="https://songrgg.github.io/operation/istio-version-control-on-k8s/"/>
    <id>https://songrgg.github.io/operation/istio-version-control-on-k8s/</id>
    <published>2019-03-28T18:10:00.000Z</published>
    <updated>2020-06-06T23:48:33.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://istio.io/">Istio</a> has been adopted as a common implementation of <a href="https://istio.io/docs/concepts/what-is-istio/">service mesh</a>, since more and more companies want to bring Istio into production, the version control of Istio seems a significant problem to solve.</p><p>Version control is necessary as Istio components can be treated as the equivalent RPC services like our business services, we need to have an understanding of which version we are using now and what does the next version bring. And some Istio components can cooperate with the others, if we need to upgrade one component we need to upgrade the other components too.</p><p>Although the Istio community provides the Istio upgrade method, we don’t actually want to upgrade such a whole thing in one move, it influences so much that we don’t want to risk.</p><span id="more"></span><h3 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h3><p><a href="https://helm.sh/">Helm</a> is package control system for Kubernetes, it’s more like the complicated version of brew on Mac.</p><p>It uses Yaml and Golang templates to formulate a complete application configuration on Kubernetes. A lot of applications are packaged as Helm charts, we can build a complicated application by declaring the dependencies between these charts.</p><h3 id="Istio-Helm"><a href="#Istio-Helm" class="headerlink" title="Istio + Helm"></a>Istio + Helm</h3><p>Istio project contains the <a href="https://github.com/istio/istio/blob/master/install/kubernetes/helm/istio/README.md">Helm configuration</a> itself, I recommend the users to extract the Helm brought by Istio into a standalone Git repository.</p><p><img src="/images/istio-helm-git.webp" alt="istio-helm-git"></p><p>Like the other services, we use Git to control each component’s configuration and track every modification.</p><h3 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI/CD"></a>CI/CD</h3><p>As more and more people advocate <code>infrastructure as code</code>, we not only store the Istio Helm as a Git repository, we bring the CI/CD to the infrastructure.</p><p>If three Kubernetes clusters: <code>test</code>, <code>stage</code>, <code>production</code> exist, we can setup CI/CD to <code>test</code> cluster based on the specified Git <code>test</code> branch, each commit will trigger the generation of the latest Istio K8S Yaml config and apply them to the <code>test</code> cluster, after the tests on <code>test</code> environment, we brought the Istio updates to the <code>stage</code> and <code>production</code> in order.</p><h3 id="Still-worried-about-Production"><a href="#Still-worried-about-Production" class="headerlink" title="Still worried about Production?"></a>Still worried about Production?</h3><p>Although we have tested in the <code>test</code> environment, we still worry if it works in the <code>production</code> and a method to let you know what actually changes is to <strong>diff</strong> the K8S configuration between the latest config and the current K8S config.<br>I recommend the <a href="https://github.com/weaveworks/kubediff"><code>kubediff</code></a> tool to distinguish the differences.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul><li>Every updates to Istio configuration need to be tracked by Git. </li><li>Like the common services, deploy the change to <code>test</code> environment as soon as possible to fail fast.</li><li>Use <code>kubediff</code> to show the changes.</li></ul><div><h2>Recommended Posts<span style="font-size:0.45em; color:gray">(Driven by<a href="https://github.com/huiwang/hexo-recommended-posts">Hexo Recommended Posts plugin</a>)</span></h2><ul><li><a href="https://songrgg.github.io/operation/how-to-alert-for-Pod-Restart-OOMKilled-in-Kubernetes/">How to alert for Pod Restart & OOMKilled in Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/use-traffic-control-simulate-network-chaos/">Use Traffic Control to Simulate Network Chaos in Bare metal & Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/zero-downtime-kubernetes-service-rollout/">Implement zero downtime HTTP service rollout on Kubernetes</a></li><li><a href="https://songrgg.github.io/operation/hackathon-spinnaker/">My first Hackathon: bring Spinnaker to my company</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://istio.io/&quot;&gt;Istio&lt;/a&gt; has been adopted as a common implementation of &lt;a href=&quot;https://istio.io/docs/concepts/what-is-istio/&quot;&gt;service mesh&lt;/a&gt;, since more and more companies want to bring Istio into production, the version control of Istio seems a significant problem to solve.&lt;/p&gt;
&lt;p&gt;Version control is necessary as Istio components can be treated as the equivalent RPC services like our business services, we need to have an understanding of which version we are using now and what does the next version bring. And some Istio components can cooperate with the others, if we need to upgrade one component we need to upgrade the other components too.&lt;/p&gt;
&lt;p&gt;Although the Istio community provides the Istio upgrade method, we don’t actually want to upgrade such a whole thing in one move, it influences so much that we don’t want to risk.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="configuration management" scheme="https://songrgg.github.io/tags/configuration-management/"/>
    
      <category term="istio" scheme="https://songrgg.github.io/tags/istio/"/>
    
  </entry>
  
</feed>
