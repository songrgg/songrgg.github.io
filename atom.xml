<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog | Songrgg</title>
  
  <subtitle>A programmer who likes travelling and cooking :)</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://songrgg.github.io/"/>
  <updated>2020-05-31T10:26:37.134Z</updated>
  <id>https://songrgg.github.io/</id>
  
  <author>
    <name>songrgg</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>How does Prometheus query work? - Part 1, Step, Query and Range</title>
    <link href="https://songrgg.github.io/programming/how-does-prometheus-query-works/"/>
    <id>https://songrgg.github.io/programming/how-does-prometheus-query-works/</id>
    <published>2020-05-31T08:27:50.000Z</published>
    <updated>2020-05-31T10:26:37.134Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://prometheus.io/">Prometheus</a> is an opensource time series database, commonly used to gather and calculate monitoring metrics, with <a href="https://grafana.com/">Grafana</a> which is the visualization dashboard. This article explains how the query works with <strong>/query_range</strong> API.</p><a id="more"></a><h2 id="Start-a-Prometheus"><a href="#Start-a-Prometheus" class="headerlink" title="Start a Prometheus"></a>Start a Prometheus</h2><p>According to the Prometheus doc, a prometheus server has been started and listens at <code>localhost:9090</code>.</p><p>Prometheus browser is a WEB UI that is used to query the metrics for testing, the path is <code>http://localhost:9090/graph</code>, there are two APIs used to query the metrics, the first one is /query (which is used to see the metric value in a specified time point, the other one is <strong>/query_range</strong> used to query the metric during a period.</p><h2 id="Metric-types"><a href="#Metric-types" class="headerlink" title="Metric types"></a>Metric types</h2><p>Before we start analyzing a query, we need to know the metric types Prometheus provides:</p><h3 id="Counter"><a href="#Counter" class="headerlink" title="Counter"></a>Counter</h3><p>Indicates an cumulative number of the observable, for example the total http request number. This metric value is increasing monotonically increasing. For instance, <code>http_request_total</code> records the total count of HTTP requests the server serves.</p><h3 id="Gauge"><a href="#Gauge" class="headerlink" title="Gauge"></a>Gauge</h3><p>A gauge is a metric that represents a single numerical value that can arbitrarily go up and down. For instance, the instance’s CPU usage, it’s changeable all the time.</p><h3 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h3><p>A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets. It also provides a sum of all observed values.<br>The <a href="https://prometheus.io/docs/practices/histograms/">Prometheus Histograms</a> gives an example, <code>http_request_duration_seconds</code>, consider we have an SLO requirement, 95% requests’ response time is within 300ms, so the straightforward way is to divide the bucket into several segments, for example, 300ms, 1s, 5s, 10s, +inf, and each bucket contains its <strong>counter</strong> metric which counts the total number of the requests within this bucket,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http_request_duration_bucket</span><br><span class="line">[0 - 300ms]</span><br><span class="line">[0 - 1s]</span><br><span class="line">[0 - 5s]</span><br><span class="line">[0 - 10s]</span><br><span class="line">[0 - +inf]</span><br></pre></td></tr></table></figure><p>You’ll see the bucket is divided and each segment starts from 0 seconds, it means [0 - 1s] will include the [0 - 300ms]. As we said, each bucket metric is of <strong>counter</strong> type, it records the total requests number within that response time and there’s a total count metric called <code>http_request_duration_seconds_count</code>.</p><p>To calculate how much does 300ms occupy, we can calculate with <code>http_request_duration_seconds_bucket{le=&quot;0.3&quot;}/http_request_duration_seconds_count</code>, it calculates the instant value of the moment, but if we only use the instant value of that moment, the data will be not smooth and the graph might be spiky, so we’d better use duration to gather more data, <code>sum(rate(http_request_duration_seconds_bucket{le=&quot;0.3&quot;}[5m]))/sum(rate(http_request_duration_seconds_count[5m]))</code>.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Similar to a histogram, a summary samples observations (usually things like request durations and response sizes). While it also provides a total count of observations and a sum of all observed values, it calculates configurable quantiles over a sliding time window.  </p><h2 id="How-does-query-work"><a href="#How-does-query-work" class="headerlink" title="How does query work?"></a>How does query work?</h2><p>When we use Prometheus to calculate a query, normally we’re using the <strong>query_range</strong> functionality, after a time range and step is specified, the query will be applied to every step and a point will be put into the results.</p><p>Let’s see an entire query API:<br><a href="http://localhost:9090/api/v1/query_range?query=prometheus_target_interval_length_seconds&amp;start=1590830727.588&amp;end=1590834327.588&amp;step=14">http://localhost:9090/api/v1/query_range?query=prometheus_target_interval_length_seconds&amp;start=1590830727.588&amp;end=1590834327.588&amp;step=14</a></p><p>it might be a little messy, let’s break it down into parameters,</p><ul><li>query<br>query is the metric formula that needs to be calculated</li><li>Time range (start and end)<br>It is easy to understand, we can specify when should the metrics start and end, I want to see the last 30 minutes or last 7 days, it’s set by the start and end parameters, their format is unix timestamp.</li><li>step<br>It is used to decide how many data points we need by setting each data points’ interval and its format is second.</li></ul><p>The result is too much, I would only paste part of it:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"status"</span>: <span class="string">"success"</span>,</span><br><span class="line">    <span class="attr">"data"</span>: &#123;</span><br><span class="line">        <span class="attr">"resultType"</span>: <span class="string">"matrix"</span>,</span><br><span class="line">        <span class="attr">"result"</span>: [&#123;</span><br><span class="line">            <span class="attr">"metric"</span>: &#123;</span><br><span class="line">                <span class="attr">"__name__"</span>: <span class="string">"prometheus_target_interval_length_seconds"</span>,</span><br><span class="line">                <span class="attr">"instance"</span>: <span class="string">"localhost:9090"</span>,</span><br><span class="line">                <span class="attr">"interval"</span>: <span class="string">"15s"</span>,</span><br><span class="line">                <span class="attr">"job"</span>: <span class="string">"prometheus"</span>,</span><br><span class="line">                <span class="attr">"quantile"</span>: <span class="string">"0.01"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"values"</span>: [</span><br><span class="line">                [<span class="number">1590830727.588</span>, <span class="string">"14.996369259"</span>],</span><br><span class="line">                [<span class="number">1590830741.588</span>, <span class="string">"14.996369259”]</span></span><br><span class="line"><span class="string">            ]</span></span><br><span class="line"><span class="string">        &#125;]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><ul><li>status marks the calculation is successful or not</li><li>result.metric shows the original metric</li><li>result.values shows the actual data points we need, the left value is the timestamp, the right one is the metric value.<br>Each result value’s interval is exactly the step we set, in the previous example, it’s 14 seconds. It means every 14 second, the query will be calculated and one data point is generated.</li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>I explored the query_range API a bit in this article, in the next article, I’ll explore some frequent Prometheus functions like rate, irate, histogram_percentile, etc.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://prometheus.io/docs/concepts/metric_types/">Prometheus - Metric types</a></li><li><a href="https://prometheus.io/docs/prometheus/latest/getting_started/">Prometheus - Get started</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://prometheus.io/&quot;&gt;Prometheus&lt;/a&gt; is an opensource time series database, commonly used to gather and calculate monitoring metrics, with &lt;a href=&quot;https://grafana.com/&quot;&gt;Grafana&lt;/a&gt; which is the visualization dashboard. This article explains how the query works with &lt;strong&gt;/query_range&lt;/strong&gt; API.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
      <category term="prometheus" scheme="https://songrgg.github.io/tags/prometheus/"/>
    
  </entry>
  
  <entry>
    <title>Linux namespace in Go - Part 3, Cgroups resource limit</title>
    <link href="https://songrgg.github.io/programming/linux-namespace-part03-cgroups/"/>
    <id>https://songrgg.github.io/programming/linux-namespace-part03-cgroups/</id>
    <published>2020-05-21T18:21:50.000Z</published>
    <updated>2020-05-24T17:41:22.433Z</updated>
    
    <content type="html"><![CDATA[<p>In the <a href="/programming/linux-namespace-part02-uid-mount/">previous article</a>, I did two experiments on what isolation it brings with UID and Mount, this article explains how to limit the container’s resource by using Cgroups, for instance, CPU, memory resources.</p><a id="more"></a><h2 id="Cgroups"><a href="#Cgroups" class="headerlink" title="Cgroups"></a>Cgroups</h2><blockquote><p>Control groups, usually referred to as cgroups, are a Linux kernel feature which allow processes to be organized into hierarchical groups whose usage of various types of resources can then be limited and monitored. The kernel’s cgroup interface is provided through a pseudo-filesystem called cgroupfs.  Grouping is implemented in the core cgroup kernel code, while resource tracking and limits are implemented in a set of per-resource-type subsystems (memory, CPU, and so on).</p></blockquote><p>We can use cgroups to control the container’s resource usage, it’s necessary when we have many containers running in a host machine, it prevents some container from consuming too much resources therefore the other containers would run out of CPU, memory, etc. The interface we setup the resource limit is Linux I/O interface, you can simply write to the cgroups configuration files and it will take effect immediately.</p><h2 id="How-to-setup-cgroup-limit"><a href="#How-to-setup-cgroup-limit" class="headerlink" title="How to setup cgroup limit?"></a>How to setup cgroup limit?</h2><p>Cgroup configuration is organized by file system hierachy, for convention, the cgroup directory is mounted under <code>/sys/fs/cgroup</code>, the separate resource configuration directories are placed under some paths like <code>/sys/fs/cgroup/cpu/user/user1</code>, this is the configuration for user1’s processes.<br>Cgroup configuration is applied to the processes, if the parent process’s resource is limited, its child processes are also automatically limited according to its parent cgroup limit. The process list is stored under <code>/sys/fs/cgroup/cpu/user/user1/cgroup.procs</code>, after you add the process ID to the file, the processes it spawns will be added to the file automatically.</p><h2 id="Resource-Types"><a href="#Resource-Types" class="headerlink" title="Resource Types"></a>Resource Types</h2><p>There are different resource types that you can specify for your process, they’re called <code>controllers</code>.</p><ul><li><p>cpu<br>You’re allowed to setup both soft and hard limits to the CPU shares your processes can use, soft means if the CPU is not busy, it would specify more CPU shares to the process otherwise it would not. Hard means no matter the CPU is busy or not, the process could not use more that the specified limit.</p></li><li><p>cpuacct<br>The CPU accounting controller is used to group tasks using cgroups and<br>account the CPU usage of these groups of tasks.</p></li></ul><p>The CPU accounting controller supports multi-hierarchy groups. An accounting<br>group accumulates the CPU usage of all of its child groups and the tasks<br>directly present in its group.</p><ul><li><p>cpuset<br>This cgroup can be used to bind the processes in a cgroup to a specified set of CPUs and NUMA nodes.</p></li><li><p>memory<br>The memory controller supports reporting and limiting of process memory, kernel memory, and swap used by cgroups.</p></li><li><p>devices<br>This supports controlling which processes may create (mknod)<br>devices as well as open them for reading or writing.  The<br>policies may be specified as allow-lists and deny-lists.<br>Hierarchy is enforced, so new rules must not violate existing<br>rules for the target or ancestor cgroups.</p></li><li><p>freezer<br>The freezer cgroup can suspend and restore (resume) all processes in a cgroup.  Freezing a cgroup /A also causes its<br>children, for example, processes in /A/B, to be frozen.</p></li><li><p>net_cls<br>This places a classid, specified for the cgroup, on network<br>packets created by a cgroup.  These classids can then be used<br>in firewall rules, as well as used to shape traffic using<br>tc(8).  This applies only to packets leaving the cgroup, not<br>to traffic arriving at the cgroup.</p></li><li><p>blkio<br>The blkio cgroup controls and limits access to specified block devices by applying IO control in the form of throttling and upper limits against leaf nodes and intermediate nodes in the storage hierarchy.</p></li><li><p>perf_event<br>This controller allows perf monitoring of the set of processes grouped in a cgroup.</p></li><li><p>net_prio<br>This allows <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/net_prio.txt">priorities</a> to be specified, per network interface, for cgroups.</p></li><li><p>hugetlb<br>This supports limiting the use of huge pages by cgroups.</p></li><li><p>pids<br>This controller permits limiting the number of process that may be created in a cgroup.</p></li><li><p>rdma<br>The RDMA controller permits limiting the use of RDMA/IB-specific resources per cgroup.</p></li></ul><p>I would take CPU and memory controllers as example in the following exercises.</p><h2 id="CPU-controller"><a href="#CPU-controller" class="headerlink" title="CPU controller"></a>CPU controller</h2><p>This introduces how to setup CPU limits for the process, in this case, I wanna limit the CPU hard limit to 0.5 cores.</p><p>First, we need to create an isolated group for this CPU limit, as I said before, the configuration is usually under <code>/sys/fs/cgroup</code>, let’s create a new folder for this, we call this <code>/sys/fs/cgroup/cpu/mycontainer</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /sys/fs/cgroup/cpu/mycontainer</span><br></pre></td></tr></table></figure><p>Then, we set the CPU hard limit to 0.5 cores, there are two parameters</p><ul><li>cpu.cfs_period_us<br>the total available run-time within a period (in microseconds)</li><li>cpu.cfs_quota_us<br>the length of a period (in microseconds)</li></ul><p>The actual schedule run-time of the process will be <code>cpu.cfs_quota_us</code> microseconds of <code>cpu.cfs_period_us</code> microsends, so to use only 0.5 cores, we can specify 5000 out of 10000.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo su</span><br><span class="line"><span class="built_in">echo</span> 10000 &gt; /sys/fs/cgroup/cpu/mycontainer/cpu.cfs_period_us</span><br><span class="line"><span class="built_in">echo</span> 5000  &gt; /sys/fs/cgroup/cpu/mycontainer/cpu.cfs_quota_us</span><br></pre></td></tr></table></figure><p>Finally, we put the process of a Bash script to the <code>cgroup.procs</code> file,</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bash</span><br><span class="line"><span class="built_in">echo</span> $$ &gt; /sys/fs/cgroup/cpu/mycontainer/cgroup.procs</span><br></pre></td></tr></table></figure><p>You can test the CPU usage with <code>yes &gt; /dev/null</code> and use htop to monitor the current CPU usage, it will be around 0.5 core used by the <code>yes</code> command.</p><h2 id="Memory-Controller"><a href="#Memory-Controller" class="headerlink" title="Memory Controller"></a>Memory Controller</h2><p>Similar to the CPU controller, let’s have a look at the memory cgroup configurations.</p><ul><li>tasks                 # attach a task(thread) and show list of threads</li><li>cgroup.procs             # show list of processes</li><li>cgroup.event_control         # an interface for event_fd()</li><li>memory.usage_in_bytes         # show current usage for memory<pre><code>(See 5.5 for details)</code></pre></li><li>memory.memsw.usage_in_bytes     # show current usage for memory+Swap<pre><code>(See 5.5 for details)</code></pre></li><li>memory.limit_in_bytes         # set/show limit of memory usage</li><li>memory.memsw.limit_in_bytes     # set/show limit of memory+Swap usage</li><li>… For more details, check <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">Memory Cgroup</a></li></ul><p>To setup the memory hard limit for the process, first we create a cgroup folder for this and write to the <code>memory.limit_in_bytes</code>. After that, we added the process ID to the <code>cgroup.procs</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /sys/fs/cgroup/memory/mycontainer</span><br><span class="line">sudo su</span><br><span class="line"><span class="built_in">echo</span> 10000000 &gt; /sys/fs/cgroup/memory/mycontainer/memory.limit_in_bytes</span><br><span class="line"><span class="built_in">echo</span> &lt;process-id&gt; &gt; /sys/fs/cgroup/memory/mycontainer/cgroup.procs</span><br></pre></td></tr></table></figure><h2 id="Cgroups-in-Golang"><a href="#Cgroups-in-Golang" class="headerlink" title="Cgroups in Golang"></a>Cgroups in Golang</h2><p><a href="https://github.com/songrgg/namespace-demo/blob/master/README.md#cgroups">Cgroup in Golang</a> is equivalent to the commands I have executed before, the example code you can access in the <a href="https://github.com/songrgg/namespace-demo/blob/master/exercise05/main.go">exercise05</a>.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">addProcessToCgroup</span><span class="params">(filepath <span class="keyword">string</span>, pid <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">file, err := os.OpenFile(filepath, os.O_WRONLY, <span class="number">0644</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(err)</span><br><span class="line">os.Exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> file.Close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> _, err := file.WriteString(fmt.Sprintf(<span class="string">"%d"</span>, pid)); err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"failed to setup cgroup for the container: "</span>, err)</span><br><span class="line">os.Exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">cgroupSetup</span><span class="params">(pid <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, c := <span class="keyword">range</span> []<span class="keyword">string</span>&#123;<span class="string">"cpu"</span>, <span class="string">"memory"</span>&#125; &#123;</span><br><span class="line">cpath := fmt.Sprintf(<span class="string">"/sys/fs/cgroup/%s/mycontainer/"</span>, c)</span><br><span class="line"><span class="keyword">if</span> err := os.MkdirAll(cpath, <span class="number">0644</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">"failed to create cpu cgroup for my container: "</span>, err)</span><br><span class="line">os.Exit(<span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line">addProcessToCgroup(cpath+<span class="string">"cgroup.procs"</span>, pid)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The update to cgroup directories needs root permission, we not only need to use <code>sudo</code> to run the program, but also need to modify the <code>SysProcIDMap</code>, use the command line arguments to setup the UID and GID mapping to the root user &amp; group in the container, in my case it’s the current non-root user I use, so I use <code>-uid=1000 -gid=1000</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo NEWROOT=/home/srjiang/Downloads/alpine_root go run exercise05/main.go -uid=1000 -gid=1000</span><br></pre></td></tr></table></figure><p>After you run the program, you’ll find the process of the program in the <code>/sys/fs/cgroup/cpu/mycontainer/cgroup.procs</code>, it’s up to you to modify the cgroup configuration like CPU limits and memory limits on your own.</p><h2 id="What’s-Next"><a href="#What’s-Next" class="headerlink" title="What’s Next?"></a>What’s Next?</h2><p>We’ve had a container with its own file system, isolated user namespace and PID namespace, and we can limit the resource of this container, next, we want to bring the network to this container.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">Cgroups Linux Manual</a></li><li><a href="https://drill.apache.org/docs/configuring-cgroups-to-control-cpu-usage/#set-the-cpu-limit-for-the-drillbit-service">Drill Set the CPU limit for the Service</a></li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt">Memory Cgroup</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In the &lt;a href=&quot;/programming/linux-namespace-part02-uid-mount/&quot;&gt;previous article&lt;/a&gt;, I did two experiments on what isolation it brings with UID and Mount, this article explains how to limit the container’s resource by using Cgroups, for instance, CPU, memory resources.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="linux" scheme="https://songrgg.github.io/tags/linux/"/>
    
      <category term="namespace" scheme="https://songrgg.github.io/tags/namespace/"/>
    
      <category term="cgroups" scheme="https://songrgg.github.io/tags/cgroups/"/>
    
  </entry>
  
  <entry>
    <title>Linux namespace in Go - Part 2, UID and Mount</title>
    <link href="https://songrgg.github.io/programming/linux-namespace-part02-uid-mount/"/>
    <id>https://songrgg.github.io/programming/linux-namespace-part02-uid-mount/</id>
    <published>2020-05-09T08:27:50.000Z</published>
    <updated>2020-05-09T16:58:41.281Z</updated>
    
    <content type="html"><![CDATA[<p>In the <a href="/programming/linux-namespace-part01-uts-pid/">previous article</a>, I did two experiments on what isolation it brings with PID and UTS, this article explains UID and Mount namespace. </p><a id="more"></a><h2 id="UID-namespace"><a href="#UID-namespace" class="headerlink" title="UID namespace"></a>UID namespace</h2><p>As Linux man page described, </p><blockquote><p>User namespaces isolate security-related identifiers and attributes,<br>in particular, user IDs and group IDs (see credentials(7)), the root directory, keys (see keyrings(7)), and capabilities (see capabilities(7)).  A process’s user and group IDs can be different inside and outside a user namespace.  In particular, a process can have a normal unprivileged user ID outside a user namespace while at the same time having a user ID of 0 inside the namespace; in other words, the process has full privileges for operations inside the user namespace, but is unprivileged for operations outside the namespace.</p></blockquote><p>The key point is that the unprivileged user outside the namespace can be mapped to the root-user inside the new namespace by creating a UID namespace with UID mappings.</p><p>Let’s take an example, on my Ubuntu I want to create a user namespace and use non-root user to run the process, as tested in my previous article, I can’t run the Go program without root permission. But with user namespace, I can map non-root user, in this case, </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> id</span></span><br><span class="line">uid=1000(srjiang) gid=1000(srjiang) groups=1000(srjiang),</span><br></pre></td></tr></table></figure><p>to the root user in the container, </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"os"</span></span><br><span class="line">    <span class="string">"os/exec"</span></span><br><span class="line">    <span class="string">"syscall"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    cmd := exec.Command(<span class="string">"/bin/bash"</span>)</span><br><span class="line"></span><br><span class="line">    cmd.Stdin = os.Stdin</span><br><span class="line">    cmd.Stdout = os.Stdout</span><br><span class="line">    cmd.Stderr = os.Stderr</span><br><span class="line"></span><br><span class="line">    cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123;</span><br><span class="line">        Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWUSER,</span><br><span class="line">        UidMappings: []syscall.SysProcIDMap&#123;</span><br><span class="line">            &#123;</span><br><span class="line">                ContainerID: <span class="number">0</span>,</span><br><span class="line">                HostID:      os.Getuid(),</span><br><span class="line">                Size:        <span class="number">1</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">        GidMappings: []syscall.SysProcIDMap&#123;</span><br><span class="line">            &#123;</span><br><span class="line">                ContainerID: <span class="number">0</span>,</span><br><span class="line">                HostID:      os.Getgid(),</span><br><span class="line">                Size:        <span class="number">1</span>,</span><br><span class="line">            &#125;,</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Printf(<span class="string">"Error running the exec.Command - %s\n"</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>UidMappings</strong> implements the user mapping between host and container, it will map the user id in the host to the user id in the container, the size parameter indicates it’s a contiguous range mapping. If size is 10 and containerID is 0, HostID is 1000, it means 1000-1010 will be mapped to 0-10.</p><p><strong>GidMappings</strong> is the same mechanism as UidMappings, it represents Group id.</p><p>Now, we’re root in the container but non-root in the host, how does the permission look like in the container?</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># id</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root),65534(nogroup)</span><br><span class="line">(container) <span class="comment"># touch /testmypermission</span></span><br><span class="line">touch: cannot touch <span class="string">'/testmypermission'</span>: Permission denied</span><br></pre></td></tr></table></figure><p>You can find out that although I’m the root user in the container, I still don’t have the permission to<br>create a file under root directory, because to the host, I’m actually a non-root user <em>srjiang</em>, I can only manipulate the files that <em>srjiang</em> can. If I run the golang program with sudo, I can operate on the root directory as I wish.</p><h2 id="What-about-ps-ef"><a href="#What-about-ps-ef" class="headerlink" title="What about ps -ef?"></a>What about ps -ef?</h2><p>Remember in the previous article, I left a question how to list the processes only visible within this namespace, here comes the answer: <strong>mount a new /proc</strong>.</p><p>The proc filesystem is a pseudo-filesystem which provides an interface to kernel data structures. It is commonly mounted at /proc.<br>As name explained, the process information is stored under /proc folder, most of the files in the proc filesystem are read-only, they’re dynamic and stored in memory.</p><p>By default, everybody may access all /proc/[pid] directories, besides process information you can also update the process configuration.</p><p>To isolate the container’s process list from the host, we need to mount a new /proc directory instead of sharing the host’s /proc, we can implement this by</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># mount -t proc proc /proc</span></span><br></pre></td></tr></table></figure><p>After mounting the /proc, </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># ps -ef</span></span><br><span class="line">UID         PID   PPID  C STIME TTY          TIME CMD</span><br><span class="line">root          1      0  0 09:08 pts/1    00:00:00 /bin/bash</span><br><span class="line">root         74      1  0 09:56 pts/1    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><p>You’ll only see the processes within the container.</p><h2 id="One-step-forward"><a href="#One-step-forward" class="headerlink" title="One step forward"></a>One step forward</h2><p>For now, we have our own <code>/proc</code> directory that supports standalone process information, but we still share other filesystem with the host, if we want to have a totally fresh filesystem, we need to prepare a new root filesystem and replace the default root filesystem with the new one.</p><h3 id="Download-the-alpine-root-filesystem"><a href="#Download-the-alpine-root-filesystem" class="headerlink" title="Download the alpine root filesystem"></a>Download the alpine root filesystem</h3><p>Alpine OS is popular and secure, tiny OS, I choose it as this experiment’s OS, the files (mini root filesystem) can be downloaded from <a href="https://alpinelinux.org/downloads/">https://alpinelinux.org/downloads/</a>, after that we need to consider how to let the process use this root filesystem, we’ll pivot_root here to change the root filesystem.<br>pivot_root takes two main parameters, the first one is new_root which is where your new root filesystem is, in this case, ~/Downloads/alpine_root/; the second one put_old which is the location you want to put your current root filesystem.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># mount -B ~/Downloads/alpine_root/ ~/Downloads/alpine_root/</span></span><br><span class="line">(container) <span class="comment"># pivot_root ~/Downloads/alpine_root/ ~/Downloads/alpine_root/old_root</span></span><br><span class="line">(container) <span class="comment"># cd /</span></span><br><span class="line">(container) <span class="comment"># ls</span></span><br><span class="line">bin       brook     dev       etc       home      lib       media     mnt       old_root  opt       proc      root      run       sbin      srv       sys       tmp       usr       var</span><br></pre></td></tr></table></figure><p>The reader might be asking “why do we need to mount the new root filesystem again?”,  read the pivot_root man page, you will see new_root must be a path to a mount point, but can’t be “/“, so mounting itself ensures it’s a mount point.</p><p>After you run the commands in the container, you have set the alpine root filesystem now.</p><h3 id="What-about-old-root"><a href="#What-about-old-root" class="headerlink" title="What about old_root?"></a>What about old_root?</h3><p>We almost forget old_root, it’s the previous root filesystem, we don’t want to see it in the container, so let’s umount it.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(container) <span class="comment"># umount /old_root</span></span><br><span class="line">umount: can<span class="string">'t unmount /old_root: Resource busy</span></span><br></pre></td></tr></table></figure><p>Who’s using old_root now? I remember, the shell we use now is still under /old_root, we need to use alpine’s shell, so, the final workflow of the program is:</p><ol><li>mount alpine root filesystem</li><li>mount /proc</li><li>use pivot_root to use alpine</li><li>chdir to the root directory</li><li>umount the old root filesystem</li><li>run the alpine’s shell (or whatever you like)</li></ol><p>For the Golang implementation, it’s here: <a href="https://github.com/songrgg/namespace-demo#mount-a-new-root-filesystem">https://github.com/songrgg/namespace-demo#mount-a-new-root-filesystem</a></p><h2 id="What’s-Next"><a href="#What’s-Next" class="headerlink" title="What’s Next?"></a>What’s Next?</h2><p>Until now, we have setup an Alpine container that has separate UTS, UID, PID namespaces, we’ll create the networking namespace in the next experiment.<br>Also, in the future we can test how to limit the container resource.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://man7.org/linux/man-pages/man5/proc.5.html">Linux Manual - proc</a><br><a href="https://www.slashroot.in/proc-file-system-linux-explained">Linux /proc explained</a><br><a href="https://linux.die.net/man/8/pivot_root">Pivot_root</a><br><a href="http://man7.org/linux/man-pages/man2/pivot_root.2.html">Pivot_root2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;In the &lt;a href=&quot;/programming/linux-namespace-part01-uts-pid/&quot;&gt;previous article&lt;/a&gt;, I did two experiments on what isolation it brings with PID and UTS, this article explains UID and Mount namespace. &lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="linux" scheme="https://songrgg.github.io/tags/linux/"/>
    
      <category term="namespace" scheme="https://songrgg.github.io/tags/namespace/"/>
    
  </entry>
  
  <entry>
    <title>Linux namespace in Go - Part 1, UTS and PID</title>
    <link href="https://songrgg.github.io/programming/linux-namespace-part01-uts-pid/"/>
    <id>https://songrgg.github.io/programming/linux-namespace-part01-uts-pid/</id>
    <published>2020-05-02T14:27:50.000Z</published>
    <updated>2020-05-09T16:58:21.648Z</updated>
    
    <content type="html"><![CDATA[<p>This article starts some <a href="https://github.com/songrgg/namespace-demo">Golang experiments</a> on Linux namespace and provides context for Container technology. Linux namespace is an important foundation of container technology, it provides lightweight isolation between processes with Linux kernel support, therefore, different services can share the same machine with better resource utilization, great security.</p><a id="more"></a><h2 id="Linux-namespace"><a href="#Linux-namespace" class="headerlink" title="Linux namespace"></a>Linux namespace</h2><p>There’s a definition from Linux manual introducing Linux namespace:</p><blockquote><p>A namespace wraps a global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. Changes to the global resource are visible to other processes that are members of the namespace, but are invisible to other processes.</p></blockquote><p>So, Linux namespace is the key that we can control the resources the processes can access.</p><h3 id="Namespace-types"><a href="#Namespace-types" class="headerlink" title="Namespace types"></a>Namespace types</h3><p>What kind of isolation could we control is decided by the namespace types.</p><ul><li>UTS<br>Hostname and NIS domain name</li><li>Cgroup<br>Controls the system resources (like CPU, Memory…) the process can use.</li><li>IPC<br>POSIX message queues</li><li>Network<br>Network devices, stacks, ports, etc.</li><li>Mount<br>Mount points</li><li>PID<br>Process IDs</li><li>Time<br>Boot and monotonic clocks</li><li>User<br>User and group IDs</li></ul><h2 id="“Go”-through-these-types"><a href="#“Go”-through-these-types" class="headerlink" title="“Go” through these types"></a>“Go” through these types</h2><p>Note that Linux namespace is only available in Linux distributions, I use Ubuntu 20.04 and Golang 1.14.2 here to run the experiments. If you’re using other OS, you might find the Linux namespace libraries missing, go and find a Linux machine and Ubuntu is recommended.</p><p><strong>Note: The experiments code can be found in <a href="https://github.com/songrgg/namespace-demo">https://github.com/songrgg/namespace-demo</a></strong></p><h3 id="UTS-Namespace"><a href="#UTS-Namespace" class="headerlink" title="UTS Namespace"></a>UTS Namespace</h3><p>UTS will isolate the hostname for the forked process from its caller.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// folder v1</span></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"os"</span></span><br><span class="line"><span class="string">"os/exec"</span></span><br><span class="line"><span class="string">"syscall"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">exec.Command(<span class="string">"/bin/bash"</span>)</span><br><span class="line">cmd := exec.Cmd&#123;</span><br><span class="line">Path:   <span class="string">"/bin/bash"</span>,</span><br><span class="line">Stdin:  os.Stdin,</span><br><span class="line">Stdout: os.Stdout,</span><br><span class="line">Stderr: os.Stderr,</span><br><span class="line">SysProcAttr: &amp;syscall.SysProcAttr&#123;</span><br><span class="line">Cloneflags: syscall.CLONE_NEWUTS,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>This script needs <code>sudo</code> permission, run <code>sudo go run main.go</code> and it will create a new bash process with a new UTS namespace, you could modify hostname within this namespace and it won’t change the outside’s hostname.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[sojiang@ namespace-demo]$ hostname</span><br><span class="line">sojiang.local</span><br><span class="line">[sojiang@ namespace-demo]$ sudo go run exercise01/main.go</span><br><span class="line">[root@ namespace-demo]<span class="comment"># hostname</span></span><br><span class="line">sojiang.local</span><br><span class="line">[root@ namespace-demo]<span class="comment"># hostname test.local</span></span><br><span class="line">[root@ namespace-demo]<span class="comment"># hostname</span></span><br><span class="line">test.local</span><br><span class="line">[root@ namespace-demo]<span class="comment"># exit</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line">[sojiang@ namespace-demo]$ hostname</span><br><span class="line">sojiang.local</span><br></pre></td></tr></table></figure><h3 id="PID-namespace"><a href="#PID-namespace" class="headerlink" title="PID namespace"></a><a href="http://man7.org/linux/man-pages/man7/pid_namespaces.7.html">PID namespace</a></h3><p>PID namespace would create a new namespace for the process where the process ID is the same as the parent process, but note that you can only operate the processes under your namespace and can’t operate the processes in the parent namespace, in the opposite, the parent namespace has permission to operate the processes under the child namespaces.</p><p>Create a PID namespace simply by adding a <code>CLONE_NEWPID</code> flag:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SysProcAttr: &amp;syscall.SysProcAttr&#123;</span><br><span class="line">    Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID,</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>Run the process again, </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[sojiang@ namespace-demo]$ sudo go run exercise02/main.go</span><br><span class="line">[root@ namespace-demo]$ ps -ef</span><br><span class="line">sojiang  6820  4062 0 06:44 ? /bin/zsh -i</span><br><span class="line">root     7561  ... sudo go run exercise02/main.go</span><br><span class="line">[root@ namespace-demo]$ <span class="built_in">kill</span> -9 6820</span><br><span class="line">bash: <span class="built_in">kill</span>: (6820) - No such process</span><br></pre></td></tr></table></figure><p>In the <code>ps -ef</code> output, we could see <code>zsh</code> which runs in the parent namespace and <code>go run exercise02/main.go</code> is running in the process’s namespace. We call the parent namespace <code>P</code> and the child namespace <code>C</code>, if we run <code>sleep 100</code> in <code>P</code>, use <code>ps -ef</code> to get the process id and run <code>kill -9 &lt;process-id&gt;</code> in <code>C</code>, it will output “process not exist”. In the opposite, we could kill the process in <code>C</code>, that’s because the process visibility is in a single direction, only parent namespace could see all the processes in both <code>P</code> and <code>C</code>.</p><p>Like the following picture, pid 1 is in the parent namespace of pid Namespace x, so pid 1 could see all the processes, pid 3 could only see pid 3, pid 5 and pid 5.<br><img src="/images/linux_namespace_pid.webp" alt="Process hierachy"></p><h2 id="What’s-next"><a href="#What’s-next" class="headerlink" title="What’s next?"></a>What’s next?</h2><p>Here I did experiments on Linux UTS and PID namespaces, we know the isolation mechanism of them. I still have several questions,</p><ul><li>How to run the program as other user instead of root?</li><li>I can still see the process list by <code>ps -ef</code> in the child namespace, however, most of the processes are in the parent namespace, there’s no need for me to see them, how to hide them or have my own process list?</li></ul><p>The answer is in the <a href="/programming/linux-namespace-part02-uid-mount/">Linux namespace in Go - Part 2, UID and Mount</a>.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://medium.com/@teddyking/linux-namespaces-850489d3ccf">Linux Namespaces by Ed King</a></li><li><a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">Linux Programmer’s Manual Namespaces(7)</a></li><li><a href="https://golang.org/pkg/os/exec/">Golang exec package</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article starts some &lt;a href=&quot;https://github.com/songrgg/namespace-demo&quot;&gt;Golang experiments&lt;/a&gt; on Linux namespace and provides context for Container technology. Linux namespace is an important foundation of container technology, it provides lightweight isolation between processes with Linux kernel support, therefore, different services can share the same machine with better resource utilization, great security.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="linux" scheme="https://songrgg.github.io/tags/linux/"/>
    
      <category term="namespace" scheme="https://songrgg.github.io/tags/namespace/"/>
    
  </entry>
  
  <entry>
    <title>Setup OAuth2 client for Django in 5 minutes</title>
    <link href="https://songrgg.github.io/programming/django-oauth-client-setup/"/>
    <id>https://songrgg.github.io/programming/django-oauth-client-setup/</id>
    <published>2020-04-12T22:00:00.000Z</published>
    <updated>2020-04-13T10:20:45.022Z</updated>
    
    <content type="html"><![CDATA[<p>This article explains how to setup OAuth2 client for Django in 5 minutes, it’s used for Web service which requires user to login by OAuth2, especially for those who are familiar with OAuth2.0 but unfamiliar with Django.</p><p>If you have no idea about OAuth2.0 workflow, please visit <a href="https://oauth.net/2/">OAuth2 net</a></p><a id="more"></a><p>The example here introduces Web service implements the OAuth2 workflow, the user must login first then he can see the web content. The Web Framework is Python Django, the OAuth library we use is <code>Authlib==0.14.1</code>. It supports user session persistence and auto-refresh access_token.</p><h2 id="OAuth-configuration"><a href="#OAuth-configuration" class="headerlink" title="OAuth configuration"></a>OAuth configuration</h2><p>If we consider using Github as the authorization server, first you need to <a href="https://github.com/settings/applications/new">register a new OAuth application in Github</a>, then you’ll have you credentials.<br>Secondly, setup OAuth settings in <code>settings.py</code>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># OAuth Settings</span></span><br><span class="line">OAUTH_URL_WHITELISTS = []</span><br><span class="line"></span><br><span class="line">OAUTH_CLIENT_NAME = <span class="string">'github'</span></span><br><span class="line"></span><br><span class="line">OAUTH_CLIENT = &#123;</span><br><span class="line">    <span class="string">'client_id'</span>: <span class="string">''</span>,</span><br><span class="line">    <span class="string">'client_secret'</span>: <span class="string">''</span>,</span><br><span class="line">    <span class="string">'access_token_url'</span>: <span class="string">'https://github.com/login/oauth/access_token'</span>,</span><br><span class="line">    <span class="string">'authorize_url'</span>: <span class="string">'https://github.com/login/oauth/authorize'</span>,</span><br><span class="line">    <span class="string">'api_base_url'</span>: <span class="string">'https://api.github.com/'</span>,</span><br><span class="line">    <span class="string">'redirect_uri'</span>: <span class="string">'https://songrgg.com/oauth/callback'</span>,</span><br><span class="line">    <span class="string">'client_kwargs'</span>: &#123;</span><br><span class="line">        <span class="string">'scope'</span>: <span class="string">'profile email'</span>,</span><br><span class="line">        <span class="string">'token_placement'</span>: <span class="string">'header'</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">'userinfo_endpoint'</span>: <span class="string">'user'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Pay attention, the redirect uri should be the one your server will use to fetch access token and setup user session, I setup <code>/oauth/callback</code> here, the logic will be introduced in middleware.</p><h2 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h2><p>For each user request, the server will check user’s session and see if user has logined, in both Django or other Web frameworks, we could setup middleware to handle user requests.</p><h3 id="Initialize-the-OAuth-client"><a href="#Initialize-the-OAuth-client" class="headerlink" title="Initialize the OAuth client"></a>Initialize the OAuth client</h3><p>Use the OAuth configuration to initialize the OAuth client.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_token</span><span class="params">(token, refresh_token, access_token)</span>:</span></span><br><span class="line">    request.session[<span class="string">'token'</span>] = token</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">sso_client = self.oauth.register(</span><br><span class="line">    settings.OAUTH_CLIENT_NAME, overwrite=<span class="literal">True</span>, **settings.OAUTH_CLIENT, update_token=update_token</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>update_token</code> parameter is used to refresh the access_token when it’s expired.</p><h3 id="Process-OAuth-callback"><a href="#Process-OAuth-callback" class="headerlink" title="Process OAuth callback"></a>Process OAuth callback</h3><p>After the user authorizes the login, our server should fetch the access_token from the authorization server and store it in user session.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> request.path.startswith(<span class="string">'/oauth/callback'</span>):</span><br><span class="line">    self.clear_session(request)</span><br><span class="line">    request.session[<span class="string">'token'</span>] = sso_client.authorize_access_token(request)</span><br><span class="line">    <span class="keyword">if</span> self.get_current_user(sso_client, request) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        redirect_uri = request.session.pop(<span class="string">'redirect_uri'</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> redirect_uri <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> redirect(redirect_uri)</span><br><span class="line">        <span class="keyword">return</span> redirect(views.index)</span><br></pre></td></tr></table></figure><h3 id="Fetch-user-info"><a href="#Fetch-user-info" class="headerlink" title="Fetch user info"></a>Fetch user info</h3><p>After the <code>access_token</code> is ready, fetch the user info from the resource API, otherwise redirect user to the authorization page.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_current_user</span><span class="params">(sso_client, request)</span>:</span></span><br><span class="line">    token = request.session.get(<span class="string">'token'</span>, <span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">if</span> token <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> <span class="string">'access_token'</span> <span class="keyword">not</span> <span class="keyword">in</span> token:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> OAuth2Token.from_dict(token).is_expired() <span class="keyword">and</span> <span class="string">'user'</span> <span class="keyword">in</span> request.session:</span><br><span class="line">        <span class="keyword">return</span> request.session[<span class="string">'user'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = sso_client.get(settings.OAUTH_CLIENT[<span class="string">'userinfo_endpoint'</span>], token=OAuth2Token(token))</span><br><span class="line">        <span class="keyword">if</span> res.ok:</span><br><span class="line">            request.session[<span class="string">'user'</span>] = res.json()</span><br><span class="line">            <span class="keyword">return</span> res.json()</span><br><span class="line">    <span class="keyword">except</span> OAuthError <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><h3 id="Put-the-middleware"><a href="#Put-the-middleware" class="headerlink" title="Put the middleware"></a>Put the middleware</h3><p>In <code>settings.py</code>, put the middleware class to the array.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MIDDLEWARE = [</span><br><span class="line">    <span class="string">'oauth_demo.middleware.oauth.OAuthMiddleware'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h2><p>We use Django session module and the default storage is <code>sqlite3</code>, you can simply change it to other backends like <code>redis</code> by modifying <code>settings.py</code>.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>The full repository is located at <a href="https://github.com/songrgg/oauth-demo">https://github.com/songrgg/oauth-demo</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article explains how to setup OAuth2 client for Django in 5 minutes, it’s used for Web service which requires user to login by OAuth2, especially for those who are familiar with OAuth2.0 but unfamiliar with Django.&lt;/p&gt;
&lt;p&gt;If you have no idea about OAuth2.0 workflow, please visit &lt;a href=&quot;https://oauth.net/2/&quot;&gt;OAuth2 net&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="django" scheme="https://songrgg.github.io/tags/django/"/>
    
      <category term="oauth2" scheme="https://songrgg.github.io/tags/oauth2/"/>
    
  </entry>
  
  <entry>
    <title>InfluxDB command cheatsheet</title>
    <link href="https://songrgg.github.io/operation/influxdb-command-cheatsheet/"/>
    <id>https://songrgg.github.io/operation/influxdb-command-cheatsheet/</id>
    <published>2020-03-17T23:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.406Z</updated>
    
    <content type="html"><![CDATA[<p>This article is InfluxDB command cheatsheet about how to interact with influxDB server and query the metrics. The InfluxDB version I tested is <a href="https://docs.influxdata.com/influxdb/v1.7/">v1.7.10</a></p><a id="more"></a><h2 id="Connect-amp-Start"><a href="#Connect-amp-Start" class="headerlink" title="Connect &amp; Start"></a>Connect &amp; Start</h2><p>Connect to InfluxDB server and select the database.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ influx -host 127.0.0.1 -port 8086</span><br><span class="line">&gt; SHOW DATABASES;</span><br><span class="line">name: databases</span><br><span class="line">name</span><br><span class="line">----</span><br><span class="line">_internal</span><br><span class="line">&gt; CREATE DATABASE <span class="built_in">test</span>;</span><br><span class="line">&gt; USE <span class="built_in">test</span>;</span><br><span class="line">Using database <span class="built_in">test</span></span><br><span class="line">&gt; --- fill the database with some points</span><br><span class="line">&gt; INSERT temperature,machine=unit42,<span class="built_in">type</span>=assembly external=25,internal=37</span><br><span class="line">&gt; INSERT temperature,machine=unit43,<span class="built_in">type</span>=assembly external=25,internal=37</span><br><span class="line">&gt; INSERT temperature,machine=unit43,<span class="built_in">type</span>=not_assembly external=25,internal=37</span><br></pre></td></tr></table></figure><h2 id="Show-everything"><a href="#Show-everything" class="headerlink" title="Show everything"></a>Show everything</h2><p><strong>Show</strong> is a helpful command that will help you find all the schemas you may use.</p><h3 id="Show-common-information"><a href="#Show-common-information" class="headerlink" title="Show common information"></a>Show common information</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- list all databases</span><br><span class="line">&gt; SHOW DATABASES</span><br><span class="line">&gt; --- show all measurements</span><br><span class="line">&gt; SHOW MEASUREMENTS</span><br><span class="line">&gt; --- show measurements <span class="built_in">where</span> machine tag = <span class="string">'unit42'</span></span><br><span class="line">&gt; SHOW MEASUREMENTS WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- show measurements that start with <span class="string">'temp'</span></span><br><span class="line">&gt; SHOW MEASUREMENTS WITH MEASUREMENT =~ /temp.*/</span><br><span class="line">&gt; --- show all running queries</span><br><span class="line">&gt; SHOW QUERIES</span><br><span class="line">&gt; --- show all retention policies on a database</span><br><span class="line">&gt; SHOW RETENTION POLICIES ON <span class="string">"test"</span></span><br><span class="line">&gt; --- show all users <span class="keyword">in</span> InfluxDB</span><br><span class="line">&gt; SHOW USERS</span><br></pre></td></tr></table></figure><h3 id="Show-series"><a href="#Show-series" class="headerlink" title="Show series"></a>Show series</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- show all series</span><br><span class="line">&gt; show series from temperature</span><br><span class="line">key</span><br><span class="line">---</span><br><span class="line">temperature,machine=unit42,<span class="built_in">type</span>=assembly</span><br><span class="line">temperature,machine=unit43,<span class="built_in">type</span>=assembly</span><br><span class="line">temperature,machine=unit43,<span class="built_in">type</span>=not_assembly</span><br><span class="line">&gt; --- show series from machine unit42</span><br><span class="line">&gt; SHOW SERIES FROM temperature WHERE machine = <span class="string">'unit42'</span></span><br><span class="line">key</span><br><span class="line">---</span><br><span class="line">temperature,machine=unit42,<span class="built_in">type</span>=assembly</span><br><span class="line">&gt; -- show estimated cardinality of the series on current database</span><br><span class="line">&gt; SHOW SERIES CARDINALITY</span><br><span class="line">-- show estimated cardinality of the series on specified database</span><br><span class="line">&gt; SHOW SERIES CARDINALITY ON mydb</span><br><span class="line">cardinality estimation</span><br><span class="line">----------------------</span><br><span class="line">3</span><br></pre></td></tr></table></figure><h3 id="Show-tag"><a href="#Show-tag" class="headerlink" title="Show tag"></a>Show tag</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- show tag keys</span><br><span class="line">&gt; SHOW TAG KEYS</span><br><span class="line">name: temperature</span><br><span class="line">tagKey</span><br><span class="line">------</span><br><span class="line">machine</span><br><span class="line"><span class="built_in">type</span></span><br><span class="line">&gt; --- show all tag keys from the temperature measurement</span><br><span class="line">&gt; SHOW TAG KEYS FROM <span class="string">"temperature"</span></span><br><span class="line">&gt; --- show all tag keys <span class="built_in">where</span> the machine key = <span class="string">'unit42'</span></span><br><span class="line">&gt; SHOW TAG KEYS WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- show all tag values across all measurements <span class="keyword">for</span> the machine tag</span><br><span class="line">&gt; SHOW TAG VALUES WITH KEY = <span class="string">"machine"</span></span><br><span class="line">name: temperature</span><br><span class="line">key     value</span><br><span class="line">---     -----</span><br><span class="line">machine unit42</span><br><span class="line">machine unit43</span><br><span class="line">&gt; --- show tag values <span class="keyword">for</span> a specific database and measurement</span><br><span class="line">&gt; SHOW TAG VALUES ON <span class="built_in">test</span> FROM temperature WITH KEY = <span class="string">"machine"</span></span><br></pre></td></tr></table></figure><h3 id="Show-field"><a href="#Show-field" class="headerlink" title="Show field"></a>Show field</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; SHOW FIELD KEYS ON <span class="built_in">test</span></span><br><span class="line">name: temperature</span><br><span class="line">fieldKey fieldType</span><br><span class="line">-------- ---------</span><br><span class="line">external <span class="built_in">float</span></span><br><span class="line">internal <span class="built_in">float</span></span><br></pre></td></tr></table></figure><h3 id="Show-cardinality"><a href="#Show-cardinality" class="headerlink" title="Show cardinality"></a>Show cardinality</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; SHOW MEASUREMENT CARDINALITY</span><br><span class="line">cardinality estimation</span><br><span class="line">----------------------</span><br><span class="line">1</span><br><span class="line">&gt; SHOW MEASUREMENT EXACT CARDINALITY ON <span class="built_in">test</span></span><br><span class="line">count</span><br><span class="line">-----</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h2 id="Measurement"><a href="#Measurement" class="headerlink" title="Measurement"></a>Measurement</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- create a temperature point</span><br><span class="line">&gt; INSERT temperature,machine=unit42,<span class="built_in">type</span>=assembly external=26,internal=38</span><br><span class="line">&gt; --- select temperature <span class="keyword">for</span> unit42</span><br><span class="line">&gt; SELECT * FROM temperature WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- select specific fields and tags from measurement, NOTE: at least one field must be included</span><br><span class="line">&gt; SELECT <span class="string">"internal"</span>::field, <span class="string">"machine"</span>::tag FROM temperature WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- delete metrics from temperature measurement</span><br><span class="line">&gt; DELETE FROM <span class="string">"temperature"</span> WHERE time &lt; <span class="string">'2000-01-01T00:00:00Z'</span></span><br><span class="line">&gt; --- drop the temperature measurement</span><br><span class="line">&gt; DROP MEASUREMENT <span class="string">"temperature"</span></span><br></pre></td></tr></table></figure><h2 id="Query-analysis"><a href="#Query-analysis" class="headerlink" title="Query analysis"></a>Query analysis</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- explain the logic behind the query</span><br><span class="line">&gt; EXPLAIN SELECT * FROM temperature</span><br><span class="line">QUERY PLAN</span><br><span class="line">----------</span><br><span class="line">EXPRESSION: &lt;nil&gt;</span><br><span class="line">AUXILIARY FIELDS: external::<span class="built_in">float</span>, internal::<span class="built_in">float</span>, machine::tag, <span class="built_in">type</span>::tag</span><br><span class="line">NUMBER OF SHARDS: 1</span><br><span class="line">NUMBER OF SERIES: 3</span><br><span class="line">CACHED VALUES: 0</span><br><span class="line">NUMBER OF FILES: 6</span><br><span class="line">NUMBER OF BLOCKS: 6</span><br><span class="line">SIZE OF BLOCKS: 204</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.influxdata.com/influxdb/v1.7/query_language/spec/#query-engine-internals">InfluxDB 1.7 Query language</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article is InfluxDB command cheatsheet about how to interact with influxDB server and query the metrics. The InfluxDB version I tested is &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.7/&quot;&gt;v1.7.10&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="influxdb" scheme="https://songrgg.github.io/tags/influxdb/"/>
    
  </entry>
  
  <entry>
    <title>how to build the smallest docker image as fast as you can</title>
    <link href="https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/"/>
    <id>https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/</id>
    <published>2020-03-15T19:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.404Z</updated>
    
    <content type="html"><![CDATA[<p>I’ll use an example to introduce how to build the smallest docker image to your best, a light image will accelerate image rollout and the fast build process will speed up your development cycle.</p><a id="more"></a><h2 id="A-Golang-sample"><a href="#A-Golang-sample" class="headerlink" title="A Golang sample"></a>A Golang sample</h2><p>It’s quite common that we use golang to implement microservice, for example tens of golang service docker images are deployed to the Kubernetes.</p><p>Consider we need to make our first golang service image, it runs the following code as an HTTP server.</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"net/http"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  http.HandleFunc(<span class="string">"/"</span>, test)</span><br><span class="line">  http.ListenAndServe(<span class="string">":8080"</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">  w.Header().Set(<span class="string">"Service"</span>, <span class="string">"Test"</span>)</span><br><span class="line">  w.WriteHeader(<span class="number">200</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Docker-it"><a href="#Docker-it" class="headerlink" title="Docker it!"></a>Docker it!</h3><p>The intuitive solution is to run <code>go run main.go</code> in the docker, so let’s use golang image as a base image.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span>.<span class="number">0</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/songrgg/testservice/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [ <span class="string">"go"</span>, <span class="string">"run"</span>, <span class="string">"main.go"</span> ]</span></span><br></pre></td></tr></table></figure><p>Run <code>docker build .</code> and it shows</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/4 : FROM golang:1.14.0-alpine</span><br><span class="line"> ---&gt; 51e47ee4db58</span><br><span class="line">Step 2/4 : WORKDIR /go/src/github.com/songrgg/testservice/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8dc325ca7ca6</span><br><span class="line">Step 3/4 : COPY main.go .</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; c46c5f5bfda8</span><br><span class="line">Step 4/4 : CMD [ <span class="string">"go"</span>, <span class="string">"run"</span>, <span class="string">"main.go"</span> ]</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; acc5a6d462f5</span><br><span class="line">Successfully built acc5a6d462f5</span><br><span class="line"></span><br><span class="line">$ docker image inspect acc5a6d462f5 --format=<span class="string">'&#123;&#123;.Size&#125;&#125;'</span></span><br><span class="line">369193951</span><br></pre></td></tr></table></figure><p>It’s 369193951 bytes near <strong>370MB</strong>.</p><h3 id="Reduce-the-unnecessary-files"><a href="#Reduce-the-unnecessary-files" class="headerlink" title="Reduce the unnecessary files"></a>Reduce the unnecessary files</h3><p>Golang is a compilation language which can be packed into a binary, we can reduce the size by only putting the binary into the image.</p><p>We know that the latest docker supports multi-stage builds which can eliminate the intermediate layers effectively, the revised dockerfile looks like this:</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span>.<span class="number">0</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/songrgg/testservice/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:latest</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache add ca-certificates</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/github.com/songrgg/testservice/app .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./app"</span>]</span></span><br></pre></td></tr></table></figure><p>Let’s see the layers it generates.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ docker build .</span><br><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/9 : FROM golang:1.14.0-alpine</span><br><span class="line"> ---&gt; 51e47ee4db58</span><br><span class="line">Step 2/9 : WORKDIR /go/src/github.com/songrgg/testservice/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8dc325ca7ca6</span><br><span class="line">Step 3/9 : COPY main.go .</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; c46c5f5bfda8</span><br><span class="line">Step 4/9 : RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> be3bdce1ec48</span><br><span class="line">Removing intermediate container be3bdce1ec48</span><br><span class="line"> ---&gt; 9c3470f9e73d</span><br><span class="line">Step 5/9 : FROM alpine:latest</span><br><span class="line"> ---&gt; 053cde6e8953</span><br><span class="line">Step 6/9 : RUN apk --no-cache add ca-certificates</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 6acd18e2d2ba</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/1) Installing ca-certificates (20161130-r3)</span><br><span class="line">Executing busybox-1.26.2-r7.trigger</span><br><span class="line">Executing ca-certificates-20161130-r3.trigger</span><br><span class="line">OK: 5 MiB <span class="keyword">in</span> 12 packages</span><br><span class="line">Removing intermediate container 6acd18e2d2ba</span><br><span class="line"> ---&gt; 7b4ee3222013</span><br><span class="line">Step 7/9 : WORKDIR /root/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 336a8a2115a6</span><br><span class="line">Removing intermediate container 336a8a2115a6</span><br><span class="line"> ---&gt; 77fa1196ab2f</span><br><span class="line">Step 8/9 : COPY --from=0 /go/src/github.com/songrgg/testservice/app .</span><br><span class="line"> ---&gt; c6bc47f614af</span><br><span class="line">Step 9/9 : CMD [<span class="string">"./app"</span>]</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> f77053027c4b</span><br><span class="line">Removing intermediate container f77053027c4b</span><br><span class="line"> ---&gt; d327f978f1d8</span><br><span class="line">Successfully built d327f978f1d8</span><br><span class="line"></span><br><span class="line">$ docker inspect d327f978f1d8 --format=<span class="string">'&#123;&#123;.Size&#125;&#125;'</span></span><br><span class="line">11924648</span><br></pre></td></tr></table></figure><p>We could notice there are several intermediate containers removed, they’re layers from the first stage and prepare the executable for the second stage.</p><p>Most importantly, the docker image size is below <strong>12MB</strong>.</p><p>The most important factor is we changed the FROM image to alpine which is only <strong>4.2MB</strong>, so the extra size is almost the size of the golang process.</p><h3 id="From-scratch"><a href="#From-scratch" class="headerlink" title="From scratch?"></a>From scratch?</h3><p>Yeah, the base image could be smaller, <code>FROM scratch</code> is a base image that will make the next command to be the first layer in your image.</p><p>I changed the <code>FROM alpine:latest</code> to <code>FROM scratch</code>, the image size is <strong>7MB</strong> now, but I would suggest using alpine because it’ll be hard for you in scratch if you want to debug within the container. So you’ll need a balance between the image size and functionality :)</p><h2 id="Some-pitfalls-you-may-face"><a href="#Some-pitfalls-you-may-face" class="headerlink" title="Some pitfalls you may face"></a>Some pitfalls you may face</h2><h3 id="Unnecessary-large-build-context"><a href="#Unnecessary-large-build-context" class="headerlink" title="Unnecessary large build context"></a>Unnecessary large build context</h3><p>Docker build will send the build context to docker daemon at first, the context is default to the current directory, so please be sure the files in the current directory is necessary or is small enough. If the file size is big, it will affect docker build speed terribly.</p><h3 id="Wrong-command-order"><a href="#Wrong-command-order" class="headerlink" title="Wrong command order"></a>Wrong command order</h3><p>Just remember to put the stable layers before the changeable layers, because docker will cache the layers if they are not changed, it’s calculated by the hash value of their content.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> changeable.txt .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ...</span></span><br></pre></td></tr></table></figure><p>In the above example, every time the changeable.txt is changed, it will rerun every commands after it and waste time doing the things it could prevent. Just turn to the following form.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ...</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> changeable.txt .</span></span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Best practises for writing Dockerfile</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ll use an example to introduce how to build the smallest docker image to your best, a light image will accelerate image rollout and the fast build process will speed up your development cycle.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="docker" scheme="https://songrgg.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>How to check and monitor SSL certificates expiration with Telegraf</title>
    <link href="https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/"/>
    <id>https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/</id>
    <published>2020-02-11T21:11:50.000Z</published>
    <updated>2020-03-30T13:15:06.398Z</updated>
    
    <content type="html"><![CDATA[<html><head></head><body><p>As a developer or operator of a Website, the certificate expiration could happen and make the services not work. I’ll introduce how to monitor certificates like SSL,JKS,P12 using Telegraf.</p><p>Certificates are broadly used for security reasons, they can be used within internal service or public service communication. The most common certificate is TLS used for verifying the identity of the HTTPS service. To increase security, the certificate will not be always valid because of expiration. To prevent the certificate expiry, we should rotate them periodically and meanwhile monitor them and alert if expired. Telegraf is a popular metric collecting tool to implement this.</p><a id="more"></a><h2 id="Overview-for-certificate-types"><a href="#Overview-for-certificate-types" class="headerlink" title="Overview for certificate types"></a>Overview for certificate types</h2><ol><li>.csr<br>Certificate Signing Request used to request a certificate from the certificate authority.</li><li>.pem<br>This is a container format that may include just the public certificate or may include an entire certificate chain including public key, private key, and root certificates. Confusingly, it may also encode a CSR (e.g. as used here) as the PKCS10 format can be translated into PEM.</li><li>.key<br>This is a PEM formatted file containing just the private-key of a specific certificate and is merely a conventional name and not a standardized one.</li><li>.pkcs12 .pfx .p12<br>This is a passworded container format that contains both public and private certificate pairs. Unlike .pem files, this container is fully encrypted. Openssl can turn this into a .pem file with both public and private keys.</li><li>.cert .cer .crt<br>A .pem (or rarely .der) formatted file with a different extension, one that is recognized by Windows Explorer as a certificate, which .pem is not.</li><li>.jks<br>A Java KeyStore (JKS) is a repository of security certificates – either authorization certificates or public key certificates – plus corresponding private keys, used for instance in SSL encryption.</li></ol><h2 id="Check-certificate-expiry-time"><a href="#Check-certificate-expiry-time" class="headerlink" title="Check certificate expiry time"></a>Check certificate expiry time</h2><ol><li><p>check the JKS expiry time</p> <figure class="highlight bash"><figcaption><span>check_jks.sh</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to check keystore.jks expiry time</span></span><br><span class="line">keytool -list -v -keystore keystore.jks -storepass <span class="string">"pass"</span> | grep until</span><br></pre></td></tr></tbody></table></figure></li><li><p>check the PKCS#12 expiry time</p> <figure class="highlight bash"><figcaption><span>check_p12.sh</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to check certicate.p12 expiry time</span></span><br><span class="line">openssl pkcs12 -<span class="keyword">in</span> certicate.p12 -nokeys | openssl x509 -noout -enddate</span><br></pre></td></tr></tbody></table></figure></li></ol><h2 id="Customize-telegraf-plugin"><a href="#Customize-telegraf-plugin" class="headerlink" title="Customize telegraf plugin"></a>Customize telegraf plugin</h2><p>In this case, we can use a bash script to collect the metrics and output it as <a href="https://docs.influxdata.com/influxdb/v1.7/write_protocols/line_protocol_tutorial/">influxDB line protocol</a>, it does not need you to use influxDB, you can use any kind of monitoring backend that can read from telegraf, for example, Prometheus.</p><p><a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a> is a daemon that can be running on servers to collect system metrics, it supports multiple input plugins to collect metrics. <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec"><code>intput.exec</code></a> is an input plugin which will run the specified script, the output of the script will be treated as a data point.</p><h3 id="Bash-script-to-generate-the-metric"><a href="#Bash-script-to-generate-the-metric" class="headerlink" title="Bash script to generate the metric"></a>Bash script to generate the metric</h3><p>We can write a bash script to generate an influxDB line formatted metric, the script will use <code>openssl</code> to resolve the certificate.</p><ol><li><p>This is a script used to resolve PKCS#12 files.</p> <figure class="highlight bash"><figcaption><span>generate_p12_metric.sh</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">FILE_PATH=<span class="string">"path-to-pkcs#12-cert"</span></span><br><span class="line">P12_UNTIL=$(openssl pkcs12 -<span class="keyword">in</span> <span class="variable">$FILE_PATH</span> -nokeys 2>/dev/null | openssl x509 -text -noout 2>/dev/null | grep After | sed <span class="string">'s/.*After : //'</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># return 1 year when there's no existing file</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$P12_UNTIL</span>"</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$((360*24*60*60)</span>)"</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">P12_UNTIL_EPOCH=$(date +%s --date=<span class="string">"<span class="variable">$P12_UNTIL</span>"</span>)</span><br><span class="line">NOW_EPOCH=$(date +%s)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pkcs12_cert,source=<span class="variable">$FILE_PATH</span> expiry=<span class="variable">$(($P12_UNTIL_EPOCH-$NOW_EPOCH)</span>) <span class="variable">${NOW_EPOCH}</span>000000000"</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>Another script to resolve the JKS file</p> <figure class="highlight bash"><figcaption><span>generate_jks_metric.sh</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">FILE_PATH=<span class="string">"path-to-jks-cert"</span></span><br><span class="line">KEYSTORE_UNTIL=$(<span class="built_in">echo</span> <span class="string">'dummydummy'</span> | keytool -list -v -keystore <span class="variable">$FILE_PATH</span> 2>/dev/null | grep -i Until  | sed <span class="string">'s/.*until: //'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This may be caused by unexistent file, return 1 year to skip checking.</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$KEYSTORE_UNTIL</span>"</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$((360*24*60*60)</span>)"</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">KEYSTORE_UNTIL_EPOCH=$(date +%s --date=<span class="string">"<span class="variable">$KEYSTORE_UNTIL</span>"</span>)</span><br><span class="line">NOW_EPOCH=$(date +%s)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"jks_cert,source=<span class="variable">$FILE_PATH</span> expiry=<span class="variable">$(($KEYSTORE_UNTIL_EPOCH-$NOW_EPOCH)</span>) <span class="variable">${NOW_EPOCH}</span>000000000"</span></span><br></pre></td></tr></tbody></table></figure></li><li><p>X509 Cert<br>There’s an <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/x509_cert">X509 Cert Input Plugin</a> already there.</p></li></ol><h3 id="Telegraf-configuration"><a href="#Telegraf-configuration" class="headerlink" title="Telegraf configuration"></a>Telegraf configuration</h3><p>Put the <code>jks_cert.conf</code> under the telegraf’s configuration folder, restart telegraf and it will take effect.</p><figure class="highlight"><figcaption><span>jks_cert.conf</span></figcaption><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[[inputs.exec]]</span></span><br><span class="line">  commands = [ "/usr/local/bin/jks_certificate_metric.sh" ]</span><br><span class="line"></span><br><span class="line">  data_format = "influx"</span><br></pre></td></tr></tbody></table></figure><h3 id="What’s-next"><a href="#What’s-next" class="headerlink" title="What’s next"></a>What’s next</h3><p>Connect the data Telegraf collected to Time series database like Prometheus, InfluxDB, Graphite, and show them with Grafana.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file">What is a pem file and how does it differ from other OpenSSL generated key files?</a></li><li><a href="https://pingtool.org/openssl-check-p12-expiration-date/">OpenSSL check p12 expiration date</a></li><li><a href="https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file">What is a PEM file and how does it differ from other OpenSSL generated key file</a></li><li><a href="https://en.wikipedia.org/wiki/PKCS_12">pkcs#12</a></li><li><a href="https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs">OpenSSL essentials</a></li><li><a href="https://www.digitalocean.com/community/tutorials/java-keytool-essentials-working-with-java-keystores">Java keytool essentials</a></li><li><a href="https://en.wikipedia.org/wiki/Java_KeyStore">Java KeyStore</a></li></ol></body></html>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;As a developer or operator of a Website, the certificate expiration could happen and make the services not work. I’ll introduce how to monitor certificates like SSL,JKS,P12 using Telegraf.&lt;/p&gt;
&lt;p&gt;Certificates are broadly used for security reasons, they can be used within internal service or public service communication. The most common certificate is TLS used for verifying the identity of the HTTPS service. To increase security, the certificate will not be always valid because of expiration. To prevent the certificate expiry, we should rotate them periodically and meanwhile monitor them and alert if expired. Telegraf is a popular metric collecting tool to implement this.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="certificate" scheme="https://songrgg.github.io/tags/certificate/"/>
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
  </entry>
  
  <entry>
    <title>Practice datacenter failover in production</title>
    <link href="https://songrgg.github.io/operation/practice-datacenter-failover-in-production/"/>
    <id>https://songrgg.github.io/operation/practice-datacenter-failover-in-production/</id>
    <published>2019-12-12T23:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.413Z</updated>
    
    <content type="html"><![CDATA[<p>Distributed system is like human body, it will have issues and break. There’s a theory that we feed it with issues deliberately and constantly, the body will be more and more stable and robust. It’s the same to system, put some issues to datacenters and let them failover automatically.</p><a id="more"></a><h3 id="Multiple-data-centers"><a href="#Multiple-data-centers" class="headerlink" title="Multiple data centers"></a>Multiple data centers</h3><p>Companies use data center redundancy to implement service’s high availability, there will be multiple data centers existing with 3 main deployments:</p><ol><li>Disaster Recovery<br>You will have your live traffic served in the primary data center, meanwhile disaster recovery data center is a backup to recover when the primary is down. Usually, it doesn’t allow you to run normal operations in the disaster recovery one.</li><li>Hot Standby<br>The primary data center is taking traffic, the hot standby data center is almost equivalent to primary but doesn’t take traffic. You can switch to hot standby anytime the primary data center is down.</li><li>Live traffic handling<br>There are multiple data centers and they’re taking traffic simultaneously.</li></ol><h3 id="What-is-DC-failover"><a href="#What-is-DC-failover" class="headerlink" title="What is DC failover?"></a>What is DC failover?</h3><p>When dc ( data center ) failure happens, the most emergent thing is to use the backup dc to replace the primary one and ensures the business keeps running, so the technical team will failover the data center to backup one.</p><!-- more --><h3 id="Why-do-we-need-to-do-failover-often"><a href="#Why-do-we-need-to-do-failover-often" class="headerlink" title="Why do we need to do failover often?"></a>Why do we need to do failover often?</h3><p>In the deployments mentioned before, there will be one or more data centers serving user, once the primary one is down the backup one needs to take over as soon as possible, but it’s not often that the primary data center is down, as the time flies, likely, backup datacenter cannot replace the primary or is hard to replace.<br>To keep the backup dc up-to-date, we should do dc failover often regardless manually or automatically.</p><h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><h3 id="Define-the-impact"><a href="#Define-the-impact" class="headerlink" title="Define the impact"></a>Define the impact</h3><p>Service is always for customers, although failover is a long-term project that will improve the service’s availability, it’s better not to interrupt the customer’s experience all of a sudden, so according to different company’s considerations, they need to define the impact they can undertake.</p><h3 id="Define-the-scope"><a href="#Define-the-scope" class="headerlink" title="Define the scope"></a>Define the scope</h3><p>After the company decides to practice data center failover in production, there will be a lot of questions to answer, “What’s the scale of this failover?”, “Is it global or partial?”, “What consequences can I bear or how much budget do we have?”, “who should participate in”…<br>Such questions can define the scope of the failover, how many business lines should participate in it, how many teams, how many people will join.</p><h3 id="Define-the-goal"><a href="#Define-the-goal" class="headerlink" title="Define the goal"></a>Define the goal</h3><p>Also, define the goal clearly, it’s a long term project that ensures there will be always multiple available data centers online, this failover is the first time and will repeat very soon, finally, it’ll be continuous and automatic like chaos engineering.</p><h3 id="Team-as-unit"><a href="#Team-as-unit" class="headerlink" title="Team as unit"></a>Team as unit</h3><p>Every team involved should take care of the servers, services… they need to failover when the failover day comes, the team is the minimal unit.</p><h3 id="Deadline"><a href="#Deadline" class="headerlink" title="Deadline"></a>Deadline</h3><p>“Deadline is the first productivity”, since the failover may not seem to be important to everyone, teams may not put them to the priority, so the deadline is a clear signal it will happen sooner or later.</p><h3 id="From-an-SRE’s-perspective"><a href="#From-an-SRE’s-perspective" class="headerlink" title="From an SRE’s perspective"></a>From an SRE’s perspective</h3><p>As an SRE, I play a vital role in this failover and will execute the operations.</p><ul><li>You should have a full list of your services.</li><li>Get your operation documentation ready, for example, the operation commands and monitoring dashboard addresses.</li><li>Mini failovers can be done gradually before the entire one.</li></ul><h2 id="When-the-day-comes"><a href="#When-the-day-comes" class="headerlink" title="When the day comes"></a>When the day comes</h2><h3 id="A-clear-agenda"><a href="#A-clear-agenda" class="headerlink" title="A clear agenda"></a>A clear agenda</h3><p>A clear agenda is a precondition that everything is under control even if something unexpected happens. Take the unexpected into consideration and make the agenda more flexible.</p><h3 id="Instant-communication"><a href="#Instant-communication" class="headerlink" title="Instant communication"></a>Instant communication</h3><p>For the team, the progress must be understood by every team member and their clients.<br>Also, it’s necessary to put everything unexpected into a global channel and everyone is aware of it.</p><h3 id="Roles-we-play"><a href="#Roles-we-play" class="headerlink" title="Roles we play"></a>Roles we play</h3><p>The coordinator is the one who’s responsible for connecting all the team players, (s)he’s responsible for recording the matters happening including success and failure, other team players should report what they’ve done and seen to the coordinator.</p><h2 id="After-the-failover"><a href="#After-the-failover" class="headerlink" title="After the failover"></a>After the failover</h2><p>After the failover, teams involved in this failover should look back and check what’s the good part and what needs to be improved.<br>Against the weakness, we can make some plans and put them into the backlog, we’ll be more confident facing the next failover.<br>I will spend more time on chaos engineering which is the continuous accidents injection to production and will bring production more resilience.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://blog.serverdensity.com/multi-data-center-redundancy-application-considerations/">Multiple data center redundancy</a></li><li><a href="https://principlesofchaos.org/?lang=ENcontent">Principles of Chaos Engineering</a> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Distributed system is like human body, it will have issues and break. There’s a theory that we feed it with issues deliberately and constantly, the body will be more and more stable and robust. It’s the same to system, put some issues to datacenters and let them failover automatically.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="distributed system" scheme="https://songrgg.github.io/tags/distributed-system/"/>
    
      <category term="data center failover" scheme="https://songrgg.github.io/tags/data-center-failover/"/>
    
      <category term="resilience" scheme="https://songrgg.github.io/tags/resilience/"/>
    
      <category term="chaos engineering" scheme="https://songrgg.github.io/tags/chaos-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Generate monitoring dashboards &amp; alertings using Grafana API</title>
    <link href="https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/"/>
    <id>https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/</id>
    <published>2019-09-22T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.415Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://grafana.com">Grafana</a> has been adopted as a common monitoring dashboard by more and more companies, in many cases, when operators need to create dashboard repeatedly they either choose to use template variables or create dashboards one by one. I think it’s very useful to leverage the <a href="https://grafana.com/docs/http_api/">Grafana API</a> to generate the monitoring dashboards automatically from template.</p><a id="more"></a><h2 id="My-thought-on-dashboard-automation"><a href="#My-thought-on-dashboard-automation" class="headerlink" title="My thought on dashboard automation"></a>My thought on dashboard automation</h2><p>There’s a common use case, if you need to create a lot of similar dashboard (like system stats) for different services, the dashboard skeleton may always be the same, you can use template variables to make the difference. However, you can not create alertings on the graphs which use template variables, so in these situations you have to create graphs without variables.</p><p>So we can create a template dashboard first with variables in Grafana, then use scripts to read from the template and render them with variables we specify, finally call Grafana APIs to create/update dashboards.</p><ol><li><p>Listen to what dashboards we need to create/update, collect metadata first.<br>For example, if it’s for server stats, we need to get the server info from cloud provider or other infrastructure.</p></li><li><p>Trigger the change to the dashboard</p><ul><li>Create the template of dashboard with template variables, it’s okay, we’ll replace the template later.</li><li>Render the template with the metadata we collected.</li><li>Add the graphs using CRUD APIs.</li></ul></li></ol><h2 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h2><p>Metadata is what you need to generate dashboards, basically it contains:</p><ol><li>How many dashboards you want to create?</li><li>What are each dashboard’s variables?<br>If you use public cloud providers, cloud APIs can be used otherwise you have your own infrastructure management APIs.</li></ol><h2 id="Template-dashboard"><a href="#Template-dashboard" class="headerlink" title="Template dashboard"></a>Template dashboard</h2><p><a href="https://grafana.com/docs/reference/templating/">Grafana Variables</a> is a good functionality for monitor a great number of servers or application, defining the template dashboard with variables is good for rendering because you can not only view the effect on the template but also the variable is easy to replace for the format is <code>$VARIABLE</code> or <code>[[VARIABLE]]</code>, string replacement is enough for this.<br><img src="/images/grafana_variables_dashboard.webp" alt="Grafana Variables"></p><h3 id="Grafana-dashboard-CRUD-API"><a href="#Grafana-dashboard-CRUD-API" class="headerlink" title="Grafana dashboard CRUD API"></a>Grafana dashboard CRUD API</h3><p>Grafana provides enough HTTP APIs to do this, once you create the template dashboard it already has the graphs and alertings, so <a href="https://grafana.com/docs/http_api/dashboard/">Grafana dashboard API</a> is enough for most cases.</p><p>For authentication, you can create a service account for automating the dashboards and use API token to call APIs.</p><p>The automation scripts can maintain a relationship between the dashboard UID and dashboard name and you can also do the change comparison before updating the dashboards.<br>Delete the dashboards when some of them are deprecated.</p><h3 id="Run-your-automation"><a href="#Run-your-automation" class="headerlink" title="Run your automation"></a>Run your automation</h3><p>It’s okay to run automation scripts as cronjobs.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li><a href="https://grafana.com/docs/http_api/dashboard/">Grafana dashboard API</a></li><li><a href="https://grafana.com/docs/http_api/alerting/">Grafana alerting API</a> is only used to get alerts, if you need to modify the alerts using dashboard API</li><li><a href="https://grafana.com/docs/tutorials/api_org_token_howto/">Grafana API token</a></li><li><a href="https://github.com/grafana-tools/sdk">Grafana SDK</a></li><li><a href="https://grafana.com/docs/reference/dashboard/">Grafana dashboard reference</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://grafana.com&quot;&gt;Grafana&lt;/a&gt; has been adopted as a common monitoring dashboard by more and more companies, in many cases, when operators need to create dashboard repeatedly they either choose to use template variables or create dashboards one by one. I think it’s very useful to leverage the &lt;a href=&quot;https://grafana.com/docs/http_api/&quot;&gt;Grafana API&lt;/a&gt; to generate the monitoring dashboards automatically from template.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
      <category term="grafana" scheme="https://songrgg.github.io/tags/grafana/"/>
    
      <category term="automation" scheme="https://songrgg.github.io/tags/automation/"/>
    
      <category term="alerting" scheme="https://songrgg.github.io/tags/alerting/"/>
    
  </entry>
  
  <entry>
    <title>How to install Spinnaker on CentOS 7</title>
    <link href="https://songrgg.github.io/operation/install-spinnaker-on-centos/"/>
    <id>https://songrgg.github.io/operation/install-spinnaker-on-centos/</id>
    <published>2019-09-18T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.407Z</updated>
    
    <content type="html"><![CDATA[<p>Spinnaker doesn’t support installation on CentOS machine, this article introduces how to use Docker to install Spinnaker components on CentOS directly.</p><p>As we know, according to the spinnaker’s official documentation, spinnaker provides a tool for installing the spinnaker cluster in Kubernetes cluster or debian/ubuntu bare metal machine, but there’s not an option to install it on CentOS or other common operating systems. Althogh the <a href="https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose">spinnaker</a> provides a way to start Spinnaker with <a href="https://docs.docker.com/compose/">Docker Compose</a>, but it’s out of date. So I created a new <a href="https://github.com/songrgg/spinnaker-compose">docker-compose project</a> to quickstart a spinnaker cluster on any kind of os.</p><a id="more"></a><h2 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart</h2><p>Provision a machine with at least 16GB memory and 4 cores, it may need more than this since my macbook pro(4cores, 16GB) was stuck when I started spinnaker.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/songrgg/spinnaker-compose</span><br><span class="line"><span class="built_in">cd</span> spinnaker-compose</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><h2 id="To-access-the-spinnaker"><a href="#To-access-the-spinnaker" class="headerlink" title="To access the spinnaker"></a>To access the spinnaker</h2><p>Visit <code>http://localhost:9000</code> in browser if you run spinnaker on local machine.</p><p>Otherwise you can use ssh to create tunnel on local machine. Spinnaker exposes two ports, 9000 for web, 8084 for api gateway.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 8084:localhost:8084 &lt;remote-host&gt;</span><br><span class="line">ssh -L 9000:localhost:9000 &lt;remote-host&gt;</span><br></pre></td></tr></table></figure><h2 id="Add-clouddriver"><a href="#Add-clouddriver" class="headerlink" title="Add clouddriver"></a>Add clouddriver</h2><p>You need to edit <code>config/clouddriver.yml</code> to open multiple clouddrivers, it’s not easy to integrate since we don’t have the <code>halyard</code> to do this stuff, but if you already have the clouddriver.yml, it’s easier to make it work.</p><p>Since clouddriver will need credentials, you need to modify the <code>docker-compose.yml</code> to mount the credential files on the docker containers.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spinnaker doesn’t support installation on CentOS machine, this article introduces how to use Docker to install Spinnaker components on CentOS directly.&lt;/p&gt;
&lt;p&gt;As we know, according to the spinnaker’s official documentation, spinnaker provides a tool for installing the spinnaker cluster in Kubernetes cluster or debian/ubuntu bare metal machine, but there’s not an option to install it on CentOS or other common operating systems. Althogh the &lt;a href=&quot;https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose&quot;&gt;spinnaker&lt;/a&gt; provides a way to start Spinnaker with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker Compose&lt;/a&gt;, but it’s out of date. So I created a new &lt;a href=&quot;https://github.com/songrgg/spinnaker-compose&quot;&gt;docker-compose project&lt;/a&gt; to quickstart a spinnaker cluster on any kind of os.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="spinnaker" scheme="https://songrgg.github.io/tags/spinnaker/"/>
    
      <category term="docker" scheme="https://songrgg.github.io/tags/docker/"/>
    
      <category term="centos" scheme="https://songrgg.github.io/tags/centos/"/>
    
  </entry>
  
  <entry>
    <title>How to host Swagger documentation using yaml/json configuration files?</title>
    <link href="https://songrgg.github.io/operation/host-swagger-documentation-with-yaml-json-files/"/>
    <id>https://songrgg.github.io/operation/host-swagger-documentation-with-yaml-json-files/</id>
    <published>2019-09-12T19:11:50.000Z</published>
    <updated>2020-03-30T14:06:12.616Z</updated>
    
    <content type="html"><![CDATA[<p>Maintain the swagger documentation by <a href="https://editor.swagger.io">Swagger Editor</a> and then you can use the yaml files to generate online swagger documentation easily with <a href="https://spring.io/projects/spring-boot">Spring boot</a>.</p><a id="more"></a><h2 id="Workflow-for-Swagger-documentation"><a href="#Workflow-for-Swagger-documentation" class="headerlink" title="Workflow for Swagger documentation"></a>Workflow for Swagger documentation</h2><ol><li>Update swagger documentation with Swagger Editor, export the yaml files</li><li>Update the yaml files in Spring boot project</li><li>Redeploy the Spring boot project</li></ol><h2 id="How-to-setup-in-Spring-boot"><a href="#How-to-setup-in-Spring-boot" class="headerlink" title="How to setup in Spring boot?"></a>How to setup in Spring boot?</h2><p>Swagger provides swagger-ui and some jars to host a documentation, you can use Java annotations or yaml files to autogenerate the swagger documentation. The example below is using static yaml files to generate documentation.</p><p>Demo project: <a href="https://github.com/songrgg/swaggerdemo">https://github.com/songrgg/swaggerdemo</a></p><p>The static yaml file is fetched from Swagger Editor, put it under the resources directory.</p><figure class="highlight yaml"><figcaption><span>src/main/resources/static/swagger-apis/api1/swagger.yaml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">swagger:</span> <span class="string">"2.0"</span></span><br><span class="line"><span class="attr">info:</span></span><br><span class="line">  <span class="attr">description:</span> <span class="string">"This is a sample server Petstore server.  You can find out more about     Swagger at [http://swagger.io](http://swagger.io) or on [irc.freenode.net, #swagger](http://swagger.io/irc/).      For this sample, you can use the api key `special-key` to test the authorization     filters."</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">"1.0.0"</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">"Swagger Petstore"</span></span><br><span class="line">  <span class="attr">termsOfService:</span> <span class="string">"http://swagger.io/terms/"</span></span><br><span class="line">  <span class="attr">contact:</span></span><br><span class="line">    <span class="attr">email:</span> <span class="string">"apiteam@swagger.io"</span></span><br><span class="line">  <span class="attr">license:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">"Apache 2.0"</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">"http://www.apache.org/licenses/LICENSE-2.0.html"</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><figcaption><span>Application.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableSwagger</span>2</span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SwaggerDemoApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(SwaggerDemoApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Docket <span class="title">swagger</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Docket(SWAGGER_2)</span><br><span class="line">            .select()</span><br><span class="line">            .apis(RequestHandlerSelectors.any())</span><br><span class="line">            .paths(PathSelectors.any())</span><br><span class="line">            .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Read the static yaml files:<br><code>src/main/resources/swagger-apis/api1/swagger.yaml</code> and <code>src/main/resources/swagger-apis/api2/swagger.yaml</code>.</p><figure class="highlight java"><figcaption><span>SwaggerSpecConfig.java</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SwaggerSpecConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SwaggerResourcesProvider <span class="title">swaggerResourcesProvider</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        InMemorySwaggerResourcesProvider defaultResourcesProvider)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> () -&gt; &#123;</span><br><span class="line">            List&lt;SwaggerResource&gt; resources = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            Arrays.asList(<span class="string">"api1"</span>, <span class="string">"api2"</span>)</span><br><span class="line">                .forEach(resourceName -&gt; resources.add(loadResource(resourceName)));</span><br><span class="line">            <span class="keyword">return</span> resources;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> SwaggerResource <span class="title">loadResource</span><span class="params">(String resource)</span> </span>&#123;</span><br><span class="line">        SwaggerResource wsResource = <span class="keyword">new</span> SwaggerResource();</span><br><span class="line">        wsResource.setName(resource);</span><br><span class="line">        wsResource.setSwaggerVersion(<span class="string">"2.0"</span>);</span><br><span class="line">        wsResource.setLocation(<span class="string">"/swagger-apis/"</span> + resource + <span class="string">"/swagger.yaml"</span>);</span><br><span class="line">        <span class="keyword">return</span> wsResource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight xml"><figcaption><span>pom.xml</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger-ui<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.springfox<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>springfox-swagger2<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Run the spring boot server and access <code>&lt;hostname&gt;/swagger-ui.html</code> to see the documentation.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Maintain the swagger documentation by &lt;a href=&quot;https://editor.swagger.io&quot;&gt;Swagger Editor&lt;/a&gt; and then you can use the yaml files to generate online swagger documentation easily with &lt;a href=&quot;https://spring.io/projects/spring-boot&quot;&gt;Spring boot&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="swagger" scheme="https://songrgg.github.io/tags/swagger/"/>
    
      <category term="spring boot" scheme="https://songrgg.github.io/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>My first Hackathon: bring Spinnaker to my company</title>
    <link href="https://songrgg.github.io/operation/hackathon-spinnaker/"/>
    <id>https://songrgg.github.io/operation/hackathon-spinnaker/</id>
    <published>2019-09-11T21:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.401Z</updated>
    
    <content type="html"><![CDATA[<p>I’ve joined my first Hackathon and worked on a project about using <a href="https://www.spinnaker.io">Spinnaker</a> as CI/CD tool within company. The biggest challenge is to install Spinnaker on CentOS 7 with <a href="https://docs.docker.com/compose/">docker-compose</a>.</p><h2 id="Why-Spinnaker"><a href="#Why-Spinnaker" class="headerlink" title="Why Spinnaker?"></a>Why Spinnaker?</h2><ul><li>Spinnaker is dedicated to deploy services across multiple cloud providers and the integration with AWS, GCP, Azure is out of box.</li><li>It’s focused on deploy stably, support full control of workflow, developers can customize the deployment flow to improve the quality of deployment, also it’s automatic.</li><li>You will have a Web UI.</li></ul><a id="more"></a><h2 id="How-to-use-Spinnaker"><a href="#How-to-use-Spinnaker" class="headerlink" title="How to use Spinnaker?"></a>How to use Spinnaker?</h2><p>Spinnaker can integrate with VCS like Github, Gitlab, Gitbucket, docker registry.<br>For example the workflow of deploy golang github project to Kubernetes cluster.</p><ol><li>A developer pushes code to Github repository, it triggers the Travis-CI that starts the test, build, package stages, a docker image is pushed to Docker repository finally.</li><li>Spinnaker has a trigger on the Docker repository and starts to deploy that image to a Kubernetes cluster in some cloud provider.</li><li>The deployment workflow includes Deploy to staging, Canary Deployment, Deploy to production.</li></ol><h2 id="Details-of-this-hackathon"><a href="#Details-of-this-hackathon" class="headerlink" title="Details of this hackathon"></a>Details of this hackathon</h2><p>Our goal is to start a Spinnaker cluster and create a pipeline that can deploy the Git project to AWS and our own Kubernetes cluster.<br>There’re some contraints for this hackathon, I’m still new to the company so maybe it’s because of my limited information.</p><ol><li>I don’t have a Kuberntes cluster with API server’s access right, that means I can’t deploy Spinnaker cluster to Kubernetes.</li><li>I don’t have a Debian/Ubuntu machine, that means I can’t start Spinnaker on a bare metal with <a href="https://www.spinnaker.io/setup/install/halyard/">Halyard</a>.</li><li>The Spinnaker need to be deployed within company’s infrastructure which is not any cloud provider, otherwise it can’t communicate with other infrastructure.</li></ol><p>And what does Spinnaker need? It needs Halyard to configure the Spinnaker cluster, it will control where Spinnaker cluster is deployed, as we know Spinnaker itself is composed of microservices, hard to deploy on bare metal. Especially for its cloud provider settings, so Spinnaker relies on Halyard heavily, and every time the Spinnaker cluster update and upgrade can be managed safely.</p><p>Sadly, Halyard is only used for deploying Spinnaker itself to Kubernetes or  some cloud providers and Debian/Ubuntu single machine. Then according to our constraints above, we lose every chance to use that tool. Maybe it’s time to give up :(</p><p>We didn’t give up, choose to install Spinnaker cluster the hardest way. Install Spinnaker cluster on Bare metal machine which is CentOS 7, for running the cluster easier, we use Docker to start each components.</p><p><img src="/images/spin-dependencies.webp" alt="Spinnaker microservice dependencies"></p><p>My colleague found <code>docker-compose.yml</code> in <a href="https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose">Spinnaker</a>, but the latest modification time was 4 years ago. After trying so many times we still couldn’t make it, I tried to give up actually, and also it was far away from quickstart and wasted so much time.</p><p>Actually I didn’t give up, I returned home and thought if the Spinnaker cluster can be deployed in Kubernetes, it can be deployed with Docker compose, since they didn’t have any difference.</p><p>So I chose the most stupid method, I created a Spinnaker cluster on GCP with far less time and rewrote the <code>docker-compose.yml</code> according to:</p><ol><li>Check each Kubernetes Pod’s yaml file to get the environment variables, image name, arguments…</li><li>Login to the containers to fetch the mounted configuration files like clouddriver.yml, front50.yml, gate.yml… Yes, they’re generated by Halyard where the comment says <code>DONT&#39;T EDIT THIS FILE, IT&#39;S AUTOGENERATED BY...</code>.</li></ol><p>After another X hours, without ignoring every details, I migrated all the Kubernetes configuration to <code>docker-compose.yml</code>, the second when I ran the <code>docker-compose up -d</code> and every microservice was labeled <code>DONE</code> and <code>http://localhost:9000</code> worked.</p><h2 id="Reflection-of-this-hackathon"><a href="#Reflection-of-this-hackathon" class="headerlink" title="Reflection of this hackathon"></a>Reflection of this hackathon</h2><p>Yes, it’s not a happy ending for my first hackathon, our team didn’t reach our goal, there’s some experience for this time.</p><p><strong>Gain</strong></p><ol><li>The hardest way to know how the Spinnaker configuration works, how it deploys.</li><li>I felt some joy when the installation was successful :)</li><li>Some knowledge about the GCP (first time to use GCP)</li></ol><p><strong>Improvements next time</strong></p><ol><li>Team member can be closer, whatever the seat we sit or the communication channel we talked, time is presious, we need check our progress frequently.</li><li>Fail fast, although this time I worked out the installation, but it was not a great result, next time we should help the team member to tackle the most important task.</li><li>Prepare enough, time is precious, if you want to make it in the Hackathon project, do some preparations, it’s not cheat!</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ve joined my first Hackathon and worked on a project about using &lt;a href=&quot;https://www.spinnaker.io&quot;&gt;Spinnaker&lt;/a&gt; as CI/CD tool within company. The biggest challenge is to install Spinnaker on CentOS 7 with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;docker-compose&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Why-Spinnaker&quot;&gt;&lt;a href=&quot;#Why-Spinnaker&quot; class=&quot;headerlink&quot; title=&quot;Why Spinnaker?&quot;&gt;&lt;/a&gt;Why Spinnaker?&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Spinnaker is dedicated to deploy services across multiple cloud providers and the integration with AWS, GCP, Azure is out of box.&lt;/li&gt;
&lt;li&gt;It’s focused on deploy stably, support full control of workflow, developers can customize the deployment flow to improve the quality of deployment, also it’s automatic.&lt;/li&gt;
&lt;li&gt;You will have a Web UI.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="sre" scheme="https://songrgg.github.io/tags/sre/"/>
    
      <category term="cicd" scheme="https://songrgg.github.io/tags/cicd/"/>
    
      <category term="spinnaker" scheme="https://songrgg.github.io/tags/spinnaker/"/>
    
      <category term="docker-compose" scheme="https://songrgg.github.io/tags/docker-compose/"/>
    
  </entry>
  
  <entry>
    <title>Anatomy of envoy proxy: the architecture of envoy and how it works</title>
    <link href="https://songrgg.github.io/architecture/deeper-understanding-to-envoy/"/>
    <id>https://songrgg.github.io/architecture/deeper-understanding-to-envoy/</id>
    <published>2019-08-13T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.397Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.envoyproxy.io">Envoy</a> has become more and more popular, the basic functionality is quite similar to <a href="https://www.nginx.com/">Nginx</a>, working as a high performace Web server, proxy. But Enovy imported a lot of features that was related to <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">SOA</a> or <a href="https://en.wikipedia.org/wiki/Microservices">Microservice</a> like Service Discovery, Circuit Breaker, Rate limiting and so on. </p><p>A lot of developers know the roles envoy plays, and the basic functionality it will implement, but don’t know how it organize the architecture and how we understand its configuration well. For me, it’s not easy to understand envoy’s architecture and its configuration since it has a lot of terminology, but if the developer knew how the user traffic goes, he could understand the design of envoy.</p><a id="more"></a><h3 id="Envoy-In-Servicemesh"><a href="#Envoy-In-Servicemesh" class="headerlink" title="Envoy In Servicemesh"></a>Envoy In Servicemesh</h3><p>Recently, more and more companies take Service Mesh to solve the communication problem among backend services, it’s a typical use case for envoy to work as a basic component for building a service mesh, envoy plays an important role and one of the service mesh solution <a href="https://istio.io">Istio</a> uses Envoy as the core of the networking.</p><p><img src="/images/envoy-in-service-mesh.webp" alt="envoy in service mesh"></p><p>As pictured, the Envoy is deployed beside every application, this kind of application we call it <code>Sidecar</code>.</p><p>Let’s analyze how the user traffic moves.</p><ol><li>The user hits the website and the browser tries to query an API, the api gateway receives the user request.</li><li>The API Gateway redirects the request to the backend server1 (in Kubernetes, it can be a Pod)</li><li>The envoy on backend server receives this HTTP request and resolves it to the destination server and forwards the request to the local destination port which APP1 listens at.</li><li>The APP1 receives requests, processes the bussiness logic and tries to call a dependent RPC service in APP2, the request first is sent to local envoy.</li><li>The local envoy resolves the RPC service APP2’s IP address and port according to the management server and sends the RPC request to APP2 server.</li><li>The server where the RPC service located at recevies the request,  to be clear, it’s the envoy receiving the request, after the same logic like step 3.</li><li>The APP2 processes the request and returns.</li><li>The envoy forwards the response to server1.</li><li>There’re two forwards being ignored, envoy(1) to APP1, APP1 to envoy(1). Then the envoy(1) returns the reponse to API gateway.</li><li>The API gateway returns to the user.</li></ol><p>The management server is responsible for telling envoy how to process the requests and where to forward.<br>Service discovery is where applications register themselves.</p><h4 id="Ingress-and-Egress"><a href="#Ingress-and-Egress" class="headerlink" title="Ingress and Egress"></a>Ingress and Egress</h4><p>As you can see, there’re two kinds of traffic within a server: ingress and egress.</p><ul><li>Any traffic sent to server, it’s ingress.</li><li>Any traffic sent from server, it’s egress.</li></ul><p>How to implement this transparently?</p><ul><li><p>Setup <strong>IPtables</strong> to redirect any traffic to this server to the envoy service first, then envoy redirects the traffic to the real application on this server.</p></li><li><p>Setup <strong>IPtables</strong> to redirect any traffic from this server to the envoy service first and envoy resolves the destination service using Service Discovery, redirects the request to the destination server.</p></li></ul><p>By intercepting the inbound and outbound traffic, envoy can implement the service discovery, circuit breaker, rate limiting, monitoring transparently, the developers don’t need to care about the details or integrate libraries.</p><h3 id="Anatomy-of-envoy-proxy-configuration"><a href="#Anatomy-of-envoy-proxy-configuration" class="headerlink" title="Anatomy of envoy proxy configuration"></a>Anatomy of envoy proxy configuration</h3><p>The first important role of envoy in the service mesh is <strong>proxy</strong>, it receives requests and forwards requests.<br>To see the components that make the proxy work, we can start with a request flow.</p><p><img src="/images/envoy-config.webp" alt="How Envoy Configuration works"></p><ol><li>A request reaches a port on the server which envoy listens at, we call this part <strong>listener</strong>.</li><li>Envoy receives the request and tries to process this request according to some rule, the rule is <strong>route</strong>.</li><li>The route processes the request based on the request’s metadata and tries to request the specific backend servers, the backend servers are called <strong>cluster</strong>.</li><li>The concrete server IP:port behind cluster is called <strong>endpoint</strong>.</li></ol><p>It’s the main part of envoy components in most of the proxy cases, similar to Nginx, you’re allowed to setup all the configuration by static files.</p><p>Here is an example with static configuration, you can see the full file <a href="https://github.com/envoyproxy/envoy/blob/master/examples/front-proxy/front-envoy.yaml">here</a>.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">static_resources:</span></span><br><span class="line">  <span class="attr">listeners:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span></span><br><span class="line">      <span class="attr">socket_address:</span></span><br><span class="line">        <span class="attr">address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">port_value:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">filter_chains:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">filters:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">envoy.http_connection_manager</span></span><br><span class="line">        <span class="attr">typed_config:</span></span><br><span class="line">          <span class="string">"@type"</span><span class="string">:</span> <span class="string">type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager</span></span><br><span class="line">          <span class="attr">codec_type:</span> <span class="string">auto</span></span><br><span class="line">          <span class="attr">stat_prefix:</span> <span class="string">ingress_http</span></span><br><span class="line">          <span class="attr">route_config:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">local_route</span></span><br><span class="line">            <span class="attr">virtual_hosts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">backend</span></span><br><span class="line">              <span class="attr">domains:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">"*"</span></span><br><span class="line">              <span class="attr">routes:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">                  <span class="attr">prefix:</span> <span class="string">"/service/1"</span></span><br><span class="line">                <span class="attr">route:</span></span><br><span class="line">                  <span class="attr">cluster:</span> <span class="string">service1</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">                  <span class="attr">prefix:</span> <span class="string">"/service/2"</span></span><br><span class="line">                <span class="attr">route:</span></span><br><span class="line">                  <span class="attr">cluster:</span> <span class="string">service2</span></span><br><span class="line">          <span class="attr">http_filters:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">envoy.router</span></span><br><span class="line">            <span class="attr">typed_config:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">  <span class="attr">clusters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">strict_dns</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">round_robin</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">service1</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="string">service1</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">strict_dns</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">round_robin</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">service2</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="string">service2</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>Don’t be nervous, you can understand this configuration easily by order:</p><ul><li>listener<br>It says the envoy listens at 0.0.0.0:80</li><li>route<br>It tells how to process request, there’s a route named local_route, a rule matching wildcard domain and forwards the request to <code>service1</code> cluster if the request path’s prefix matches <code>/service/1</code>, else forwards to <code>service2</code> cluster if the request path’s prefix matches <code>service/2</code>.</li><li>cluster<br>Finally, the <code>service1</code> cluster memtioned before is resolved to several endpoints, it’s the real address of the server, the address is <code>service1:80</code>.</li></ul><p>So the basic structure of the configuration is quite straightforward and easy to understand, if you want to manipulate the configuration and don’t know where to start, you can refer to this sample and every data model inside can be found in envoy documentation.</p><p>But most importantly, it’s allowed to use <strong>dynamic configuration</strong> which is mostly used in SOA and Microservice, it fits the situations where the service’s endpoints and route rules may change anytime.</p><p>For using dynamic resources, envoy supports setting an API server and divides the above components into different APIs or different resources within an API.</p><ul><li>LDS: listener<br>The listener discovery service (LDS) is an optional API that Envoy will call to dynamically fetch listeners. Envoy will reconcile the API response and add, modify, or remove known listeners depending on what is required.</li><li>RDS: route<br>The route discovery service (RDS) API is an optional API that Envoy will call to dynamically fetch route configurations. A route configuration includes both HTTP header modifications, virtual hosts, and the individual route entries contained within each virtual host.</li><li>CDS: cluster<br>The cluster discovery service (CDS) is an optional API that Envoy will call to dynamically fetch cluster manager members. Envoy will reconcile the API response and add, modify, or remove known clusters depending on what is required.</li><li>EDS: endpoint<br>The endpoint discovery service is a xDS management server based on gRPC or REST-JSON API server used by Envoy to fetch cluster members. The cluster members are called “endpoint” in Envoy terminology. For each cluster, Envoy fetch the endpoints from the discovery service.</li></ul><p>The concept is equal to the static configuration, you can initialize the configuration by</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">admin:</span></span><br><span class="line">  <span class="attr">access_log_path:</span> <span class="string">/tmp/admin_access.log</span></span><br><span class="line">  <span class="attr">address:</span></span><br><span class="line">    <span class="attr">socket_address:</span> <span class="string">&#123;</span> <span class="attr">address:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">,</span> <span class="attr">port_value:</span> <span class="number">9901</span> <span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">dynamic_resources:</span></span><br><span class="line">  <span class="attr">lds_config:</span></span><br><span class="line">    <span class="attr">api_config_source:</span></span><br><span class="line">      <span class="attr">api_type:</span> <span class="string">GRPC</span></span><br><span class="line">      <span class="attr">grpc_services:</span></span><br><span class="line">        <span class="attr">envoy_grpc:</span></span><br><span class="line">          <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line">  <span class="attr">cds_config:</span></span><br><span class="line">    <span class="attr">api_config_source:</span></span><br><span class="line">      <span class="attr">api_type:</span> <span class="string">GRPC</span></span><br><span class="line">      <span class="attr">grpc_services:</span></span><br><span class="line">        <span class="attr">envoy_grpc:</span></span><br><span class="line">          <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line"></span><br><span class="line"><span class="attr">static_resources:</span></span><br><span class="line">  <span class="attr">clusters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">xds_cluster</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">STATIC</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">ROUND_ROBIN</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">upstream_connection_options:</span></span><br><span class="line">      <span class="comment"># configure a TCP keep-alive to detect and reconnect to the admin</span></span><br><span class="line">      <span class="comment"># server in the event of a TCP socket half open connection</span></span><br><span class="line">      <span class="attr">tcp_keepalive:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">5678</span></span><br></pre></td></tr></table></figure><p>The only static resource is the xds_cluster which is the management server cluster which provides <strong>a GRPC streaming API</strong> answering the LDS, CDS, EDS, RDS configuration.<br>As you notice, there’re only lds_config and cds_config inside the config file, that’s because rds is included in lds and eds is included in cds.</p><p>In Service Mesh architecture, the management server is the most important module, it always connects to a distributed service discovery system which can be <a href="https://etcd.io">Etcd</a>, <a href="https://zookeeper.apache.org">Zookeeper</a>, <a href="https://www.consul.io">Consul</a>, <a href="https://github.com/Netflix/eureka">Eureka</a> or the Kubernetes(Kubernetes often used Etcd as their service discovery component), and provide some interfaces to manipulate the configuration to implement near-realtime configuration change.</p><h2 id="Conclustion"><a href="#Conclustion" class="headerlink" title="Conclustion"></a>Conclustion</h2><p>Understanding how the user traffic flows makes it easier for me to understand the component design of envoy and have a first glimpse of the envoy configuration, then you can start with more features later.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.envoyproxy.io&quot;&gt;Envoy&lt;/a&gt; has become more and more popular, the basic functionality is quite similar to &lt;a href=&quot;https://www.nginx.com/&quot;&gt;Nginx&lt;/a&gt;, working as a high performace Web server, proxy. But Enovy imported a lot of features that was related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot;&gt;SOA&lt;/a&gt; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot;&gt;Microservice&lt;/a&gt; like Service Discovery, Circuit Breaker, Rate limiting and so on. &lt;/p&gt;
&lt;p&gt;A lot of developers know the roles envoy plays, and the basic functionality it will implement, but don’t know how it organize the architecture and how we understand its configuration well. For me, it’s not easy to understand envoy’s architecture and its configuration since it has a lot of terminology, but if the developer knew how the user traffic goes, he could understand the design of envoy.&lt;/p&gt;
    
    </summary>
    
    
      <category term="architecture" scheme="https://songrgg.github.io/categories/architecture/"/>
    
    
      <category term="envoy" scheme="https://songrgg.github.io/tags/envoy/"/>
    
      <category term="service mesh" scheme="https://songrgg.github.io/tags/service-mesh/"/>
    
      <category term="architecture" scheme="https://songrgg.github.io/tags/architecture/"/>
    
      <category term="request analysis" scheme="https://songrgg.github.io/tags/request-analysis/"/>
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Istio Version Control On Kubernetes</title>
    <link href="https://songrgg.github.io/operation/istio-version-control-on-k8s/"/>
    <id>https://songrgg.github.io/operation/istio-version-control-on-k8s/</id>
    <published>2019-03-28T18:10:00.000Z</published>
    <updated>2020-03-20T19:02:13.409Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://istio.io">Istio</a> has been adopted as a common implementation of <a href="https://istio.io/docs/concepts/what-is-istio/">service mesh</a>, since more and more companies want to bring Istio into production, the version control of Istio seems a significant problem to solve.</p><p>Version control is necessary as Istio components can be treated as the equivalent RPC services like our business services, we need to have an understanding of which version we are using now and what does the next version bring. And some Istio components can cooperate with the others, if we need to upgrade one component we need to upgrade the other components too.</p><p>Although the Istio community provides the Istio upgrade method, we don’t actually want to upgrade such a whole thing in one move, it influences so much that we don’t want to risk.</p><a id="more"></a><h3 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h3><p><a href="https://helm.sh">Helm</a> is package control system for Kubernetes, it’s more like the complicated version of brew on Mac.</p><p>It uses Yaml and Golang templates to formulate a complete application configuration on Kubernetes. A lot of applications are packaged as Helm charts, we can build a complicated application by declaring the dependencies between these charts.</p><h3 id="Istio-Helm"><a href="#Istio-Helm" class="headerlink" title="Istio + Helm"></a>Istio + Helm</h3><p>Istio project contains the <a href="https://github.com/istio/istio/blob/master/install/kubernetes/helm/istio/README.md">Helm configuration</a> itself, I recommend the users to extract the Helm brought by Istio into a standalone Git repository.</p><p><img src="/images/istio-helm-git.webp" alt="istio-helm-git"></p><p>Like the other services, we use Git to control each component’s configuration and track every modification.</p><h3 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI/CD"></a>CI/CD</h3><p>As more and more people advocate <code>infrastructure as code</code>, we not only store the Istio Helm as a Git repository, we bring the CI/CD to the infrastructure.</p><p>If three Kubernetes clusters: <code>test</code>, <code>stage</code>, <code>production</code> exist, we can setup CI/CD to <code>test</code> cluster based on the specified Git <code>test</code> branch, each commit will trigger the generation of the latest Istio K8S Yaml config and apply them to the <code>test</code> cluster, after the tests on <code>test</code> environment, we brought the Istio updates to the <code>stage</code> and <code>production</code> in order.</p><h3 id="Still-worried-about-Production"><a href="#Still-worried-about-Production" class="headerlink" title="Still worried about Production?"></a>Still worried about Production?</h3><p>Although we have tested in the <code>test</code> environment, we still worry if it works in the <code>production</code> and a method to let you know what actually changes is to <strong>diff</strong> the K8S configuration between the latest config and the current K8S config.<br>I recommend the <a href="https://github.com/weaveworks/kubediff"><code>kubediff</code></a> tool to distinguish the differences.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul><li>Every updates to Istio configuration need to be tracked by Git. </li><li>Like the common services, deploy the change to <code>test</code> environment as soon as possible to fail fast.</li><li>Use <code>kubediff</code> to show the changes.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://istio.io&quot;&gt;Istio&lt;/a&gt; has been adopted as a common implementation of &lt;a href=&quot;https://istio.io/docs/concepts/what-is-istio/&quot;&gt;service mesh&lt;/a&gt;, since more and more companies want to bring Istio into production, the version control of Istio seems a significant problem to solve.&lt;/p&gt;
&lt;p&gt;Version control is necessary as Istio components can be treated as the equivalent RPC services like our business services, we need to have an understanding of which version we are using now and what does the next version bring. And some Istio components can cooperate with the others, if we need to upgrade one component we need to upgrade the other components too.&lt;/p&gt;
&lt;p&gt;Although the Istio community provides the Istio upgrade method, we don’t actually want to upgrade such a whole thing in one move, it influences so much that we don’t want to risk.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="configuration management" scheme="https://songrgg.github.io/tags/configuration-management/"/>
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="istio" scheme="https://songrgg.github.io/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>再见，micro: 迁移go-micro到纯gRPC框架</title>
    <link href="https://songrgg.github.io/microservice/goodbye-micro/"/>
    <id>https://songrgg.github.io/microservice/goodbye-micro/</id>
    <published>2018-10-27T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.399Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/micro/micro">micro</a>是基于golang的微服务框架，之前华尔街见闻架构升级中谈到了我们是基于go-micro的后端架构，随着我们对服务网格的调研、测试和实施，为了打通不同语言之间的服务调用，我们选择了gRPC作为服务内部的通用协议。</p><p>go-micro框架的架构非常具有拓展性，它拥有自己的RPC框架，通过抽象codec,transport,selector等微服务组件，你既可以使用官方实现的各种插件<a href="https://github.com/micro/go-plugins">go-plugins</a>进行组装，又可以根据实际的情况实现自己的组件。然而，我们打算利用服务网格的优势，将微服务的基础组件下沉到基础设施中去，将组件代码从代码库中剥离开来。</p><p>这样一来，我们相当于只需要最简的RPC框架，只需要服务之间有统一、稳定、高效的通信协议，由于micro在我们新架构中略显臃肿，于是我们选择逐渐剥除micro。还有一个重要原因，我们选择的服务网格方案是istio，它的代理原生支持gRPC，而micro只是将gRPC当做transport层，相当于复写了gRPC的服务路由逻辑，这样有损于istio的一些特性，譬如流量监控等功能。</p><p>出于这些考虑，第一步需要将micro改成纯gRPC模式，这里的改造部分我们考虑只应该去更改基础库的代码，而尽量不要使业务代码更改，减少对已有逻辑的影响，和一些软性的譬如开发人员的工作量。</p><a id="more"></a><h2 id="服务发现模块"><a href="#服务发现模块" class="headerlink" title="服务发现模块"></a>服务发现模块</h2><p>istio的服务发现支持etcd、consul等，我们需要将其改成使用kubernetes的服务名进行访问。通过实现<a href="https://gist.github.com/songrgg/22999fb7ab76a30dcac17cb28ed412d4">istio selector</a>的方式，我们将RPC调用的服务名与k8s的服务名端口做映射。</p><figure class="highlight go"><figcaption><span>register.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> istio</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/micro/go-micro/registry"</span></span><br><span class="line"><span class="string">"github.com/micro/go-micro/selector"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">svcPort = <span class="number">10088</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">serviceHostMapping = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;</span><br><span class="line"><span class="string">"payment"</span>: <span class="string">"payment.common"</span>,</span><br><span class="line"><span class="string">"content"</span>: <span class="string">"content.ns1"</span>,</span><br><span class="line"><span class="string">"user"</span>:    <span class="string">"user.ns1"</span>,</span><br><span class="line">&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> istio <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *istio)</span> <span class="title">Select</span><span class="params">(service <span class="keyword">string</span>, opts ...selector.SelectOption)</span> <span class="params">(selector.Next, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> host, exist := serviceHostMapping[service]; exist &#123;</span><br><span class="line">node := &amp;registry.Node&#123;</span><br><span class="line">Id:      service,</span><br><span class="line">Address: host,</span><br><span class="line">Port:    svcPort,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="params">(*registry.Node, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> node, <span class="literal">nil</span></span><br><span class="line">&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"service %s(%s) not found"</span>, service, svc)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这里注意的是由于服务之间调用需要指定service name和端口，所以在这里我们把端口设置了一个magic number。</p><h2 id="传输模块"><a href="#传输模块" class="headerlink" title="传输模块"></a>传输模块</h2><p>go-micro采用各种协议作为传输报文的工具，可以从<a href="https://github.com/micro/go-plugins/tree/master/transport">transport</a>中了解到，有http/grpc/tcp/utp等，我们曾先后使用过tcp、utp、gRPC，经过测试gRPC是其中最为稳定的。之前提到过gRPC只是作为传输信道，micro定义了自己的RPC接口，实现了RPC的路由、传输、重试等功能，通过自定义了protobuf的插件生成符合micro标准的proto文件。</p><p>为了向后兼容，在使用grpc替换原RPC时，我也需要根据protobuf文件生成新的golang代码，其中包括client端、server端代码的变更，实际上我的更新是针对<a href="https://github.com/golang/protobuf/tree/master/protoc-gen-go">protoc-gen-go</a>，fork之后修改<a href="https://github.com/golang/protobuf/blob/master/protoc-gen-go/grpc/grpc.go">grpc/grpc.go</a>部分，在<code>func generateService()</code>中对Client端代码进行micro的适配。</p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *someClient)</span> <span class="title">DoSomething</span><span class="params">(ctx context.Context, in *SomeRequest, opts ...grpc.CallOption)</span> <span class="params">(*SomeResponse, error)</span></span></span><br></pre></td></tr></table></figure><h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><p>Server端代码的更新除了接口的适配，有一个关注点是micro的接口设计是</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DoSomething(context.Context, *SomeRequest, *SomeResponse) error</span><br></pre></td></tr></table></figure><p>而gRPC是</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DoSomething(context.Context, *SomeRequest) (*SomeResponse, error)</span><br></pre></td></tr></table></figure><p>micro接口设计的好处是支持服务端缓存的应用，当服务端handler触发时，cache interceptor可以将response缓存，当缓存命中时可以将其返回。而由于gRPC的版本将response放在了返回值中，运行时无法将譬如redis中字符串格式的response解码成<code>SomeResponse</code>，而micro版本由于将其放在了参数位置，所以可以通过</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json.Unmarshall([]<span class="keyword">byte</span>(<span class="string">""</span>), &amp;SomeResponse&#123;&#125;)</span><br></pre></td></tr></table></figure><p>从字符串恢复response。</p><p>我们的做法是不改变接口的设计，而是在自动生成的golang代码中，在interceptor运行之前将response object塞入context。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Server</span></span><br><span class="line">ctx = ctx.WithValue(<span class="string">"IstioResponseBody"</span>, &amp;SomeResponse&#123;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Interceptor</span></span><br><span class="line">obj := ctx.Value(<span class="string">"IstioResponseBody"</span>)</span><br><span class="line">json.Unmarshall([]<span class="keyword">byte</span>(<span class="string">""</span>), obj)</span><br></pre></td></tr></table></figure><h2 id="Interceptor模块"><a href="#Interceptor模块" class="headerlink" title="Interceptor模块"></a>Interceptor模块</h2><p>一些interceptor的迁移工作，例如logger、cache、recover等。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol><li><p>向后兼容<br>更新的过程开发人员实际上并不是特别感兴趣，我们SRE能做的是对他们基本上无改动，第一个版本不要让开发感知。虽然实际上测试时由于我们的变动，测试环境不断受到稳定性质疑。</p></li><li><p>micro和gRPC的context传递不同<br>gRPC是基于http2，metadata是基于HTTP header传递，Client利用<code>metadata.NewOutgoingContext(ctx, MD)</code>携带metadata，而Server端利用<code>metadata.FromIncomingContext(ctx)</code>提取metadata。而micro则用<code>context.WithValue(metaKey{}, MD)</code>传递。</p></li><li><p>使用环境变量做一些特殊处理<br>我们通过环境变量在基础库里做了一些判断，在新老架构并存下进行一些特殊处理，譬如刚才说到的metadata获取逻辑。</p></li><li><p>关于proto自动生成<br>我们通过在CI中配置istio版本镜像的编译打包逻辑和原有逻辑共存，在编译前我们运行proto编译工具，生成gRPC的golang文件，从而打出新的镜像。</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>micro陪伴了我们一年多的时间，期间它的架构设计给了我们很大的弹性可以去适配一些我们的架构，可以选择很多好的开源工具，譬如zipkin、prometheus、etcd等，适合于刚上微服务不久的项目进行技术摸索和选择，而这一年的时间，我们的架构也逐渐明晰和稳定，我们更倾向于一个精简的基础库，并且由于在线项目的不断增加，运维成本可以通过下沉基础组件进行降低。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/micro/micro&quot;&gt;micro&lt;/a&gt;是基于golang的微服务框架，之前华尔街见闻架构升级中谈到了我们是基于go-micro的后端架构，随着我们对服务网格的调研、测试和实施，为了打通不同语言之间的服务调用，我们选择了gRPC作为服务内部的通用协议。&lt;/p&gt;
&lt;p&gt;go-micro框架的架构非常具有拓展性，它拥有自己的RPC框架，通过抽象codec,transport,selector等微服务组件，你既可以使用官方实现的各种插件&lt;a href=&quot;https://github.com/micro/go-plugins&quot;&gt;go-plugins&lt;/a&gt;进行组装，又可以根据实际的情况实现自己的组件。然而，我们打算利用服务网格的优势，将微服务的基础组件下沉到基础设施中去，将组件代码从代码库中剥离开来。&lt;/p&gt;
&lt;p&gt;这样一来，我们相当于只需要最简的RPC框架，只需要服务之间有统一、稳定、高效的通信协议，由于micro在我们新架构中略显臃肿，于是我们选择逐渐剥除micro。还有一个重要原因，我们选择的服务网格方案是istio，它的代理原生支持gRPC，而micro只是将gRPC当做transport层，相当于复写了gRPC的服务路由逻辑，这样有损于istio的一些特性，譬如流量监控等功能。&lt;/p&gt;
&lt;p&gt;出于这些考虑，第一步需要将micro改成纯gRPC模式，这里的改造部分我们考虑只应该去更改基础库的代码，而尽量不要使业务代码更改，减少对已有逻辑的影响，和一些软性的譬如开发人员的工作量。&lt;/p&gt;
    
    </summary>
    
    
      <category term="microservice" scheme="https://songrgg.github.io/categories/microservice/"/>
    
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="go-micro" scheme="https://songrgg.github.io/tags/go-micro/"/>
    
      <category term="gRPC" scheme="https://songrgg.github.io/tags/gRPC/"/>
    
      <category term="migration" scheme="https://songrgg.github.io/tags/migration/"/>
    
  </entry>
  
  <entry>
    <title>gRPC Golang Client Connection Test</title>
    <link href="https://songrgg.github.io/programming/grpc-go-client-performance-test/"/>
    <id>https://songrgg.github.io/programming/grpc-go-client-performance-test/</id>
    <published>2018-09-24T23:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.400Z</updated>
    
    <content type="html"><![CDATA[<p>gRPC is a well-known RPC protocol and a lot of companies adopted it as an internal communication protocol because of its robustness and stability. To use it more efficiently, I’ve done some experiments about how to maximize the gRPC client concurrency.</p><a id="more"></a><h2 id="3-Tests"><a href="#3-Tests" class="headerlink" title="3 Tests"></a>3 Tests</h2><ol><li>One connection per request<br>Create a connection when request is made.</li><li>Only one client, one connection<br>Use a common client by all requests.</li><li>Fixed-size Connection pool<br>If connection pool has enough connections, take it from pool, otherwise create a new connection.<br>The connection pool has fixed max capacity, release unused connection to pool when it’s not full.</li></ol><h2 id="Performance-Comparison"><a href="#Performance-Comparison" class="headerlink" title="Performance Comparison"></a>Performance Comparison</h2><p><strong>Hardware</strong><br>MacBook Pro (15-inch, 2016)<br>Processor 2.7 GHz Intel Core i7<br>Memory 16GB 2133 MHz LPDDR3</p><p><strong>Press tool, client and server run on the same machine</strong></p><h3 id="When-server-just-says-hello-to-client"><a href="#When-server-just-says-hello-to-client" class="headerlink" title="When server just says hello to client"></a>When server just says hello to client</h3><ol><li>Only one client, one connection <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency     2.85ms    1.24ms  22.24ms   80.47%</span><br><span class="line">    Req/Sec    15.86k     2.86k   21.58k    76.50%</span><br><span class="line">  316674 requests <span class="keyword">in</span> 10.04s, 38.66MB <span class="built_in">read</span></span><br><span class="line">Requests/sec:  31532.58</span><br><span class="line">Transfer/sec:      3.85MB</span><br></pre></td></tr></table></figure></li><li>Fixed-size Connection pool<br>Take connection from pool first, otherwise create a new connection. <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    36.86ms   34.35ms 334.72ms   83.30%</span><br><span class="line">    Req/Sec     1.58k   660.95     3.89k    67.86%</span><br><span class="line">  31127 requests <span class="keyword">in</span> 10.04s, 3.80MB <span class="built_in">read</span></span><br><span class="line">Requests/sec:   3100.89</span><br><span class="line">Transfer/sec:    387.61KB</span><br></pre></td></tr></table></figure></li><li>One connection per request<br>Close to the second result, about 3000 Requests/sec</li></ol><h3 id="When-server-sleeps-0-5s-and-says-hello-to-client"><a href="#When-server-sleeps-0-5s-and-says-hello-to-client" class="headerlink" title="When server sleeps 0.5s and says hello to client"></a>When server sleeps 0.5s and says hello to client</h3><ol><li><p>Only one client, one connection</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   503.43ms    1.95ms 511.62ms   64.35%</span><br><span class="line">    Req/Sec   130.60    119.12   485.00     80.85%</span><br><span class="line">  2000 requests <span class="keyword">in</span> 10.10s, 250.00KB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    198.04</span><br><span class="line">Transfer/sec:     24.75KB</span><br></pre></td></tr></table></figure></li><li><p>Fixed-size Connection pool  </p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   504.44ms    5.14ms 529.46ms   92.58%</span><br><span class="line">    Req/Sec   119.40     95.83   470.00     85.11%</span><br><span class="line">  1901 requests <span class="keyword">in</span> 10.07s, 237.62KB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    188.80</span><br><span class="line">Transfer/sec:     23.60KB</span><br></pre></td></tr></table></figure></li><li><p>one connection per request</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   509.30ms    4.85ms 529.65ms   73.74%</span><br><span class="line">    Req/Sec   188.81    188.12   494.00     71.23%</span><br><span class="line">  1900 requests <span class="keyword">in</span> 10.06s, 237.50KB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    188.89</span><br><span class="line">Transfer/sec:     23.61KB</span><br></pre></td></tr></table></figure></li></ol><h2 id="Sample-Code"><a href="#Sample-Code" class="headerlink" title="Sample Code"></a>Sample Code</h2><p>Find <a href="https://github.com/songrgg/go-experiments/tree/master/grpc/clientconn_test">sample code</a></p><h2 id="Some-Results"><a href="#Some-Results" class="headerlink" title="Some Results"></a>Some Results</h2><p>In gereral, use shared grpc client rather than use a customized connection pool. </p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://grpc.io">grpc</a><br><a href="https://mycodesmells.com/post/pooling-grpc-connections">pooling-grpc-connections</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;gRPC is a well-known RPC protocol and a lot of companies adopted it as an internal communication protocol because of its robustness and stability. To use it more efficiently, I’ve done some experiments about how to maximize the gRPC client concurrency.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="gRPC" scheme="https://songrgg.github.io/tags/gRPC/"/>
    
      <category term="client performance" scheme="https://songrgg.github.io/tags/client-performance/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes DNS拓展</title>
    <link href="https://songrgg.github.io/operation/extend-kubernetes-dns/"/>
    <id>https://songrgg.github.io/operation/extend-kubernetes-dns/</id>
    <published>2018-08-18T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.399Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes DNS在内部服务与外部服务交互，内部服务与内部服务，内部服务与云托管服务交互的工具，拓展DNS可以在内部服务访问集群外服务时像访问集群内服务一样，通过DNS映射将统一风格的域名映射到可访问的IP，而不需要影响内部服务的运行，这里介绍如何使用Consul来拓展DNS。</p><a id="more"></a><h3 id="自定义域名解析"><a href="#自定义域名解析" class="headerlink" title="自定义域名解析"></a>自定义域名解析</h3><p>拓展DNS的方法就是为特定规则的域名指定DNS服务器，在ConfigMap中设置指定域名相对的dns server，如<code>consul.local</code>结尾的域名使用<code>10.150.0.1</code>来解析。</p><figure class="highlight yaml"><figcaption><span>ConfigMap</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-dns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">stubDomains:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">&#123;"consul.local":</span> <span class="string">["10.150.0.1"]&#125;</span></span><br><span class="line">  <span class="attr">upstreamNameservers:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">["172.16.0.1"]</span></span><br></pre></td></tr></table></figure><p>自定义规则不对<strong>dnsPolicy</strong>为<code>Default</code>或<code>None</code>的Pod起作用，只有当<code>ClusterFirst</code>时，域名解析会按照stubDomains和upstreamNameservers来解析。<br><strong>无自定义配置</strong>: 任何不匹配集群域名后缀的请求，被转发给节点的dns.<br><strong>自定义</strong>: 如果stub和upstream配置，按照如下顺序</p><ol><li>带集群后缀的，请求转发给kube-dns</li><li>stub后缀的，转发给指定的dns</li><li>其它的转发给upstream dns</li></ol><h3 id="Consul-as-a-DNS"><a href="#Consul-as-a-DNS" class="headerlink" title="Consul as a DNS"></a>Consul as a DNS</h3><p><a href="https://consul.io/">Consul</a>是Golang实现的服务发现工具，同时支持DNS解析，通过HTTP API动态添加服务发现节点实现动态DNS解析。</p><ul><li><p>注册Redis1到redis</p><figure class="highlight json"><figcaption><span>dns.json</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ID"</span>: <span class="string">"redis1"</span>,</span><br><span class="line">  <span class="attr">"Name"</span>: <span class="string">"redis"</span>,</span><br><span class="line">  <span class="attr">"Tags"</span>: [</span><br><span class="line">    <span class="string">"primary"</span>,</span><br><span class="line">    <span class="string">"v1"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">  <span class="attr">"Port"</span>: <span class="number">8000</span>,</span><br><span class="line">  <span class="attr">"Meta"</span>: &#123;</span><br><span class="line">    <span class="attr">"redis_version"</span>: <span class="string">"4.0"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"EnableTagOverride"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XPUT http://localhost:8500/v1/agent/service/register -d @dns.json</span><br></pre></td></tr></table></figure></li><li><p>使用DNS查询</p><figure class="highlight bash"><figcaption><span>dig redis service</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ dig @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line">; (1 server found)</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 6823</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;redis.service.consul.INSRV</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">redis.service.consul.0INSRV1 1 8000 srjiangs-MacBook-Pro.local.node.dc1.consul.</span><br><span class="line"></span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN A 127.0.0.1</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN TXT <span class="string">"consul-network-segment="</span></span><br></pre></td></tr></table></figure></li><li><p>注册多个Redis</p><figure class="highlight json"><figcaption><span>dns.json</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ID"</span>: <span class="string">"redis2"</span>,</span><br><span class="line">  <span class="attr">"Name"</span>: <span class="string">"redis"</span>,</span><br><span class="line">  <span class="attr">"Tags"</span>: [</span><br><span class="line">    <span class="string">"primary"</span>,</span><br><span class="line">    <span class="string">"v1"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">  <span class="attr">"Port"</span>: <span class="number">8000</span>,</span><br><span class="line">  <span class="attr">"Meta"</span>: &#123;</span><br><span class="line">    <span class="attr">"redis_version"</span>: <span class="string">"4.0"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"EnableTagOverride"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>register</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XPUT http://localhost:8500/v1/agent/service/register -d @dns.json</span><br></pre></td></tr></table></figure></li><li><p>DNS查询</p><figure class="highlight bash"><figcaption><span>dig</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ dig @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line">; (1 server found)</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 11920</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 5</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;redis.service.consul.INSRV</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">redis.service.consul.0INSRV1 1 9000 srjiangs-MacBook-Pro.local.node.dc1.consul.</span><br><span class="line">redis.service.consul.0INSRV1 1 8000 srjiangs-MacBook-Pro.local.node.dc1.consul.</span><br><span class="line"></span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN A 127.0.0.1</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN TXT <span class="string">"consul-network-segment="</span></span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN A 127.0.0.1</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN TXT <span class="string">"consul-network-segment="</span></span><br><span class="line"></span><br><span class="line">;; Query time: 0 msec</span><br><span class="line">;; SERVER: 127.0.0.1<span class="comment">#8600(127.0.0.1)</span></span><br><span class="line">;; WHEN: Thu Aug 16 16:47:43 CST 2018</span><br><span class="line">;; MSG SIZE  rcvd: 277</span><br></pre></td></tr></table></figure></li><li><p>Consul Service</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://localhost:8500/v1/agent/services</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"redis1"</span>: &#123;</span><br><span class="line">        <span class="string">"ID"</span>: <span class="string">"redis1"</span>,</span><br><span class="line">        <span class="string">"Service"</span>: <span class="string">"redis"</span>,</span><br><span class="line">        <span class="string">"Tags"</span>: [</span><br><span class="line">            <span class="string">"primary"</span>,</span><br><span class="line">            <span class="string">"v1"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="string">"Port"</span>: 8000,</span><br><span class="line">        <span class="string">"EnableTagOverride"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"CreateIndex"</span>: 0,</span><br><span class="line">        <span class="string">"ModifyIndex"</span>: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"redis2"</span>: &#123;</span><br><span class="line">        <span class="string">"ID"</span>: <span class="string">"redis2"</span>,</span><br><span class="line">        <span class="string">"Service"</span>: <span class="string">"redis"</span>,</span><br><span class="line">        <span class="string">"Tags"</span>: [</span><br><span class="line">            <span class="string">"primary"</span>,</span><br><span class="line">            <span class="string">"v1"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="string">"Port"</span>: 9000,</span><br><span class="line">        <span class="string">"EnableTagOverride"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"CreateIndex"</span>: 0,</span><br><span class="line">        <span class="string">"ModifyIndex"</span>: 0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="更多细节"><a href="#更多细节" class="headerlink" title="更多细节"></a>更多细节</h3><ul><li>根据集群DC返回该数据中心能访问到的DNS</li><li>动态添加域名和IP映射</li></ul><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><ol><li><p><a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/">Customizing DNS Service - Kubernetes</a></p></li><li><p><a href="https://github.com/skynetservices/skydns">GitHub - skynetservices/skydns: DNS service discovery for etcd</a></p></li><li><p><a href="https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/">Adding entries to Pod /etc/hosts with HostAliases - Kubernetes</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes DNS在内部服务与外部服务交互，内部服务与内部服务，内部服务与云托管服务交互的工具，拓展DNS可以在内部服务访问集群外服务时像访问集群内服务一样，通过DNS映射将统一风格的域名映射到可访问的IP，而不需要影响内部服务的运行，这里介绍如何使用Consul来拓展DNS。&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
  </entry>
  
  <entry>
    <title>以Kubernetes sidecar方式部署Nginx: 提供更好的Web性能</title>
    <link href="https://songrgg.github.io/operation/nginx-kubernetes-sidecar-for-better-performance/"/>
    <id>https://songrgg.github.io/operation/nginx-kubernetes-sidecar-for-better-performance/</id>
    <published>2018-04-22T19:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.412Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Web-server’s-gzip"><a href="#Web-server’s-gzip" class="headerlink" title="Web server’s gzip"></a>Web server’s gzip</h3><p>Web服务开启数据压缩，有利于节省带宽。服务器根据客户端请求头所带的<code>Accept-Encoding</code>判断是否需要对返回数据进行压缩，通常支持的压缩格式是gzip。</p><h3 id="应用gzip-or-Nginx-gzip"><a href="#应用gzip-or-Nginx-gzip" class="headerlink" title="应用gzip or Nginx gzip"></a>应用gzip or Nginx gzip</h3><p>开发人员可以选择在Web framework中开发一些middleware来实现Gzip，也可以选择使用Nginx gzip，将所有gzip放在nginx中完成。</p><p>放在nginx中实现的优势是nginx中gzip性能优秀，能很大程度地减少gzip带来的消耗，像Golang中系统自带库中实现的gzip性能上相比nginx就差很多，并且需要使用对象池进行优化，避免每次创建gzip对象带来的性能损耗，在CPU和内存上占用较大。</p><h3 id="使用Nginx-gzip替代应用gzip"><a href="#使用Nginx-gzip替代应用gzip" class="headerlink" title="使用Nginx gzip替代应用gzip"></a>使用Nginx gzip替代应用gzip</h3><p>如果使用Nginx实现的gzip，那么部署的时候可以有几种方案。</p><ol><li><p>集中式nginx集群<br>nginx集中部署，通过配置反向代理服务各种应用，优势是部署方便，集中管理。劣势是更新路由也是牵一发动全身，并且需要及时拓容。</p></li><li><p>每个实例搭配nginx<br>原本对外暴露的应用现在通过nginx代理，1:1的方式部署，不用担心拓容的问题。需要解决的就是如何保证它们打包部署。</p></li></ol><h3 id="Sidecar-in-Kubernetes"><a href="#Sidecar-in-Kubernetes" class="headerlink" title="Sidecar in Kubernetes"></a>Sidecar in Kubernetes</h3><p>这里讨论Kubernetes中部署Web服务的情况，遇到刚才的方案二，可以在Kubernetes中找到非常匹配的部署方法。</p><p>Kubernetes中最小部署单位称为Pod，Pod中可以部署1个以上的功能紧密联系的容器，并且它们共享网络、磁盘，也就是它们能通过<code>localhost:port</code>访问到彼此，那以上的情况nginx作为gzip功能可以说和后端应用是紧密结合，所以可以以sidecar的形式部署。</p><h4 id="Nginx配置"><a href="#Nginx配置" class="headerlink" title="Nginx配置"></a>Nginx配置</h4><p>如果你的应用监听在8080端口，nginx监听在8090，可以如下配置</p><figure class="highlight nginx"><figcaption><span>/etc/nginx/site.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">user</span>  nginx;</span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">  <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="attribute">error_log</span>  /var/log/nginx/error.log <span class="literal">warn</span>;</span><br><span class="line"><span class="attribute">pid</span>        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">  <span class="attribute">include</span>       /etc/nginx/mime.types;</span><br><span class="line">  <span class="attribute">default_type</span>  application/octet-stream;</span><br><span class="line">  <span class="attribute">keepalive_timeout</span>  <span class="number">65</span>;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">gzip</span> <span class="literal">on</span>;</span><br><span class="line">  <span class="attribute">gzip_min_length</span>    <span class="number">256</span>;</span><br><span class="line">  <span class="attribute">gzip_types</span> application/javascript application/json text/css text/plain;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">include</span> /etc/nginx/conf.d/<span class="regexp">*.conf</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight nginx"><figcaption><span>/etc/nginx/conf.d/site.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  <span class="attribute">listen</span> <span class="number">8090</span>;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">location</span> / &#123;</span><br><span class="line">      <span class="attribute">proxy_pass</span>              http://127.0.0.1:8088/;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> Host   <span class="variable">$http_host</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol><li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/#uses-of-pods">Use of pods</a></li><li><a href="http://nginx.org/en/docs/http/ngx_http_gzip_module.html">Nginx gzip</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Encoding">HTTP Accept-Encoding</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Web-server’s-gzip&quot;&gt;&lt;a href=&quot;#Web-server’s-gzip&quot; class=&quot;headerlink&quot; title=&quot;Web server’s gzip&quot;&gt;&lt;/a&gt;Web server’s gzip&lt;/h3&gt;&lt;p&gt;Web服务开启数据压
      
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="sidecar" scheme="https://songrgg.github.io/tags/sidecar/"/>
    
      <category term="nginx" scheme="https://songrgg.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Ansible常用命令</title>
    <link href="https://songrgg.github.io/operation/ansible-frequently-used-commands/"/>
    <id>https://songrgg.github.io/operation/ansible-frequently-used-commands/</id>
    <published>2018-03-05T20:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.396Z</updated>
    
    <content type="html"><![CDATA[<h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>记录一下常用的Ansible指令、模块，方便检索。</p><h3 id="Ansible主机"><a href="#Ansible主机" class="headerlink" title="Ansible主机"></a>Ansible主机</h3><p>/etc/ansible/hosts中，server是目标服务器列表名，包含两个服务器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[spark]</span><br><span class="line">10.0.0.1</span><br><span class="line">10.0.0.2</span><br></pre></td></tr></table></figure><h3 id="Ansible-Shell模块"><a href="#Ansible-Shell模块" class="headerlink" title="Ansible Shell模块"></a>Ansible Shell模块</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在spark集群上执行ls指令</span></span><br><span class="line">$ ansible spark -m shell -a <span class="string">'ls'</span></span><br></pre></td></tr></table></figure><h3 id="Ansible-playbook"><a href="#Ansible-playbook" class="headerlink" title="Ansible-playbook"></a>Ansible-playbook</h3><p>执行较大的复杂任务时，以<code>YAML</code>的声明语法来配置，并且可以放置一些模板类文件和资源文件等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">|___python.yml</span><br><span class="line">|___python.host</span><br><span class="line">|___roles</span><br><span class="line">| |___python</span><br><span class="line">| | |___defaults  # 默认变量</span><br><span class="line">| | |___handlers  # 可以被任务使用或者任何该任务之外的地方</span><br><span class="line">| | |___files</span><br><span class="line">| | |___vars      # 其它变量</span><br><span class="line">| | |___templates # 模板</span><br><span class="line">| | |___meta      # 元数据</span><br><span class="line">| | |___tasks     # 主要任务列表</span><br><span class="line">| | | |___main.yml</span><br><span class="line">| |___airflow</span><br><span class="line">| | |___tasks</span><br><span class="line">| | | |___main.yml</span><br><span class="line">| | | |___templates</span><br><span class="line">| | | | |___airflow.cfg</span><br></pre></td></tr></table></figure><h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 声明变量</span></span><br><span class="line"><span class="attr">foo:</span></span><br><span class="line">  <span class="attr">field1:</span> <span class="string">one</span></span><br><span class="line">  <span class="attr">field2:</span> <span class="string">two</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用base_path</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">app_servers</span></span><br><span class="line">  <span class="attr">vars:</span></span><br><span class="line">      <span class="attr">app_path:</span> <span class="string">&#123;</span> <span class="string">&#123;</span> <span class="string">base_path</span> <span class="string">&#125;</span> <span class="string">&#125;/22</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在命令行传入变量</span></span><br><span class="line">$ ansible-playbook release.yml --extra-vars <span class="string">"hosts=vipers user=starbuck"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件形式</span></span><br><span class="line">$ ansible-playbook release.yml --extra-vars <span class="string">"@some_file.json"</span></span><br></pre></td></tr></table></figure><p>更多的变量还有3类作用域等，以后用到再加。</p><h4 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将files目录下的conf/发送到目标节点</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">conf</span> <span class="string">files</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=conf/agent.conf</span> <span class="string">dest=/opt/flume/apache-flume-1.7.0-bin/conf/</span></span><br></pre></td></tr></table></figure><h4 id="handler"><a href="#handler" class="headerlink" title="handler"></a>handler</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># handlers/main.yml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> <span class="string">telegraf</span></span><br><span class="line">  <span class="attr">service:</span> <span class="string">name=telegraf</span> <span class="string">state=started</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝docker配置文件并触发docker重启</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">docker</span> <span class="string">conf</span> <span class="string">to</span> <span class="string">dest</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=conf/docker.conf</span> <span class="string">dest=/etc/telegraf/telegraf.d/</span></span><br><span class="line">  <span class="attr">when:</span> <span class="string">"'docker' in group_names"</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">restart</span> <span class="string">telegraf</span></span><br></pre></td></tr></table></figure><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p><code>roles</code>目录就是按具体安装的功能模块划分，比如python模块、jdk模块、spark模块等等，他们相互不重复，并且可以有依赖关系，比如jdk -&gt; spark，通过多个role的组合搭配出各种环境的配置方法。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python/tasks/main.yml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">apt:</span> </span><br><span class="line">    <span class="attr">name:</span> <span class="string">python-pip</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Upgrade</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pip</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">--upgrade</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># airflow/tasks/main.yml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">virtualenv</span> <span class="string">for</span> <span class="string">airflow</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">virtualenv</span> <span class="string">/home/ubuntu/airflow_v</span> <span class="string">creates=/home/ubuntu/airflow_v</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">mysqlclient</span></span><br><span class="line">  <span class="attr">apt:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">libmysqlclient-dev</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">airflow</span> <span class="string">within</span> <span class="string">`airflow_v`</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">apache-airflow[all]</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">/home/ubuntu/airflow_v</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">celery[redis]</span> <span class="string">within</span> <span class="string">`airflow_v`</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">celery[redis]</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">/home/ubuntu/airflow_v</span></span><br><span class="line">    </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">Airflow</span> <span class="string">home</span></span><br><span class="line">  <span class="attr">file:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/home/ubuntu/airflow</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">directory</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="number">0755</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Initialize</span> <span class="string">airflow</span> <span class="string">database</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">source</span> <span class="string">/home/ubuntu/airflow_v/bin/activate</span> <span class="string">&amp;&amp;</span> <span class="string">/home/ubuntu/airflow_v/bin/airflow</span> <span class="string">initdb</span> <span class="string">creates=/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="attr">AIRFLOW_HOME:</span> <span class="string">/home/ubuntu/airflow</span></span><br><span class="line">    </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Syncronize</span> <span class="string">airflow</span> <span class="string">configuration</span></span><br><span class="line">  <span class="attr">synchronize:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">templates/airflow.cfg</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="入口文件"><a href="#入口文件" class="headerlink" title="入口文件"></a>入口文件</h4><p><code>python.yml</code>是ansible入口文件，包含目标host、运行的具体任务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 发布机上的代码初始化</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">spark</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">python</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">airflow</span></span><br></pre></td></tr></table></figure><p>下面是任务中常用的模块</p><hr><h4 id="apt安装模块"><a href="#apt安装模块" class="headerlink" title="apt安装模块"></a>apt安装模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装pip</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">apt:</span> </span><br><span class="line">    <span class="attr">name:</span> <span class="string">python-pip</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="Pip安装模块"><a href="#Pip安装模块" class="headerlink" title="Pip安装模块"></a>Pip安装模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pip升级pip</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Upgrade</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">extra_args:</span> <span class="string">--upgrade</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用指定虚拟环境安装依赖</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">celery[redis]</span> <span class="string">within</span> <span class="string">`airflow_v`</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">celery[redis]</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">/home/ubuntu/airflow_v</span></span><br></pre></td></tr></table></figure><h4 id="Shell模块"><a href="#Shell模块" class="headerlink" title="Shell模块"></a>Shell模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Initialize</span> <span class="string">airflow</span> <span class="string">database</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">source</span> <span class="string">/home/ubuntu/airflow_v/bin/activate</span> <span class="string">&amp;&amp;</span> <span class="string">/home/ubuntu/airflow_v/bin/airflow</span> <span class="string">initdb</span> <span class="string">creates=/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="attr">AIRFLOW_HOME:</span> <span class="string">/home/ubuntu/airflow</span></span><br></pre></td></tr></table></figure><h4 id="File模块"><a href="#File模块" class="headerlink" title="File模块"></a>File模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在目标服务器上创建权限为0755的目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">Airflow</span> <span class="string">home</span></span><br><span class="line">  <span class="attr">file:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/home/ubuntu/airflow</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">directory</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="number">0755</span></span><br></pre></td></tr></table></figure><h4 id="Synchronize模块"><a href="#Synchronize模块" class="headerlink" title="Synchronize模块"></a>Synchronize模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将本地文件同步到目标服务器上</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Syncronize</span> <span class="string">airflow</span> <span class="string">configuration</span></span><br><span class="line">  <span class="attr">synchronize:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">templates/airflow.cfg</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="下载模块"><a href="#下载模块" class="headerlink" title="下载模块"></a>下载模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从指定URL下载文件到目标服务器指定目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Download</span> <span class="string">the</span> <span class="string">Go</span> <span class="string">tarball</span></span><br><span class="line">  <span class="attr">get_url:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">"<span class="template-variable">&#123;&#123; go_download_location &#125;&#125;</span>"</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/usr/local/src/&#123;&#123;</span> <span class="string">go_tarball</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">checksum:</span> <span class="string">"<span class="template-variable">&#123;&#123; go_tarball_checksum &#125;&#125;</span>"</span></span><br></pre></td></tr></table></figure><h4 id="Systemd模块"><a href="#Systemd模块" class="headerlink" title="Systemd模块"></a>Systemd模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启docker服务</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">systemd:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">restarted</span></span><br><span class="line">    <span class="attr">daemon_reload:</span> <span class="literal">yes</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="Template模块"><a href="#Template模块" class="headerlink" title="Template模块"></a>Template模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将templates目录下的docker.my模板复制到目标服务器的/etc/default/docker目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Configure</span> <span class="string">docker</span> <span class="string">mirror</span> <span class="string">registry</span> <span class="string">to</span> <span class="string">Aliyun</span></span><br><span class="line">  <span class="attr">template:</span> <span class="string">src=docker.my</span> <span class="string">dest=/etc/default/docker</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">restart</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="Blockinfile模块"><a href="#Blockinfile模块" class="headerlink" title="Blockinfile模块"></a>Blockinfile模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个官网例子，在/etc/hosts里添加映射</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Add</span> <span class="string">mappings</span> <span class="string">to</span> <span class="string">/etc/hosts</span></span><br><span class="line">  <span class="attr">blockinfile:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/etc/hosts</span></span><br><span class="line">    <span class="attr">block:</span> <span class="string">|</span></span><br><span class="line">      <span class="string">&#123;&#123;</span> <span class="string">item.ip</span> <span class="string">&#125;&#125;</span> <span class="string">&#123;&#123;</span> <span class="string">item.name</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">marker:</span> <span class="string">"# &#123;mark&#125; ANSIBLE MANAGED BLOCK <span class="template-variable">&#123;&#123; item.name &#125;&#125;</span>"</span></span><br><span class="line">  <span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">name:</span> <span class="string">host1,</span> <span class="attr">ip:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.10</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">name:</span> <span class="string">host2,</span> <span class="attr">ip:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.11</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">name:</span> <span class="string">host3,</span> <span class="attr">ip:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.12</span> <span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h4 id="Copy模块"><a href="#Copy模块" class="headerlink" title="Copy模块"></a>Copy模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝zookeeper配置文件</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">zookeeper</span> <span class="string">conf</span> <span class="string">to</span> <span class="string">dest</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=conf/zookeeper.conf</span> <span class="string">dest=/etc/zookeeper/conf/</span></span><br></pre></td></tr></table></figure><h4 id="Service模块"><a href="#Service模块" class="headerlink" title="Service模块"></a>Service模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span> <span class="string">telegraf</span></span><br><span class="line">  <span class="attr">service:</span> <span class="string">name=telegraf</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><ol><li><a href="http://docs.ansible.com/ansible/latest/" title="Ansible文档">http://docs.ansible.com/ansible/latest/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;动机&quot;&gt;&lt;a href=&quot;#动机&quot; class=&quot;headerlink&quot; title=&quot;动机&quot;&gt;&lt;/a&gt;动机&lt;/h3&gt;&lt;p&gt;记录一下常用的Ansible指令、模块，方便检索。&lt;/p&gt;
&lt;h3 id=&quot;Ansible主机&quot;&gt;&lt;a href=&quot;#Ansible主机&quot; 
      
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
  </entry>
  
</feed>
