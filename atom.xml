<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog | Songrgg</title>
  
  <subtitle>A programmer who likes travelling and cooking :)</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://songrgg.github.io/"/>
  <updated>2020-03-20T19:02:13.406Z</updated>
  <id>https://songrgg.github.io/</id>
  
  <author>
    <name>songrgg</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>InfluxDB command cheatsheet</title>
    <link href="https://songrgg.github.io/operation/influxdb-command-cheatsheet/"/>
    <id>https://songrgg.github.io/operation/influxdb-command-cheatsheet/</id>
    <published>2020-03-17T23:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.406Z</updated>
    
    <content type="html"><![CDATA[<p>This article is InfluxDB command cheatsheet about how to interact with influxDB server and query the metrics. The InfluxDB version I tested is <a href="https://docs.influxdata.com/influxdb/v1.7/">v1.7.10</a></p><a id="more"></a><h2 id="Connect-amp-Start"><a href="#Connect-amp-Start" class="headerlink" title="Connect &amp; Start"></a>Connect &amp; Start</h2><p>Connect to InfluxDB server and select the database.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ influx -host 127.0.0.1 -port 8086</span><br><span class="line">&gt; SHOW DATABASES;</span><br><span class="line">name: databases</span><br><span class="line">name</span><br><span class="line">----</span><br><span class="line">_internal</span><br><span class="line">&gt; CREATE DATABASE <span class="built_in">test</span>;</span><br><span class="line">&gt; USE <span class="built_in">test</span>;</span><br><span class="line">Using database <span class="built_in">test</span></span><br><span class="line">&gt; --- fill the database with some points</span><br><span class="line">&gt; INSERT temperature,machine=unit42,<span class="built_in">type</span>=assembly external=25,internal=37</span><br><span class="line">&gt; INSERT temperature,machine=unit43,<span class="built_in">type</span>=assembly external=25,internal=37</span><br><span class="line">&gt; INSERT temperature,machine=unit43,<span class="built_in">type</span>=not_assembly external=25,internal=37</span><br></pre></td></tr></table></figure><h2 id="Show-everything"><a href="#Show-everything" class="headerlink" title="Show everything"></a>Show everything</h2><p><strong>Show</strong> is a helpful command that will help you find all the schemas you may use.</p><h3 id="Show-common-information"><a href="#Show-common-information" class="headerlink" title="Show common information"></a>Show common information</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- list all databases</span><br><span class="line">&gt; SHOW DATABASES</span><br><span class="line">&gt; --- show all measurements</span><br><span class="line">&gt; SHOW MEASUREMENTS</span><br><span class="line">&gt; --- show measurements <span class="built_in">where</span> machine tag = <span class="string">'unit42'</span></span><br><span class="line">&gt; SHOW MEASUREMENTS WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- show measurements that start with <span class="string">'temp'</span></span><br><span class="line">&gt; SHOW MEASUREMENTS WITH MEASUREMENT =~ /temp.*/</span><br><span class="line">&gt; --- show all running queries</span><br><span class="line">&gt; SHOW QUERIES</span><br><span class="line">&gt; --- show all retention policies on a database</span><br><span class="line">&gt; SHOW RETENTION POLICIES ON <span class="string">"test"</span></span><br><span class="line">&gt; --- show all users <span class="keyword">in</span> InfluxDB</span><br><span class="line">&gt; SHOW USERS</span><br></pre></td></tr></table></figure><h3 id="Show-series"><a href="#Show-series" class="headerlink" title="Show series"></a>Show series</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- show all series</span><br><span class="line">&gt; show series from temperature</span><br><span class="line">key</span><br><span class="line">---</span><br><span class="line">temperature,machine=unit42,<span class="built_in">type</span>=assembly</span><br><span class="line">temperature,machine=unit43,<span class="built_in">type</span>=assembly</span><br><span class="line">temperature,machine=unit43,<span class="built_in">type</span>=not_assembly</span><br><span class="line">&gt; --- show series from machine unit42</span><br><span class="line">&gt; SHOW SERIES FROM temperature WHERE machine = <span class="string">'unit42'</span></span><br><span class="line">key</span><br><span class="line">---</span><br><span class="line">temperature,machine=unit42,<span class="built_in">type</span>=assembly</span><br><span class="line">&gt; -- show estimated cardinality of the series on current database</span><br><span class="line">&gt; SHOW SERIES CARDINALITY</span><br><span class="line">-- show estimated cardinality of the series on specified database</span><br><span class="line">&gt; SHOW SERIES CARDINALITY ON mydb</span><br><span class="line">cardinality estimation</span><br><span class="line">----------------------</span><br><span class="line">3</span><br></pre></td></tr></table></figure><h3 id="Show-tag"><a href="#Show-tag" class="headerlink" title="Show tag"></a>Show tag</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- show tag keys</span><br><span class="line">&gt; SHOW TAG KEYS</span><br><span class="line">name: temperature</span><br><span class="line">tagKey</span><br><span class="line">------</span><br><span class="line">machine</span><br><span class="line"><span class="built_in">type</span></span><br><span class="line">&gt; --- show all tag keys from the temperature measurement</span><br><span class="line">&gt; SHOW TAG KEYS FROM <span class="string">"temperature"</span></span><br><span class="line">&gt; --- show all tag keys <span class="built_in">where</span> the machine key = <span class="string">'unit42'</span></span><br><span class="line">&gt; SHOW TAG KEYS WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- show all tag values across all measurements <span class="keyword">for</span> the machine tag</span><br><span class="line">&gt; SHOW TAG VALUES WITH KEY = <span class="string">"machine"</span></span><br><span class="line">name: temperature</span><br><span class="line">key     value</span><br><span class="line">---     -----</span><br><span class="line">machine unit42</span><br><span class="line">machine unit43</span><br><span class="line">&gt; --- show tag values <span class="keyword">for</span> a specific database and measurement</span><br><span class="line">&gt; SHOW TAG VALUES ON <span class="built_in">test</span> FROM temperature WITH KEY = <span class="string">"machine"</span></span><br></pre></td></tr></table></figure><h3 id="Show-field"><a href="#Show-field" class="headerlink" title="Show field"></a>Show field</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; SHOW FIELD KEYS ON <span class="built_in">test</span></span><br><span class="line">name: temperature</span><br><span class="line">fieldKey fieldType</span><br><span class="line">-------- ---------</span><br><span class="line">external <span class="built_in">float</span></span><br><span class="line">internal <span class="built_in">float</span></span><br></pre></td></tr></table></figure><h3 id="Show-cardinality"><a href="#Show-cardinality" class="headerlink" title="Show cardinality"></a>Show cardinality</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt; SHOW MEASUREMENT CARDINALITY</span><br><span class="line">cardinality estimation</span><br><span class="line">----------------------</span><br><span class="line">1</span><br><span class="line">&gt; SHOW MEASUREMENT EXACT CARDINALITY ON <span class="built_in">test</span></span><br><span class="line">count</span><br><span class="line">-----</span><br><span class="line">1</span><br></pre></td></tr></table></figure><h2 id="Measurement"><a href="#Measurement" class="headerlink" title="Measurement"></a>Measurement</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- create a temperature point</span><br><span class="line">&gt; INSERT temperature,machine=unit42,<span class="built_in">type</span>=assembly external=26,internal=38</span><br><span class="line">&gt; --- select temperature <span class="keyword">for</span> unit42</span><br><span class="line">&gt; SELECT * FROM temperature WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- select specific fields and tags from measurement, NOTE: at least one field must be included</span><br><span class="line">&gt; SELECT <span class="string">"internal"</span>::field, <span class="string">"machine"</span>::tag FROM temperature WHERE <span class="string">"machine"</span> = <span class="string">'unit42'</span></span><br><span class="line">&gt; --- delete metrics from temperature measurement</span><br><span class="line">&gt; DELETE FROM <span class="string">"temperature"</span> WHERE time &lt; <span class="string">'2000-01-01T00:00:00Z'</span></span><br><span class="line">&gt; --- drop the temperature measurement</span><br><span class="line">&gt; DROP MEASUREMENT <span class="string">"temperature"</span></span><br></pre></td></tr></table></figure><h2 id="Query-analysis"><a href="#Query-analysis" class="headerlink" title="Query analysis"></a>Query analysis</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; --- explain the logic behind the query</span><br><span class="line">&gt; EXPLAIN SELECT * FROM temperature</span><br><span class="line">QUERY PLAN</span><br><span class="line">----------</span><br><span class="line">EXPRESSION: &lt;nil&gt;</span><br><span class="line">AUXILIARY FIELDS: external::<span class="built_in">float</span>, internal::<span class="built_in">float</span>, machine::tag, <span class="built_in">type</span>::tag</span><br><span class="line">NUMBER OF SHARDS: 1</span><br><span class="line">NUMBER OF SERIES: 3</span><br><span class="line">CACHED VALUES: 0</span><br><span class="line">NUMBER OF FILES: 6</span><br><span class="line">NUMBER OF BLOCKS: 6</span><br><span class="line">SIZE OF BLOCKS: 204</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.influxdata.com/influxdb/v1.7/query_language/spec/#query-engine-internals">InfluxDB 1.7 Query language</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This article is InfluxDB command cheatsheet about how to interact with influxDB server and query the metrics. The InfluxDB version I tested is &lt;a href=&quot;https://docs.influxdata.com/influxdb/v1.7/&quot;&gt;v1.7.10&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="influxdb" scheme="https://songrgg.github.io/tags/influxdb/"/>
    
  </entry>
  
  <entry>
    <title>how to build the smallest docker image as fast as you can</title>
    <link href="https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/"/>
    <id>https://songrgg.github.io/operation/how-to-build-a-smallest-docker-image/</id>
    <published>2020-03-15T19:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.404Z</updated>
    
    <content type="html"><![CDATA[<p>I’ll use an example to introduce how to build the smallest docker image to your best, a light image will accelerate image rollout and the fast build process will speed up your development cycle.</p><a id="more"></a><h2 id="A-Golang-sample"><a href="#A-Golang-sample" class="headerlink" title="A Golang sample"></a>A Golang sample</h2><p>It’s quite common that we use golang to implement microservice, for example tens of golang service docker images are deployed to the Kubernetes.</p><p>Consider we need to make our first golang service image, it runs the following code as an HTTP server.</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  <span class="string">"net/http"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  http.HandleFunc(<span class="string">"/"</span>, test)</span><br><span class="line">  http.ListenAndServe(<span class="string">":8080"</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class="line">  w.Header().Set(<span class="string">"Service"</span>, <span class="string">"Test"</span>)</span><br><span class="line">  w.WriteHeader(<span class="number">200</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Docker-it"><a href="#Docker-it" class="headerlink" title="Docker it!"></a>Docker it!</h3><p>The intuitive solution is to run <code>go run main.go</code> in the docker, so let’s use golang image as a base image.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span>.<span class="number">0</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/songrgg/testservice/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [ <span class="string">"go"</span>, <span class="string">"run"</span>, <span class="string">"main.go"</span> ]</span></span><br></pre></td></tr></table></figure><p>Run <code>docker build .</code> and it shows</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/4 : FROM golang:1.14.0-alpine</span><br><span class="line"> ---&gt; 51e47ee4db58</span><br><span class="line">Step 2/4 : WORKDIR /go/src/github.com/songrgg/testservice/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8dc325ca7ca6</span><br><span class="line">Step 3/4 : COPY main.go .</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; c46c5f5bfda8</span><br><span class="line">Step 4/4 : CMD [ <span class="string">"go"</span>, <span class="string">"run"</span>, <span class="string">"main.go"</span> ]</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; acc5a6d462f5</span><br><span class="line">Successfully built acc5a6d462f5</span><br><span class="line"></span><br><span class="line">$ docker image inspect acc5a6d462f5 --format=<span class="string">'&#123;&#123;.Size&#125;&#125;'</span></span><br><span class="line">369193951</span><br></pre></td></tr></table></figure><p>It’s 369193951 bytes near <strong>370MB</strong>.</p><h3 id="Reduce-the-unnecessary-files"><a href="#Reduce-the-unnecessary-files" class="headerlink" title="Reduce the unnecessary files"></a>Reduce the unnecessary files</h3><p>Golang is a compilation language which can be packed into a binary, we can reduce the size by only putting the binary into the image.</p><p>We know that the latest docker supports multi-stage builds which can eliminate the intermediate layers effectively, the revised dockerfile looks like this:</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span>.<span class="number">0</span>-alpine</span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/songrgg/testservice/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:latest</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache add ca-certificates</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/github.com/songrgg/testservice/app .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./app"</span>]</span></span><br></pre></td></tr></table></figure><p>Let’s see the layers it generates.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ docker build .</span><br><span class="line">Sending build context to Docker daemon  3.072kB</span><br><span class="line">Step 1/9 : FROM golang:1.14.0-alpine</span><br><span class="line"> ---&gt; 51e47ee4db58</span><br><span class="line">Step 2/9 : WORKDIR /go/src/github.com/songrgg/testservice/</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; 8dc325ca7ca6</span><br><span class="line">Step 3/9 : COPY main.go .</span><br><span class="line"> ---&gt; Using cache</span><br><span class="line"> ---&gt; c46c5f5bfda8</span><br><span class="line">Step 4/9 : RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> be3bdce1ec48</span><br><span class="line">Removing intermediate container be3bdce1ec48</span><br><span class="line"> ---&gt; 9c3470f9e73d</span><br><span class="line">Step 5/9 : FROM alpine:latest</span><br><span class="line"> ---&gt; 053cde6e8953</span><br><span class="line">Step 6/9 : RUN apk --no-cache add ca-certificates</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 6acd18e2d2ba</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gz</span><br><span class="line">fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/community/x86_64/APKINDEX.tar.gz</span><br><span class="line">(1/1) Installing ca-certificates (20161130-r3)</span><br><span class="line">Executing busybox-1.26.2-r7.trigger</span><br><span class="line">Executing ca-certificates-20161130-r3.trigger</span><br><span class="line">OK: 5 MiB <span class="keyword">in</span> 12 packages</span><br><span class="line">Removing intermediate container 6acd18e2d2ba</span><br><span class="line"> ---&gt; 7b4ee3222013</span><br><span class="line">Step 7/9 : WORKDIR /root/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 336a8a2115a6</span><br><span class="line">Removing intermediate container 336a8a2115a6</span><br><span class="line"> ---&gt; 77fa1196ab2f</span><br><span class="line">Step 8/9 : COPY --from=0 /go/src/github.com/songrgg/testservice/app .</span><br><span class="line"> ---&gt; c6bc47f614af</span><br><span class="line">Step 9/9 : CMD [<span class="string">"./app"</span>]</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> f77053027c4b</span><br><span class="line">Removing intermediate container f77053027c4b</span><br><span class="line"> ---&gt; d327f978f1d8</span><br><span class="line">Successfully built d327f978f1d8</span><br><span class="line"></span><br><span class="line">$ docker inspect d327f978f1d8 --format=<span class="string">'&#123;&#123;.Size&#125;&#125;'</span></span><br><span class="line">11924648</span><br></pre></td></tr></table></figure><p>We could notice there are several intermediate containers removed, they’re layers from the first stage and prepare the executable for the second stage.</p><p>Most importantly, the docker image size is below <strong>12MB</strong>.</p><p>The most important factor is we changed the FROM image to alpine which is only <strong>4.2MB</strong>, so the extra size is almost the size of the golang process.</p><h3 id="From-scratch"><a href="#From-scratch" class="headerlink" title="From scratch?"></a>From scratch?</h3><p>Yeah, the base image could be smaller, <code>FROM scratch</code> is a base image that will make the next command to be the first layer in your image.</p><p>I changed the <code>FROM alpine:latest</code> to <code>FROM scratch</code>, the image size is <strong>7MB</strong> now, but I would suggest using alpine because it’ll be hard for you in scratch if you want to debug within the container. So you’ll need a balance between the image size and functionality :)</p><h2 id="Some-pitfalls-you-may-face"><a href="#Some-pitfalls-you-may-face" class="headerlink" title="Some pitfalls you may face"></a>Some pitfalls you may face</h2><h3 id="Unnecessary-large-build-context"><a href="#Unnecessary-large-build-context" class="headerlink" title="Unnecessary large build context"></a>Unnecessary large build context</h3><p>Docker build will send the build context to docker daemon at first, the context is default to the current directory, so please be sure the files in the current directory is necessary or is small enough. If the file size is big, it will affect docker build speed terribly.</p><h3 id="Wrong-command-order"><a href="#Wrong-command-order" class="headerlink" title="Wrong command order"></a>Wrong command order</h3><p>Just remember to put the stable layers before the changeable layers, because docker will cache the layers if they are not changed, it’s calculated by the hash value of their content.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> changeable.txt .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ...</span></span><br></pre></td></tr></table></figure><p>In the above example, every time the changeable.txt is changed, it will rerun every commands after it and waste time doing the things it could prevent. Just turn to the following form.</p><figure class="highlight docker"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update &amp;&amp; apt-get install curl</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ...</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> changeable.txt .</span></span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Best practises for writing Dockerfile</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ll use an example to introduce how to build the smallest docker image to your best, a light image will accelerate image rollout and the fast build process will speed up your development cycle.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="docker" scheme="https://songrgg.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>How to check and monitor SSL certificates expiration with Telegraf</title>
    <link href="https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/"/>
    <id>https://songrgg.github.io/operation/how-to-check-and-monitor-tls-jks-certificates-with-telegraf/</id>
    <published>2020-02-11T21:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.405Z</updated>
    
    <content type="html"><![CDATA[<p>As a developer or operator of a Website, the certificate expiration could happen and make the services not work. I’ll introduce how to monitor certificates like SSL,JKS,P12 using Telegraf.</p><p>Certificates are broadly used for security reasons, they can be used within internal service or public service communication. The most common certificate is TLS used for verifying the identity of the HTTPS service. To increase security, the certificate will not be always valid because of expiration. To prevent the certificate expiry, we should rotate them periodically and meanwhile monitor them and alert if expired. Telegraf is a popular metric collecting tool to implement this.</p><a id="more"></a><h2 id="Overview-for-certificate-types"><a href="#Overview-for-certificate-types" class="headerlink" title="Overview for certificate types"></a>Overview for certificate types</h2><ol><li>.csr<br>Certificate Signing Request used to request a certificate from the certificate authority.</li><li>.pem<br>This is a container format that may include just the public certificate or may include an entire certificate chain including public key, private key, and root certificates. Confusingly, it may also encode a CSR (e.g. as used here) as the PKCS10 format can be translated into PEM.</li><li>.key<br>This is a PEM formatted file containing just the private-key of a specific certificate and is merely a conventional name and not a standardized one.</li><li>.pkcs12 .pfx .p12<br>This is a passworded container format that contains both public and private certificate pairs. Unlike .pem files, this container is fully encrypted. Openssl can turn this into a .pem file with both public and private keys.</li><li>.cert .cer .crt<br>A .pem (or rarely .der) formatted file with a different extension, one that is recognized by Windows Explorer as a certificate, which .pem is not.</li><li>.jks<br>A Java KeyStore (JKS) is a repository of security certificates – either authorization certificates or public key certificates – plus corresponding private keys, used for instance in SSL encryption.</li></ol><h2 id="Check-certificate-expiry-time"><a href="#Check-certificate-expiry-time" class="headerlink" title="Check certificate expiry time"></a>Check certificate expiry time</h2><ol><li><p>check the JKS expiry time</p> <figure class="highlight bash"><figcaption><span>check_jks.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to check keystore.jks expiry time</span></span><br><span class="line">keytool -list -v -keystore keystore.jks -storepass <span class="string">"pass"</span> | grep until</span><br></pre></td></tr></table></figure></li><li><p>check the PKCS#12 expiry time</p> <figure class="highlight bash"><figcaption><span>check_p12.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># to check certicate.p12 expiry time</span></span><br><span class="line">openssl pkcs12 -<span class="keyword">in</span> certicate.p12 -nokeys | openssl x509 -noout -enddate</span><br></pre></td></tr></table></figure></li></ol><h2 id="Customize-telegraf-plugin"><a href="#Customize-telegraf-plugin" class="headerlink" title="Customize telegraf plugin"></a>Customize telegraf plugin</h2><p>In this case, we can use a bash script to collect the metrics and output it as <a href="https://docs.influxdata.com/influxdb/v1.7/write_protocols/line_protocol_tutorial/">influxDB line protocol</a>, it does not need you to use influxDB, you can use any kind of monitoring backend that can read from telegraf, for example, Prometheus.</p><p><a href="https://www.influxdata.com/time-series-platform/telegraf/">Telegraf</a> is a daemon that can be running on servers to collect system metrics, it supports multiple input plugins to collect metrics. <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/exec"><code>intput.exec</code></a> is an input plugin which will run the specified script, the output of the script will be treated as a data point.</p><h3 id="Bash-script-to-generate-the-metric"><a href="#Bash-script-to-generate-the-metric" class="headerlink" title="Bash script to generate the metric"></a>Bash script to generate the metric</h3><p>We can write a bash script to generate an influxDB line formatted metric, the script will use <code>openssl</code> to resolve the certificate.</p><ol><li><p>This is a script used to resolve PKCS#12 files.</p> <figure class="highlight bash"><figcaption><span>generate_p12_metric.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">FILE_PATH=<span class="string">"path-to-pkcs#12-cert"</span></span><br><span class="line">P12_UNTIL=$(openssl pkcs12 -<span class="keyword">in</span> <span class="variable">$FILE_PATH</span> -nokeys 2&gt;/dev/null | openssl x509 -text -noout 2&gt;/dev/null | grep After | sed <span class="string">'s/.*After : //'</span> )</span><br><span class="line"></span><br><span class="line"><span class="comment"># return 1 year when there's no existing file</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$P12_UNTIL</span>"</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$((360*24*60*60)</span>)"</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">P12_UNTIL_EPOCH=$(date +%s --date=<span class="string">"<span class="variable">$P12_UNTIL</span>"</span>)</span><br><span class="line">NOW_EPOCH=$(date +%s)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"pkcs12_cert,source=<span class="variable">$FILE_PATH</span> expiry=<span class="variable">$(($P12_UNTIL_EPOCH-$NOW_EPOCH)</span>) <span class="variable">$&#123;NOW_EPOCH&#125;</span>000000000"</span></span><br></pre></td></tr></table></figure></li><li><p>Another script to resolve the JKS file</p> <figure class="highlight bash"><figcaption><span>generate_jks_metric.sh</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">FILE_PATH=<span class="string">"path-to-jks-cert"</span></span><br><span class="line">KEYSTORE_UNTIL=$(<span class="built_in">echo</span> <span class="string">'dummydummy'</span> | keytool -list -v -keystore <span class="variable">$FILE_PATH</span> 2&gt;/dev/null | grep -i Until  | sed <span class="string">'s/.*until: //'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This may be caused by unexistent file, return 1 year to skip checking.</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">"<span class="variable">$KEYSTORE_UNTIL</span>"</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$((360*24*60*60)</span>)"</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">KEYSTORE_UNTIL_EPOCH=$(date +%s --date=<span class="string">"<span class="variable">$KEYSTORE_UNTIL</span>"</span>)</span><br><span class="line">NOW_EPOCH=$(date +%s)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"jks_cert,source=<span class="variable">$FILE_PATH</span> expiry=<span class="variable">$(($KEYSTORE_UNTIL_EPOCH-$NOW_EPOCH)</span>) <span class="variable">$&#123;NOW_EPOCH&#125;</span>000000000"</span></span><br></pre></td></tr></table></figure></li><li><p>X509 Cert<br>There’s an <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/x509_cert">X509 Cert Input Plugin</a> already there.</p></li></ol><h3 id="Telegraf-configuration"><a href="#Telegraf-configuration" class="headerlink" title="Telegraf configuration"></a>Telegraf configuration</h3><p>Put the <code>jks_cert.conf</code> under the telegraf’s configuration folder, restart telegraf and it will take effect.</p><figure class="highlight"><figcaption><span>jks_cert.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[[inputs.exec]]</span></span><br><span class="line">  commands = [ "/usr/local/bin/jks_certificate_metric.sh" ]</span><br><span class="line"></span><br><span class="line">  data_format = "influx"</span><br></pre></td></tr></table></figure><h3 id="What’s-next"><a href="#What’s-next" class="headerlink" title="What’s next"></a>What’s next</h3><p>Connect the data Telegraf collected to Time series database like Prometheus, InfluxDB, Graphite, and show them with Grafana.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file">What is a pem file and how does it differ from other OpenSSL generated key files?</a></li><li><a href="https://pingtool.org/openssl-check-p12-expiration-date/">OpenSSL check p12 expiration date</a></li><li><a href="https://serverfault.com/questions/9708/what-is-a-pem-file-and-how-does-it-differ-from-other-openssl-generated-key-file">What is a PEM file and how does it differ from other OpenSSL generated key file</a></li><li><a href="https://en.wikipedia.org/wiki/PKCS_12">pkcs#12</a></li><li><a href="https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs">OpenSSL essentials</a></li><li><a href="https://www.digitalocean.com/community/tutorials/java-keytool-essentials-working-with-java-keystores">Java keytool essentials</a></li><li><a href="https://en.wikipedia.org/wiki/Java_KeyStore">Java KeyStore</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;As a developer or operator of a Website, the certificate expiration could happen and make the services not work. I’ll introduce how to monitor certificates like SSL,JKS,P12 using Telegraf.&lt;/p&gt;
&lt;p&gt;Certificates are broadly used for security reasons, they can be used within internal service or public service communication. The most common certificate is TLS used for verifying the identity of the HTTPS service. To increase security, the certificate will not be always valid because of expiration. To prevent the certificate expiry, we should rotate them periodically and meanwhile monitor them and alert if expired. Telegraf is a popular metric collecting tool to implement this.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="certificate" scheme="https://songrgg.github.io/tags/certificate/"/>
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
  </entry>
  
  <entry>
    <title>Practice datacenter failover in production</title>
    <link href="https://songrgg.github.io/operation/practice-datacenter-failover-in-production/"/>
    <id>https://songrgg.github.io/operation/practice-datacenter-failover-in-production/</id>
    <published>2019-12-12T23:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.413Z</updated>
    
    <content type="html"><![CDATA[<p>Distributed system is like human body, it will have issues and break. There’s a theory that we feed it with issues deliberately and constantly, the body will be more and more stable and robust. It’s the same to system, put some issues to datacenters and let them failover automatically.</p><a id="more"></a><h3 id="Multiple-data-centers"><a href="#Multiple-data-centers" class="headerlink" title="Multiple data centers"></a>Multiple data centers</h3><p>Companies use data center redundancy to implement service’s high availability, there will be multiple data centers existing with 3 main deployments:</p><ol><li>Disaster Recovery<br>You will have your live traffic served in the primary data center, meanwhile disaster recovery data center is a backup to recover when the primary is down. Usually, it doesn’t allow you to run normal operations in the disaster recovery one.</li><li>Hot Standby<br>The primary data center is taking traffic, the hot standby data center is almost equivalent to primary but doesn’t take traffic. You can switch to hot standby anytime the primary data center is down.</li><li>Live traffic handling<br>There are multiple data centers and they’re taking traffic simultaneously.</li></ol><h3 id="What-is-DC-failover"><a href="#What-is-DC-failover" class="headerlink" title="What is DC failover?"></a>What is DC failover?</h3><p>When dc ( data center ) failure happens, the most emergent thing is to use the backup dc to replace the primary one and ensures the business keeps running, so the technical team will failover the data center to backup one.</p><!-- more --><h3 id="Why-do-we-need-to-do-failover-often"><a href="#Why-do-we-need-to-do-failover-often" class="headerlink" title="Why do we need to do failover often?"></a>Why do we need to do failover often?</h3><p>In the deployments mentioned before, there will be one or more data centers serving user, once the primary one is down the backup one needs to take over as soon as possible, but it’s not often that the primary data center is down, as the time flies, likely, backup datacenter cannot replace the primary or is hard to replace.<br>To keep the backup dc up-to-date, we should do dc failover often regardless manually or automatically.</p><h2 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h2><h3 id="Define-the-impact"><a href="#Define-the-impact" class="headerlink" title="Define the impact"></a>Define the impact</h3><p>Service is always for customers, although failover is a long-term project that will improve the service’s availability, it’s better not to interrupt the customer’s experience all of a sudden, so according to different company’s considerations, they need to define the impact they can undertake.</p><h3 id="Define-the-scope"><a href="#Define-the-scope" class="headerlink" title="Define the scope"></a>Define the scope</h3><p>After the company decides to practice data center failover in production, there will be a lot of questions to answer, “What’s the scale of this failover?”, “Is it global or partial?”, “What consequences can I bear or how much budget do we have?”, “who should participate in”…<br>Such questions can define the scope of the failover, how many business lines should participate in it, how many teams, how many people will join.</p><h3 id="Define-the-goal"><a href="#Define-the-goal" class="headerlink" title="Define the goal"></a>Define the goal</h3><p>Also, define the goal clearly, it’s a long term project that ensures there will be always multiple available data centers online, this failover is the first time and will repeat very soon, finally, it’ll be continuous and automatic like chaos engineering.</p><h3 id="Team-as-unit"><a href="#Team-as-unit" class="headerlink" title="Team as unit"></a>Team as unit</h3><p>Every team involved should take care of the servers, services… they need to failover when the failover day comes, the team is the minimal unit.</p><h3 id="Deadline"><a href="#Deadline" class="headerlink" title="Deadline"></a>Deadline</h3><p>“Deadline is the first productivity”, since the failover may not seem to be important to everyone, teams may not put them to the priority, so the deadline is a clear signal it will happen sooner or later.</p><h3 id="From-an-SRE’s-perspective"><a href="#From-an-SRE’s-perspective" class="headerlink" title="From an SRE’s perspective"></a>From an SRE’s perspective</h3><p>As an SRE, I play a vital role in this failover and will execute the operations.</p><ul><li>You should have a full list of your services.</li><li>Get your operation documentation ready, for example, the operation commands and monitoring dashboard addresses.</li><li>Mini failovers can be done gradually before the entire one.</li></ul><h2 id="When-the-day-comes"><a href="#When-the-day-comes" class="headerlink" title="When the day comes"></a>When the day comes</h2><h3 id="A-clear-agenda"><a href="#A-clear-agenda" class="headerlink" title="A clear agenda"></a>A clear agenda</h3><p>A clear agenda is a precondition that everything is under control even if something unexpected happens. Take the unexpected into consideration and make the agenda more flexible.</p><h3 id="Instant-communication"><a href="#Instant-communication" class="headerlink" title="Instant communication"></a>Instant communication</h3><p>For the team, the progress must be understood by every team member and their clients.<br>Also, it’s necessary to put everything unexpected into a global channel and everyone is aware of it.</p><h3 id="Roles-we-play"><a href="#Roles-we-play" class="headerlink" title="Roles we play"></a>Roles we play</h3><p>The coordinator is the one who’s responsible for connecting all the team players, (s)he’s responsible for recording the matters happening including success and failure, other team players should report what they’ve done and seen to the coordinator.</p><h2 id="After-the-failover"><a href="#After-the-failover" class="headerlink" title="After the failover"></a>After the failover</h2><p>After the failover, teams involved in this failover should look back and check what’s the good part and what needs to be improved.<br>Against the weakness, we can make some plans and put them into the backlog, we’ll be more confident facing the next failover.<br>I will spend more time on chaos engineering which is the continuous accidents injection to production and will bring production more resilience.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://blog.serverdensity.com/multi-data-center-redundancy-application-considerations/">Multiple data center redundancy</a></li><li><a href="https://principlesofchaos.org/?lang=ENcontent">Principles of Chaos Engineering</a> </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Distributed system is like human body, it will have issues and break. There’s a theory that we feed it with issues deliberately and constantly, the body will be more and more stable and robust. It’s the same to system, put some issues to datacenters and let them failover automatically.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="distributed system" scheme="https://songrgg.github.io/tags/distributed-system/"/>
    
      <category term="data center failover" scheme="https://songrgg.github.io/tags/data-center-failover/"/>
    
      <category term="resilience" scheme="https://songrgg.github.io/tags/resilience/"/>
    
      <category term="chaos engineering" scheme="https://songrgg.github.io/tags/chaos-engineering/"/>
    
  </entry>
  
  <entry>
    <title>Generate monitoring dashboards &amp; alertings using Grafana API</title>
    <link href="https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/"/>
    <id>https://songrgg.github.io/operation/use-grafana-api-generate-dashboards/</id>
    <published>2019-09-22T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.415Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://grafana.com">Grafana</a> has been adopted as a common monitoring dashboard by more and more companies, in many cases, when operators need to create dashboard repeatedly they either choose to use template variables or create dashboards one by one. I think it’s very useful to leverage the <a href="https://grafana.com/docs/http_api/">Grafana API</a> to generate the monitoring dashboards automatically from template.</p><a id="more"></a><h2 id="My-thought-on-dashboard-automation"><a href="#My-thought-on-dashboard-automation" class="headerlink" title="My thought on dashboard automation"></a>My thought on dashboard automation</h2><p>There’s a common use case, if you need to create a lot of similar dashboard (like system stats) for different services, the dashboard skeleton may always be the same, you can use template variables to make the difference. However, you can not create alertings on the graphs which use template variables, so in these situations you have to create graphs without variables.</p><p>So we can create a template dashboard first with variables in Grafana, then use scripts to read from the template and render them with variables we specify, finally call Grafana APIs to create/update dashboards.</p><ol><li><p>Listen to what dashboards we need to create/update, collect metadata first.<br>For example, if it’s for server stats, we need to get the server info from cloud provider or other infrastructure.</p></li><li><p>Trigger the change to the dashboard</p><ul><li>Create the template of dashboard with template variables, it’s okay, we’ll replace the template later.</li><li>Render the template with the metadata we collected.</li><li>Add the graphs using CRUD APIs.</li></ul></li></ol><h2 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h2><p>Metadata is what you need to generate dashboards, basically it contains:</p><ol><li>How many dashboards you want to create?</li><li>What are each dashboard’s variables?<br>If you use public cloud providers, cloud APIs can be used otherwise you have your own infrastructure management APIs.</li></ol><h2 id="Template-dashboard"><a href="#Template-dashboard" class="headerlink" title="Template dashboard"></a>Template dashboard</h2><p><a href="https://grafana.com/docs/reference/templating/">Grafana Variables</a> is a good functionality for monitor a great number of servers or application, defining the template dashboard with variables is good for rendering because you can not only view the effect on the template but also the variable is easy to replace for the format is <code>$VARIABLE</code> or <code>[[VARIABLE]]</code>, string replacement is enough for this.<br><img src="/images/grafana_variables_dashboard.webp" alt="Grafana Variables"></p><h3 id="Grafana-dashboard-CRUD-API"><a href="#Grafana-dashboard-CRUD-API" class="headerlink" title="Grafana dashboard CRUD API"></a>Grafana dashboard CRUD API</h3><p>Grafana provides enough HTTP APIs to do this, once you create the template dashboard it already has the graphs and alertings, so <a href="https://grafana.com/docs/http_api/dashboard/">Grafana dashboard API</a> is enough for most cases.</p><p>For authentication, you can create a service account for automating the dashboards and use API token to call APIs.</p><p>The automation scripts can maintain a relationship between the dashboard UID and dashboard name and you can also do the change comparison before updating the dashboards.<br>Delete the dashboards when some of them are deprecated.</p><h3 id="Run-your-automation"><a href="#Run-your-automation" class="headerlink" title="Run your automation"></a>Run your automation</h3><p>It’s okay to run automation scripts as cronjobs.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li><a href="https://grafana.com/docs/http_api/dashboard/">Grafana dashboard API</a></li><li><a href="https://grafana.com/docs/http_api/alerting/">Grafana alerting API</a> is only used to get alerts, if you need to modify the alerts using dashboard API</li><li><a href="https://grafana.com/docs/tutorials/api_org_token_howto/">Grafana API token</a></li><li><a href="https://github.com/grafana-tools/sdk">Grafana SDK</a></li><li><a href="https://grafana.com/docs/reference/dashboard/">Grafana dashboard reference</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://grafana.com&quot;&gt;Grafana&lt;/a&gt; has been adopted as a common monitoring dashboard by more and more companies, in many cases, when operators need to create dashboard repeatedly they either choose to use template variables or create dashboards one by one. I think it’s very useful to leverage the &lt;a href=&quot;https://grafana.com/docs/http_api/&quot;&gt;Grafana API&lt;/a&gt; to generate the monitoring dashboards automatically from template.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="monitoring" scheme="https://songrgg.github.io/tags/monitoring/"/>
    
      <category term="grafana" scheme="https://songrgg.github.io/tags/grafana/"/>
    
      <category term="automation" scheme="https://songrgg.github.io/tags/automation/"/>
    
      <category term="alerting" scheme="https://songrgg.github.io/tags/alerting/"/>
    
  </entry>
  
  <entry>
    <title>How to install Spinnaker on CentOS 7</title>
    <link href="https://songrgg.github.io/operation/install-spinnaker-on-centos/"/>
    <id>https://songrgg.github.io/operation/install-spinnaker-on-centos/</id>
    <published>2019-09-18T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.407Z</updated>
    
    <content type="html"><![CDATA[<p>Spinnaker doesn’t support installation on CentOS machine, this article introduces how to use Docker to install Spinnaker components on CentOS directly.</p><p>As we know, according to the spinnaker’s official documentation, spinnaker provides a tool for installing the spinnaker cluster in Kubernetes cluster or debian/ubuntu bare metal machine, but there’s not an option to install it on CentOS or other common operating systems. Althogh the <a href="https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose">spinnaker</a> provides a way to start Spinnaker with <a href="https://docs.docker.com/compose/">Docker Compose</a>, but it’s out of date. So I created a new <a href="https://github.com/songrgg/spinnaker-compose">docker-compose project</a> to quickstart a spinnaker cluster on any kind of os.</p><a id="more"></a><h2 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart</h2><p>Provision a machine with at least 16GB memory and 4 cores, it may need more than this since my macbook pro(4cores, 16GB) was stuck when I started spinnaker.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/songrgg/spinnaker-compose</span><br><span class="line"><span class="built_in">cd</span> spinnaker-compose</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><h2 id="To-access-the-spinnaker"><a href="#To-access-the-spinnaker" class="headerlink" title="To access the spinnaker"></a>To access the spinnaker</h2><p>Visit <code>http://localhost:9000</code> in browser if you run spinnaker on local machine.</p><p>Otherwise you can use ssh to create tunnel on local machine. Spinnaker exposes two ports, 9000 for web, 8084 for api gateway.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 8084:localhost:8084 &lt;remote-host&gt;</span><br><span class="line">ssh -L 9000:localhost:9000 &lt;remote-host&gt;</span><br></pre></td></tr></table></figure><h2 id="Add-clouddriver"><a href="#Add-clouddriver" class="headerlink" title="Add clouddriver"></a>Add clouddriver</h2><p>You need to edit <code>config/clouddriver.yml</code> to open multiple clouddrivers, it’s not easy to integrate since we don’t have the <code>halyard</code> to do this stuff, but if you already have the clouddriver.yml, it’s easier to make it work.</p><p>Since clouddriver will need credentials, you need to modify the <code>docker-compose.yml</code> to mount the credential files on the docker containers.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spinnaker doesn’t support installation on CentOS machine, this article introduces how to use Docker to install Spinnaker components on CentOS directly.&lt;/p&gt;
&lt;p&gt;As we know, according to the spinnaker’s official documentation, spinnaker provides a tool for installing the spinnaker cluster in Kubernetes cluster or debian/ubuntu bare metal machine, but there’s not an option to install it on CentOS or other common operating systems. Althogh the &lt;a href=&quot;https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose&quot;&gt;spinnaker&lt;/a&gt; provides a way to start Spinnaker with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker Compose&lt;/a&gt;, but it’s out of date. So I created a new &lt;a href=&quot;https://github.com/songrgg/spinnaker-compose&quot;&gt;docker-compose project&lt;/a&gt; to quickstart a spinnaker cluster on any kind of os.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="spinnaker" scheme="https://songrgg.github.io/tags/spinnaker/"/>
    
      <category term="docker" scheme="https://songrgg.github.io/tags/docker/"/>
    
      <category term="centos" scheme="https://songrgg.github.io/tags/centos/"/>
    
  </entry>
  
  <entry>
    <title>How to host Swagger documentation using yaml/json configuration files?</title>
    <link href="https://songrgg.github.io/operation/host-swagger-documentation-with-yaml-json-files/"/>
    <id>https://songrgg.github.io/operation/host-swagger-documentation-with-yaml-json-files/</id>
    <published>2019-09-12T19:11:50.000Z</published>
    <updated>2020-03-29T16:20:56.815Z</updated>
    
    <content type="html"><![CDATA[<html><head></head><body><p>Maintain the swagger documentation by <a href="https://editor.swagger.io">Swagger Editor</a> and then you can use the yaml files to generate online swagger documentation easily with <a href="https://spring.io/projects/spring-boot">Spring boot</a>.</p><a id="more"></a><h2 id="Workflow-for-Swagger-documentation"><a href="#Workflow-for-Swagger-documentation" class="headerlink" title="Workflow for Swagger documentation"></a>Workflow for Swagger documentation</h2><ol><li>Update swagger documentation with Swagger Editor, export the yaml files</li><li>Update the yaml files in Spring boot project</li><li>Redeploy the Spring boot project</li></ol><h2 id="How-to-setup-in-Spring-boot"><a href="#How-to-setup-in-Spring-boot" class="headerlink" title="How to setup in Spring boot?"></a>How to setup in Spring boot?</h2><p>Swagger provides swagger-ui and some jars to host a documentation, you can use Java annotations or yaml files to autogenerate the swagger documentation. The example below is using static yaml files to generate documentation.</p><p>Demo project: <a href="https://github.com/songrgg/swaggerdemo">https://github.com/songrgg/swaggerdemo</a></p><p><strong>src/main/resources/static/swagger-apis/api1/swagger.yaml</strong><br>The static yaml file is fetched from Swagger Editor, put it under the resources directory.</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">swagger:</span> <span class="string">"2.0"</span></span><br><span class="line"><span class="attr">info:</span></span><br><span class="line">  <span class="attr">description:</span> <span class="string">"This is a sample server Petstore server.  You can find out more about     Swagger at [http://swagger.io](http://swagger.io) or on [irc.freenode.net, #swagger](http://swagger.io/irc/).      For this sample, you can use the api key `special-key` to test the authorization     filters."</span></span><br><span class="line">  <span class="attr">version:</span> <span class="string">"1.0.0"</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">"Swagger Petstore"</span></span><br><span class="line">  <span class="attr">termsOfService:</span> <span class="string">"http://swagger.io/terms/"</span></span><br><span class="line">  <span class="attr">contact:</span></span><br><span class="line">    <span class="attr">email:</span> <span class="string">"apiteam@swagger.io"</span></span><br><span class="line">  <span class="attr">license:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">"Apache 2.0"</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">"http://www.apache.org/licenses/LICENSE-2.0.html"</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></tbody></table></figure><p><strong>Application.java</strong></p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableSwagger</span>2</span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SwaggerDemoApplication</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>{</span><br><span class="line">        SpringApplication.run(SwaggerDemoApplication<span class="class">.<span class="keyword">class</span>, <span class="title">args</span>)</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Docket <span class="title">swagger</span><span class="params">()</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Docket(SWAGGER_2)</span><br><span class="line">            .select()</span><br><span class="line">            .apis(RequestHandlerSelectors.any())</span><br><span class="line">            .paths(PathSelectors.any())</span><br><span class="line">            .build();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>SwaggerSpecConfig.java</strong><br>Read the static yaml files:<br><code>src/main/resources/swagger-apis/api1/swagger.yaml</code> and <code>src/main/resources/swagger-apis/api2/swagger.yaml</code>.</p><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SwaggerSpecConfig</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Primary</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SwaggerResourcesProvider <span class="title">swaggerResourcesProvider</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        InMemorySwaggerResourcesProvider defaultResourcesProvider)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> () -> {</span><br><span class="line">            List<SwaggerResource> resources = <span class="keyword">new</span> ArrayList<>();</span><br><span class="line">            Arrays.asList(<span class="string">"api1"</span>, <span class="string">"api2"</span>)</span><br><span class="line">                .forEach(resourceName -> resources.add(loadResource(resourceName)));</span><br><span class="line">            <span class="keyword">return</span> resources;</span><br><span class="line">        };</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> SwaggerResource <span class="title">loadResource</span><span class="params">(String resource)</span> </span>{</span><br><span class="line">        SwaggerResource wsResource = <span class="keyword">new</span> SwaggerResource();</span><br><span class="line">        wsResource.setName(resource);</span><br><span class="line">        wsResource.setSwaggerVersion(<span class="string">"2.0"</span>);</span><br><span class="line">        wsResource.setLocation(<span class="string">"/swagger-apis/"</span> + resource + <span class="string">"/swagger.yaml"</span>);</span><br><span class="line">        <span class="keyword">return</span> wsResource;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>pom.xml</strong></p><figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag"><<span class="name">dependency</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">groupId</span>></span>io.springfox<span class="tag"></<span class="name">groupId</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">artifactId</span>></span>springfox-swagger-common<span class="tag"></<span class="name">artifactId</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">version</span>></span>2.9.2<span class="tag"></<span class="name">version</span>></span></span><br><span class="line"><span class="tag"></<span class="name">dependency</span>></span></span><br><span class="line"></span><br><span class="line"><span class="tag"><<span class="name">dependency</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">groupId</span>></span>io.springfox<span class="tag"></<span class="name">groupId</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">artifactId</span>></span>springfox-swagger-ui<span class="tag"></<span class="name">artifactId</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">version</span>></span>2.9.2<span class="tag"></<span class="name">version</span>></span></span><br><span class="line"><span class="tag"></<span class="name">dependency</span>></span></span><br><span class="line"></span><br><span class="line"><span class="tag"><<span class="name">dependency</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">groupId</span>></span>io.springfox<span class="tag"></<span class="name">groupId</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">artifactId</span>></span>springfox-swagger2<span class="tag"></<span class="name">artifactId</span>></span></span><br><span class="line">    <span class="tag"><<span class="name">version</span>></span>2.9.2<span class="tag"></<span class="name">version</span>></span></span><br><span class="line"><span class="tag"></<span class="name">dependency</span>></span></span><br></pre></td></tr></tbody></table></figure><p>Run the spring boot server and access <code><hostname>/swagger-ui.html</code> to see the documentation.</p></body></html>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Maintain the swagger documentation by &lt;a href=&quot;https://editor.swagger.io&quot;&gt;Swagger Editor&lt;/a&gt; and then you can use the yaml files to generate online swagger documentation easily with &lt;a href=&quot;https://spring.io/projects/spring-boot&quot;&gt;Spring boot&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="swagger" scheme="https://songrgg.github.io/tags/swagger/"/>
    
      <category term="spring boot" scheme="https://songrgg.github.io/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>My first Hackathon: bring Spinnaker to my company</title>
    <link href="https://songrgg.github.io/operation/hackathon-spinnaker/"/>
    <id>https://songrgg.github.io/operation/hackathon-spinnaker/</id>
    <published>2019-09-11T21:11:50.000Z</published>
    <updated>2020-03-20T19:02:13.401Z</updated>
    
    <content type="html"><![CDATA[<p>I’ve joined my first Hackathon and worked on a project about using <a href="https://www.spinnaker.io">Spinnaker</a> as CI/CD tool within company. The biggest challenge is to install Spinnaker on CentOS 7 with <a href="https://docs.docker.com/compose/">docker-compose</a>.</p><h2 id="Why-Spinnaker"><a href="#Why-Spinnaker" class="headerlink" title="Why Spinnaker?"></a>Why Spinnaker?</h2><ul><li>Spinnaker is dedicated to deploy services across multiple cloud providers and the integration with AWS, GCP, Azure is out of box.</li><li>It’s focused on deploy stably, support full control of workflow, developers can customize the deployment flow to improve the quality of deployment, also it’s automatic.</li><li>You will have a Web UI.</li></ul><a id="more"></a><h2 id="How-to-use-Spinnaker"><a href="#How-to-use-Spinnaker" class="headerlink" title="How to use Spinnaker?"></a>How to use Spinnaker?</h2><p>Spinnaker can integrate with VCS like Github, Gitlab, Gitbucket, docker registry.<br>For example the workflow of deploy golang github project to Kubernetes cluster.</p><ol><li>A developer pushes code to Github repository, it triggers the Travis-CI that starts the test, build, package stages, a docker image is pushed to Docker repository finally.</li><li>Spinnaker has a trigger on the Docker repository and starts to deploy that image to a Kubernetes cluster in some cloud provider.</li><li>The deployment workflow includes Deploy to staging, Canary Deployment, Deploy to production.</li></ol><h2 id="Details-of-this-hackathon"><a href="#Details-of-this-hackathon" class="headerlink" title="Details of this hackathon"></a>Details of this hackathon</h2><p>Our goal is to start a Spinnaker cluster and create a pipeline that can deploy the Git project to AWS and our own Kubernetes cluster.<br>There’re some contraints for this hackathon, I’m still new to the company so maybe it’s because of my limited information.</p><ol><li>I don’t have a Kuberntes cluster with API server’s access right, that means I can’t deploy Spinnaker cluster to Kubernetes.</li><li>I don’t have a Debian/Ubuntu machine, that means I can’t start Spinnaker on a bare metal with <a href="https://www.spinnaker.io/setup/install/halyard/">Halyard</a>.</li><li>The Spinnaker need to be deployed within company’s infrastructure which is not any cloud provider, otherwise it can’t communicate with other infrastructure.</li></ol><p>And what does Spinnaker need? It needs Halyard to configure the Spinnaker cluster, it will control where Spinnaker cluster is deployed, as we know Spinnaker itself is composed of microservices, hard to deploy on bare metal. Especially for its cloud provider settings, so Spinnaker relies on Halyard heavily, and every time the Spinnaker cluster update and upgrade can be managed safely.</p><p>Sadly, Halyard is only used for deploying Spinnaker itself to Kubernetes or  some cloud providers and Debian/Ubuntu single machine. Then according to our constraints above, we lose every chance to use that tool. Maybe it’s time to give up :(</p><p>We didn’t give up, choose to install Spinnaker cluster the hardest way. Install Spinnaker cluster on Bare metal machine which is CentOS 7, for running the cluster easier, we use Docker to start each components.</p><p><img src="/images/spin-dependencies.webp" alt="Spinnaker microservice dependencies"></p><p>My colleague found <code>docker-compose.yml</code> in <a href="https://github.com/spinnaker/spinnaker/tree/master/experimental/docker-compose">Spinnaker</a>, but the latest modification time was 4 years ago. After trying so many times we still couldn’t make it, I tried to give up actually, and also it was far away from quickstart and wasted so much time.</p><p>Actually I didn’t give up, I returned home and thought if the Spinnaker cluster can be deployed in Kubernetes, it can be deployed with Docker compose, since they didn’t have any difference.</p><p>So I chose the most stupid method, I created a Spinnaker cluster on GCP with far less time and rewrote the <code>docker-compose.yml</code> according to:</p><ol><li>Check each Kubernetes Pod’s yaml file to get the environment variables, image name, arguments…</li><li>Login to the containers to fetch the mounted configuration files like clouddriver.yml, front50.yml, gate.yml… Yes, they’re generated by Halyard where the comment says <code>DONT&#39;T EDIT THIS FILE, IT&#39;S AUTOGENERATED BY...</code>.</li></ol><p>After another X hours, without ignoring every details, I migrated all the Kubernetes configuration to <code>docker-compose.yml</code>, the second when I ran the <code>docker-compose up -d</code> and every microservice was labeled <code>DONE</code> and <code>http://localhost:9000</code> worked.</p><h2 id="Reflection-of-this-hackathon"><a href="#Reflection-of-this-hackathon" class="headerlink" title="Reflection of this hackathon"></a>Reflection of this hackathon</h2><p>Yes, it’s not a happy ending for my first hackathon, our team didn’t reach our goal, there’s some experience for this time.</p><p><strong>Gain</strong></p><ol><li>The hardest way to know how the Spinnaker configuration works, how it deploys.</li><li>I felt some joy when the installation was successful :)</li><li>Some knowledge about the GCP (first time to use GCP)</li></ol><p><strong>Improvements next time</strong></p><ol><li>Team member can be closer, whatever the seat we sit or the communication channel we talked, time is presious, we need check our progress frequently.</li><li>Fail fast, although this time I worked out the installation, but it was not a great result, next time we should help the team member to tackle the most important task.</li><li>Prepare enough, time is precious, if you want to make it in the Hackathon project, do some preparations, it’s not cheat!</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’ve joined my first Hackathon and worked on a project about using &lt;a href=&quot;https://www.spinnaker.io&quot;&gt;Spinnaker&lt;/a&gt; as CI/CD tool within company. The biggest challenge is to install Spinnaker on CentOS 7 with &lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;docker-compose&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Why-Spinnaker&quot;&gt;&lt;a href=&quot;#Why-Spinnaker&quot; class=&quot;headerlink&quot; title=&quot;Why Spinnaker?&quot;&gt;&lt;/a&gt;Why Spinnaker?&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Spinnaker is dedicated to deploy services across multiple cloud providers and the integration with AWS, GCP, Azure is out of box.&lt;/li&gt;
&lt;li&gt;It’s focused on deploy stably, support full control of workflow, developers can customize the deployment flow to improve the quality of deployment, also it’s automatic.&lt;/li&gt;
&lt;li&gt;You will have a Web UI.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="sre" scheme="https://songrgg.github.io/tags/sre/"/>
    
      <category term="cicd" scheme="https://songrgg.github.io/tags/cicd/"/>
    
      <category term="spinnaker" scheme="https://songrgg.github.io/tags/spinnaker/"/>
    
      <category term="docker-compose" scheme="https://songrgg.github.io/tags/docker-compose/"/>
    
  </entry>
  
  <entry>
    <title>Anatomy of envoy proxy: the architecture of envoy and how it works</title>
    <link href="https://songrgg.github.io/architecture/deeper-understanding-to-envoy/"/>
    <id>https://songrgg.github.io/architecture/deeper-understanding-to-envoy/</id>
    <published>2019-08-13T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.397Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.envoyproxy.io">Envoy</a> has become more and more popular, the basic functionality is quite similar to <a href="https://www.nginx.com/">Nginx</a>, working as a high performace Web server, proxy. But Enovy imported a lot of features that was related to <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">SOA</a> or <a href="https://en.wikipedia.org/wiki/Microservices">Microservice</a> like Service Discovery, Circuit Breaker, Rate limiting and so on. </p><p>A lot of developers know the roles envoy plays, and the basic functionality it will implement, but don’t know how it organize the architecture and how we understand its configuration well. For me, it’s not easy to understand envoy’s architecture and its configuration since it has a lot of terminology, but if the developer knew how the user traffic goes, he could understand the design of envoy.</p><a id="more"></a><h3 id="Envoy-In-Servicemesh"><a href="#Envoy-In-Servicemesh" class="headerlink" title="Envoy In Servicemesh"></a>Envoy In Servicemesh</h3><p>Recently, more and more companies take Service Mesh to solve the communication problem among backend services, it’s a typical use case for envoy to work as a basic component for building a service mesh, envoy plays an important role and one of the service mesh solution <a href="https://istio.io">Istio</a> uses Envoy as the core of the networking.</p><p><img src="/images/envoy-in-service-mesh.webp" alt="envoy in service mesh"></p><p>As pictured, the Envoy is deployed beside every application, this kind of application we call it <code>Sidecar</code>.</p><p>Let’s analyze how the user traffic moves.</p><ol><li>The user hits the website and the browser tries to query an API, the api gateway receives the user request.</li><li>The API Gateway redirects the request to the backend server1 (in Kubernetes, it can be a Pod)</li><li>The envoy on backend server receives this HTTP request and resolves it to the destination server and forwards the request to the local destination port which APP1 listens at.</li><li>The APP1 receives requests, processes the bussiness logic and tries to call a dependent RPC service in APP2, the request first is sent to local envoy.</li><li>The local envoy resolves the RPC service APP2’s IP address and port according to the management server and sends the RPC request to APP2 server.</li><li>The server where the RPC service located at recevies the request,  to be clear, it’s the envoy receiving the request, after the same logic like step 3.</li><li>The APP2 processes the request and returns.</li><li>The envoy forwards the response to server1.</li><li>There’re two forwards being ignored, envoy(1) to APP1, APP1 to envoy(1). Then the envoy(1) returns the reponse to API gateway.</li><li>The API gateway returns to the user.</li></ol><p>The management server is responsible for telling envoy how to process the requests and where to forward.<br>Service discovery is where applications register themselves.</p><h4 id="Ingress-and-Egress"><a href="#Ingress-and-Egress" class="headerlink" title="Ingress and Egress"></a>Ingress and Egress</h4><p>As you can see, there’re two kinds of traffic within a server: ingress and egress.</p><ul><li>Any traffic sent to server, it’s ingress.</li><li>Any traffic sent from server, it’s egress.</li></ul><p>How to implement this transparently?</p><ul><li><p>Setup <strong>IPtables</strong> to redirect any traffic to this server to the envoy service first, then envoy redirects the traffic to the real application on this server.</p></li><li><p>Setup <strong>IPtables</strong> to redirect any traffic from this server to the envoy service first and envoy resolves the destination service using Service Discovery, redirects the request to the destination server.</p></li></ul><p>By intercepting the inbound and outbound traffic, envoy can implement the service discovery, circuit breaker, rate limiting, monitoring transparently, the developers don’t need to care about the details or integrate libraries.</p><h3 id="Anatomy-of-envoy-proxy-configuration"><a href="#Anatomy-of-envoy-proxy-configuration" class="headerlink" title="Anatomy of envoy proxy configuration"></a>Anatomy of envoy proxy configuration</h3><p>The first important role of envoy in the service mesh is <strong>proxy</strong>, it receives requests and forwards requests.<br>To see the components that make the proxy work, we can start with a request flow.</p><p><img src="/images/envoy-config.webp" alt="How Envoy Configuration works"></p><ol><li>A request reaches a port on the server which envoy listens at, we call this part <strong>listener</strong>.</li><li>Envoy receives the request and tries to process this request according to some rule, the rule is <strong>route</strong>.</li><li>The route processes the request based on the request’s metadata and tries to request the specific backend servers, the backend servers are called <strong>cluster</strong>.</li><li>The concrete server IP:port behind cluster is called <strong>endpoint</strong>.</li></ol><p>It’s the main part of envoy components in most of the proxy cases, similar to Nginx, you’re allowed to setup all the configuration by static files.</p><p>Here is an example with static configuration, you can see the full file <a href="https://github.com/envoyproxy/envoy/blob/master/examples/front-proxy/front-envoy.yaml">here</a>.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">static_resources:</span></span><br><span class="line">  <span class="attr">listeners:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">address:</span></span><br><span class="line">      <span class="attr">socket_address:</span></span><br><span class="line">        <span class="attr">address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">        <span class="attr">port_value:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">filter_chains:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">filters:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">envoy.http_connection_manager</span></span><br><span class="line">        <span class="attr">typed_config:</span></span><br><span class="line">          <span class="string">"@type"</span><span class="string">:</span> <span class="string">type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager</span></span><br><span class="line">          <span class="attr">codec_type:</span> <span class="string">auto</span></span><br><span class="line">          <span class="attr">stat_prefix:</span> <span class="string">ingress_http</span></span><br><span class="line">          <span class="attr">route_config:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">local_route</span></span><br><span class="line">            <span class="attr">virtual_hosts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">backend</span></span><br><span class="line">              <span class="attr">domains:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="string">"*"</span></span><br><span class="line">              <span class="attr">routes:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">                  <span class="attr">prefix:</span> <span class="string">"/service/1"</span></span><br><span class="line">                <span class="attr">route:</span></span><br><span class="line">                  <span class="attr">cluster:</span> <span class="string">service1</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">                  <span class="attr">prefix:</span> <span class="string">"/service/2"</span></span><br><span class="line">                <span class="attr">route:</span></span><br><span class="line">                  <span class="attr">cluster:</span> <span class="string">service2</span></span><br><span class="line">          <span class="attr">http_filters:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">envoy.router</span></span><br><span class="line">            <span class="attr">typed_config:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">  <span class="attr">clusters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service1</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">strict_dns</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">round_robin</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">service1</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="string">service1</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">80</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">service2</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">strict_dns</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">round_robin</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">service2</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="string">service2</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>Don’t be nervous, you can understand this configuration easily by order:</p><ul><li>listener<br>It says the envoy listens at 0.0.0.0:80</li><li>route<br>It tells how to process request, there’s a route named local_route, a rule matching wildcard domain and forwards the request to <code>service1</code> cluster if the request path’s prefix matches <code>/service/1</code>, else forwards to <code>service2</code> cluster if the request path’s prefix matches <code>service/2</code>.</li><li>cluster<br>Finally, the <code>service1</code> cluster memtioned before is resolved to several endpoints, it’s the real address of the server, the address is <code>service1:80</code>.</li></ul><p>So the basic structure of the configuration is quite straightforward and easy to understand, if you want to manipulate the configuration and don’t know where to start, you can refer to this sample and every data model inside can be found in envoy documentation.</p><p>But most importantly, it’s allowed to use <strong>dynamic configuration</strong> which is mostly used in SOA and Microservice, it fits the situations where the service’s endpoints and route rules may change anytime.</p><p>For using dynamic resources, envoy supports setting an API server and divides the above components into different APIs or different resources within an API.</p><ul><li>LDS: listener<br>The listener discovery service (LDS) is an optional API that Envoy will call to dynamically fetch listeners. Envoy will reconcile the API response and add, modify, or remove known listeners depending on what is required.</li><li>RDS: route<br>The route discovery service (RDS) API is an optional API that Envoy will call to dynamically fetch route configurations. A route configuration includes both HTTP header modifications, virtual hosts, and the individual route entries contained within each virtual host.</li><li>CDS: cluster<br>The cluster discovery service (CDS) is an optional API that Envoy will call to dynamically fetch cluster manager members. Envoy will reconcile the API response and add, modify, or remove known clusters depending on what is required.</li><li>EDS: endpoint<br>The endpoint discovery service is a xDS management server based on gRPC or REST-JSON API server used by Envoy to fetch cluster members. The cluster members are called “endpoint” in Envoy terminology. For each cluster, Envoy fetch the endpoints from the discovery service.</li></ul><p>The concept is equal to the static configuration, you can initialize the configuration by</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">admin:</span></span><br><span class="line">  <span class="attr">access_log_path:</span> <span class="string">/tmp/admin_access.log</span></span><br><span class="line">  <span class="attr">address:</span></span><br><span class="line">    <span class="attr">socket_address:</span> <span class="string">&#123;</span> <span class="attr">address:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">,</span> <span class="attr">port_value:</span> <span class="number">9901</span> <span class="string">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">dynamic_resources:</span></span><br><span class="line">  <span class="attr">lds_config:</span></span><br><span class="line">    <span class="attr">api_config_source:</span></span><br><span class="line">      <span class="attr">api_type:</span> <span class="string">GRPC</span></span><br><span class="line">      <span class="attr">grpc_services:</span></span><br><span class="line">        <span class="attr">envoy_grpc:</span></span><br><span class="line">          <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line">  <span class="attr">cds_config:</span></span><br><span class="line">    <span class="attr">api_config_source:</span></span><br><span class="line">      <span class="attr">api_type:</span> <span class="string">GRPC</span></span><br><span class="line">      <span class="attr">grpc_services:</span></span><br><span class="line">        <span class="attr">envoy_grpc:</span></span><br><span class="line">          <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line"></span><br><span class="line"><span class="attr">static_resources:</span></span><br><span class="line">  <span class="attr">clusters:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">xds_cluster</span></span><br><span class="line">    <span class="attr">connect_timeout:</span> <span class="number">0.</span><span class="string">25s</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">STATIC</span></span><br><span class="line">    <span class="attr">lb_policy:</span> <span class="string">ROUND_ROBIN</span></span><br><span class="line">    <span class="attr">http2_protocol_options:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">upstream_connection_options:</span></span><br><span class="line">      <span class="comment"># configure a TCP keep-alive to detect and reconnect to the admin</span></span><br><span class="line">      <span class="comment"># server in the event of a TCP socket half open connection</span></span><br><span class="line">      <span class="attr">tcp_keepalive:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">    <span class="attr">load_assignment:</span></span><br><span class="line">      <span class="attr">cluster_name:</span> <span class="string">xds_cluster</span></span><br><span class="line">      <span class="attr">endpoints:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">lb_endpoints:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">endpoint:</span></span><br><span class="line">            <span class="attr">address:</span></span><br><span class="line">              <span class="attr">socket_address:</span></span><br><span class="line">                <span class="attr">address:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">                <span class="attr">port_value:</span> <span class="number">5678</span></span><br></pre></td></tr></table></figure><p>The only static resource is the xds_cluster which is the management server cluster which provides <strong>a GRPC streaming API</strong> answering the LDS, CDS, EDS, RDS configuration.<br>As you notice, there’re only lds_config and cds_config inside the config file, that’s because rds is included in lds and eds is included in cds.</p><p>In Service Mesh architecture, the management server is the most important module, it always connects to a distributed service discovery system which can be <a href="https://etcd.io">Etcd</a>, <a href="https://zookeeper.apache.org">Zookeeper</a>, <a href="https://www.consul.io">Consul</a>, <a href="https://github.com/Netflix/eureka">Eureka</a> or the Kubernetes(Kubernetes often used Etcd as their service discovery component), and provide some interfaces to manipulate the configuration to implement near-realtime configuration change.</p><h2 id="Conclustion"><a href="#Conclustion" class="headerlink" title="Conclustion"></a>Conclustion</h2><p>Understanding how the user traffic flows makes it easier for me to understand the component design of envoy and have a first glimpse of the envoy configuration, then you can start with more features later.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://www.envoyproxy.io&quot;&gt;Envoy&lt;/a&gt; has become more and more popular, the basic functionality is quite similar to &lt;a href=&quot;https://www.nginx.com/&quot;&gt;Nginx&lt;/a&gt;, working as a high performace Web server, proxy. But Enovy imported a lot of features that was related to &lt;a href=&quot;https://en.wikipedia.org/wiki/Service-oriented_architecture&quot;&gt;SOA&lt;/a&gt; or &lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot;&gt;Microservice&lt;/a&gt; like Service Discovery, Circuit Breaker, Rate limiting and so on. &lt;/p&gt;
&lt;p&gt;A lot of developers know the roles envoy plays, and the basic functionality it will implement, but don’t know how it organize the architecture and how we understand its configuration well. For me, it’s not easy to understand envoy’s architecture and its configuration since it has a lot of terminology, but if the developer knew how the user traffic goes, he could understand the design of envoy.&lt;/p&gt;
    
    </summary>
    
    
      <category term="architecture" scheme="https://songrgg.github.io/categories/architecture/"/>
    
    
      <category term="envoy" scheme="https://songrgg.github.io/tags/envoy/"/>
    
      <category term="service mesh" scheme="https://songrgg.github.io/tags/service-mesh/"/>
    
      <category term="architecture" scheme="https://songrgg.github.io/tags/architecture/"/>
    
      <category term="request analysis" scheme="https://songrgg.github.io/tags/request-analysis/"/>
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Istio Version Control On Kubernetes</title>
    <link href="https://songrgg.github.io/operation/istio-version-control-on-k8s/"/>
    <id>https://songrgg.github.io/operation/istio-version-control-on-k8s/</id>
    <published>2019-03-28T18:10:00.000Z</published>
    <updated>2020-03-20T19:02:13.409Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://istio.io">Istio</a> has been adopted as a common implementation of <a href="https://istio.io/docs/concepts/what-is-istio/">service mesh</a>, since more and more companies want to bring Istio into production, the version control of Istio seems a significant problem to solve.</p><p>Version control is necessary as Istio components can be treated as the equivalent RPC services like our business services, we need to have an understanding of which version we are using now and what does the next version bring. And some Istio components can cooperate with the others, if we need to upgrade one component we need to upgrade the other components too.</p><p>Although the Istio community provides the Istio upgrade method, we don’t actually want to upgrade such a whole thing in one move, it influences so much that we don’t want to risk.</p><a id="more"></a><h3 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h3><p><a href="https://helm.sh">Helm</a> is package control system for Kubernetes, it’s more like the complicated version of brew on Mac.</p><p>It uses Yaml and Golang templates to formulate a complete application configuration on Kubernetes. A lot of applications are packaged as Helm charts, we can build a complicated application by declaring the dependencies between these charts.</p><h3 id="Istio-Helm"><a href="#Istio-Helm" class="headerlink" title="Istio + Helm"></a>Istio + Helm</h3><p>Istio project contains the <a href="https://github.com/istio/istio/blob/master/install/kubernetes/helm/istio/README.md">Helm configuration</a> itself, I recommend the users to extract the Helm brought by Istio into a standalone Git repository.</p><p><img src="/images/istio-helm-git.webp" alt="istio-helm-git"></p><p>Like the other services, we use Git to control each component’s configuration and track every modification.</p><h3 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI/CD"></a>CI/CD</h3><p>As more and more people advocate <code>infrastructure as code</code>, we not only store the Istio Helm as a Git repository, we bring the CI/CD to the infrastructure.</p><p>If three Kubernetes clusters: <code>test</code>, <code>stage</code>, <code>production</code> exist, we can setup CI/CD to <code>test</code> cluster based on the specified Git <code>test</code> branch, each commit will trigger the generation of the latest Istio K8S Yaml config and apply them to the <code>test</code> cluster, after the tests on <code>test</code> environment, we brought the Istio updates to the <code>stage</code> and <code>production</code> in order.</p><h3 id="Still-worried-about-Production"><a href="#Still-worried-about-Production" class="headerlink" title="Still worried about Production?"></a>Still worried about Production?</h3><p>Although we have tested in the <code>test</code> environment, we still worry if it works in the <code>production</code> and a method to let you know what actually changes is to <strong>diff</strong> the K8S configuration between the latest config and the current K8S config.<br>I recommend the <a href="https://github.com/weaveworks/kubediff"><code>kubediff</code></a> tool to distinguish the differences.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul><li>Every updates to Istio configuration need to be tracked by Git. </li><li>Like the common services, deploy the change to <code>test</code> environment as soon as possible to fail fast.</li><li>Use <code>kubediff</code> to show the changes.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://istio.io&quot;&gt;Istio&lt;/a&gt; has been adopted as a common implementation of &lt;a href=&quot;https://istio.io/docs/concepts/what-is-istio/&quot;&gt;service mesh&lt;/a&gt;, since more and more companies want to bring Istio into production, the version control of Istio seems a significant problem to solve.&lt;/p&gt;
&lt;p&gt;Version control is necessary as Istio components can be treated as the equivalent RPC services like our business services, we need to have an understanding of which version we are using now and what does the next version bring. And some Istio components can cooperate with the others, if we need to upgrade one component we need to upgrade the other components too.&lt;/p&gt;
&lt;p&gt;Although the Istio community provides the Istio upgrade method, we don’t actually want to upgrade such a whole thing in one move, it influences so much that we don’t want to risk.&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="configuration management" scheme="https://songrgg.github.io/tags/configuration-management/"/>
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="istio" scheme="https://songrgg.github.io/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>再见，micro: 迁移go-micro到纯gRPC框架</title>
    <link href="https://songrgg.github.io/microservice/goodbye-micro/"/>
    <id>https://songrgg.github.io/microservice/goodbye-micro/</id>
    <published>2018-10-27T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.399Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/micro/micro">micro</a>是基于golang的微服务框架，之前华尔街见闻架构升级中谈到了我们是基于go-micro的后端架构，随着我们对服务网格的调研、测试和实施，为了打通不同语言之间的服务调用，我们选择了gRPC作为服务内部的通用协议。</p><p>go-micro框架的架构非常具有拓展性，它拥有自己的RPC框架，通过抽象codec,transport,selector等微服务组件，你既可以使用官方实现的各种插件<a href="https://github.com/micro/go-plugins">go-plugins</a>进行组装，又可以根据实际的情况实现自己的组件。然而，我们打算利用服务网格的优势，将微服务的基础组件下沉到基础设施中去，将组件代码从代码库中剥离开来。</p><p>这样一来，我们相当于只需要最简的RPC框架，只需要服务之间有统一、稳定、高效的通信协议，由于micro在我们新架构中略显臃肿，于是我们选择逐渐剥除micro。还有一个重要原因，我们选择的服务网格方案是istio，它的代理原生支持gRPC，而micro只是将gRPC当做transport层，相当于复写了gRPC的服务路由逻辑，这样有损于istio的一些特性，譬如流量监控等功能。</p><p>出于这些考虑，第一步需要将micro改成纯gRPC模式，这里的改造部分我们考虑只应该去更改基础库的代码，而尽量不要使业务代码更改，减少对已有逻辑的影响，和一些软性的譬如开发人员的工作量。</p><a id="more"></a><h2 id="服务发现模块"><a href="#服务发现模块" class="headerlink" title="服务发现模块"></a>服务发现模块</h2><p>istio的服务发现支持etcd、consul等，我们需要将其改成使用kubernetes的服务名进行访问。通过实现<a href="https://gist.github.com/songrgg/22999fb7ab76a30dcac17cb28ed412d4">istio selector</a>的方式，我们将RPC调用的服务名与k8s的服务名端口做映射。</p><figure class="highlight go"><figcaption><span>register.go</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> istio</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/micro/go-micro/registry"</span></span><br><span class="line"><span class="string">"github.com/micro/go-micro/selector"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">svcPort = <span class="number">10088</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">serviceHostMapping = <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>&#123;</span><br><span class="line"><span class="string">"payment"</span>: <span class="string">"payment.common"</span>,</span><br><span class="line"><span class="string">"content"</span>: <span class="string">"content.ns1"</span>,</span><br><span class="line"><span class="string">"user"</span>:    <span class="string">"user.ns1"</span>,</span><br><span class="line">&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> istio <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *istio)</span> <span class="title">Select</span><span class="params">(service <span class="keyword">string</span>, opts ...selector.SelectOption)</span> <span class="params">(selector.Next, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> host, exist := serviceHostMapping[service]; exist &#123;</span><br><span class="line">node := &amp;registry.Node&#123;</span><br><span class="line">Id:      service,</span><br><span class="line">Address: host,</span><br><span class="line">Port:    svcPort,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="params">(*registry.Node, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> node, <span class="literal">nil</span></span><br><span class="line">&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">"service %s(%s) not found"</span>, service, svc)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这里注意的是由于服务之间调用需要指定service name和端口，所以在这里我们把端口设置了一个magic number。</p><h2 id="传输模块"><a href="#传输模块" class="headerlink" title="传输模块"></a>传输模块</h2><p>go-micro采用各种协议作为传输报文的工具，可以从<a href="https://github.com/micro/go-plugins/tree/master/transport">transport</a>中了解到，有http/grpc/tcp/utp等，我们曾先后使用过tcp、utp、gRPC，经过测试gRPC是其中最为稳定的。之前提到过gRPC只是作为传输信道，micro定义了自己的RPC接口，实现了RPC的路由、传输、重试等功能，通过自定义了protobuf的插件生成符合micro标准的proto文件。</p><p>为了向后兼容，在使用grpc替换原RPC时，我也需要根据protobuf文件生成新的golang代码，其中包括client端、server端代码的变更，实际上我的更新是针对<a href="https://github.com/golang/protobuf/tree/master/protoc-gen-go">protoc-gen-go</a>，fork之后修改<a href="https://github.com/golang/protobuf/blob/master/protoc-gen-go/grpc/grpc.go">grpc/grpc.go</a>部分，在<code>func generateService()</code>中对Client端代码进行micro的适配。</p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *someClient)</span> <span class="title">DoSomething</span><span class="params">(ctx context.Context, in *SomeRequest, opts ...grpc.CallOption)</span> <span class="params">(*SomeResponse, error)</span></span></span><br></pre></td></tr></table></figure><h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><p>Server端代码的更新除了接口的适配，有一个关注点是micro的接口设计是</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DoSomething(context.Context, *SomeRequest, *SomeResponse) error</span><br></pre></td></tr></table></figure><p>而gRPC是</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DoSomething(context.Context, *SomeRequest) (*SomeResponse, error)</span><br></pre></td></tr></table></figure><p>micro接口设计的好处是支持服务端缓存的应用，当服务端handler触发时，cache interceptor可以将response缓存，当缓存命中时可以将其返回。而由于gRPC的版本将response放在了返回值中，运行时无法将譬如redis中字符串格式的response解码成<code>SomeResponse</code>，而micro版本由于将其放在了参数位置，所以可以通过</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json.Unmarshall([]<span class="keyword">byte</span>(<span class="string">""</span>), &amp;SomeResponse&#123;&#125;)</span><br></pre></td></tr></table></figure><p>从字符串恢复response。</p><p>我们的做法是不改变接口的设计，而是在自动生成的golang代码中，在interceptor运行之前将response object塞入context。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Server</span></span><br><span class="line">ctx = ctx.WithValue(<span class="string">"IstioResponseBody"</span>, &amp;SomeResponse&#123;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Interceptor</span></span><br><span class="line">obj := ctx.Value(<span class="string">"IstioResponseBody"</span>)</span><br><span class="line">json.Unmarshall([]<span class="keyword">byte</span>(<span class="string">""</span>), obj)</span><br></pre></td></tr></table></figure><h2 id="Interceptor模块"><a href="#Interceptor模块" class="headerlink" title="Interceptor模块"></a>Interceptor模块</h2><p>一些interceptor的迁移工作，例如logger、cache、recover等。</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol><li><p>向后兼容<br>更新的过程开发人员实际上并不是特别感兴趣，我们SRE能做的是对他们基本上无改动，第一个版本不要让开发感知。虽然实际上测试时由于我们的变动，测试环境不断受到稳定性质疑。</p></li><li><p>micro和gRPC的context传递不同<br>gRPC是基于http2，metadata是基于HTTP header传递，Client利用<code>metadata.NewOutgoingContext(ctx, MD)</code>携带metadata，而Server端利用<code>metadata.FromIncomingContext(ctx)</code>提取metadata。而micro则用<code>context.WithValue(metaKey{}, MD)</code>传递。</p></li><li><p>使用环境变量做一些特殊处理<br>我们通过环境变量在基础库里做了一些判断，在新老架构并存下进行一些特殊处理，譬如刚才说到的metadata获取逻辑。</p></li><li><p>关于proto自动生成<br>我们通过在CI中配置istio版本镜像的编译打包逻辑和原有逻辑共存，在编译前我们运行proto编译工具，生成gRPC的golang文件，从而打出新的镜像。</p></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>micro陪伴了我们一年多的时间，期间它的架构设计给了我们很大的弹性可以去适配一些我们的架构，可以选择很多好的开源工具，譬如zipkin、prometheus、etcd等，适合于刚上微服务不久的项目进行技术摸索和选择，而这一年的时间，我们的架构也逐渐明晰和稳定，我们更倾向于一个精简的基础库，并且由于在线项目的不断增加，运维成本可以通过下沉基础组件进行降低。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://github.com/micro/micro&quot;&gt;micro&lt;/a&gt;是基于golang的微服务框架，之前华尔街见闻架构升级中谈到了我们是基于go-micro的后端架构，随着我们对服务网格的调研、测试和实施，为了打通不同语言之间的服务调用，我们选择了gRPC作为服务内部的通用协议。&lt;/p&gt;
&lt;p&gt;go-micro框架的架构非常具有拓展性，它拥有自己的RPC框架，通过抽象codec,transport,selector等微服务组件，你既可以使用官方实现的各种插件&lt;a href=&quot;https://github.com/micro/go-plugins&quot;&gt;go-plugins&lt;/a&gt;进行组装，又可以根据实际的情况实现自己的组件。然而，我们打算利用服务网格的优势，将微服务的基础组件下沉到基础设施中去，将组件代码从代码库中剥离开来。&lt;/p&gt;
&lt;p&gt;这样一来，我们相当于只需要最简的RPC框架，只需要服务之间有统一、稳定、高效的通信协议，由于micro在我们新架构中略显臃肿，于是我们选择逐渐剥除micro。还有一个重要原因，我们选择的服务网格方案是istio，它的代理原生支持gRPC，而micro只是将gRPC当做transport层，相当于复写了gRPC的服务路由逻辑，这样有损于istio的一些特性，譬如流量监控等功能。&lt;/p&gt;
&lt;p&gt;出于这些考虑，第一步需要将micro改成纯gRPC模式，这里的改造部分我们考虑只应该去更改基础库的代码，而尽量不要使业务代码更改，减少对已有逻辑的影响，和一些软性的譬如开发人员的工作量。&lt;/p&gt;
    
    </summary>
    
    
      <category term="microservice" scheme="https://songrgg.github.io/categories/microservice/"/>
    
    
      <category term="microservice" scheme="https://songrgg.github.io/tags/microservice/"/>
    
      <category term="go-micro" scheme="https://songrgg.github.io/tags/go-micro/"/>
    
      <category term="gRPC" scheme="https://songrgg.github.io/tags/gRPC/"/>
    
      <category term="migration" scheme="https://songrgg.github.io/tags/migration/"/>
    
  </entry>
  
  <entry>
    <title>gRPC Golang Client Connection Test</title>
    <link href="https://songrgg.github.io/programming/grpc-go-client-performance-test/"/>
    <id>https://songrgg.github.io/programming/grpc-go-client-performance-test/</id>
    <published>2018-09-24T23:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.400Z</updated>
    
    <content type="html"><![CDATA[<p>gRPC is a well-known RPC protocol and a lot of companies adopted it as an internal communication protocol because of its robustness and stability. To use it more efficiently, I’ve done some experiments about how to maximize the gRPC client concurrency.</p><a id="more"></a><h2 id="3-Tests"><a href="#3-Tests" class="headerlink" title="3 Tests"></a>3 Tests</h2><ol><li>One connection per request<br>Create a connection when request is made.</li><li>Only one client, one connection<br>Use a common client by all requests.</li><li>Fixed-size Connection pool<br>If connection pool has enough connections, take it from pool, otherwise create a new connection.<br>The connection pool has fixed max capacity, release unused connection to pool when it’s not full.</li></ol><h2 id="Performance-Comparison"><a href="#Performance-Comparison" class="headerlink" title="Performance Comparison"></a>Performance Comparison</h2><p><strong>Hardware</strong><br>MacBook Pro (15-inch, 2016)<br>Processor 2.7 GHz Intel Core i7<br>Memory 16GB 2133 MHz LPDDR3</p><p><strong>Press tool, client and server run on the same machine</strong></p><h3 id="When-server-just-says-hello-to-client"><a href="#When-server-just-says-hello-to-client" class="headerlink" title="When server just says hello to client"></a>When server just says hello to client</h3><ol><li>Only one client, one connection <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency     2.85ms    1.24ms  22.24ms   80.47%</span><br><span class="line">    Req/Sec    15.86k     2.86k   21.58k    76.50%</span><br><span class="line">  316674 requests <span class="keyword">in</span> 10.04s, 38.66MB <span class="built_in">read</span></span><br><span class="line">Requests/sec:  31532.58</span><br><span class="line">Transfer/sec:      3.85MB</span><br></pre></td></tr></table></figure></li><li>Fixed-size Connection pool<br>Take connection from pool first, otherwise create a new connection. <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    36.86ms   34.35ms 334.72ms   83.30%</span><br><span class="line">    Req/Sec     1.58k   660.95     3.89k    67.86%</span><br><span class="line">  31127 requests <span class="keyword">in</span> 10.04s, 3.80MB <span class="built_in">read</span></span><br><span class="line">Requests/sec:   3100.89</span><br><span class="line">Transfer/sec:    387.61KB</span><br></pre></td></tr></table></figure></li><li>One connection per request<br>Close to the second result, about 3000 Requests/sec</li></ol><h3 id="When-server-sleeps-0-5s-and-says-hello-to-client"><a href="#When-server-sleeps-0-5s-and-says-hello-to-client" class="headerlink" title="When server sleeps 0.5s and says hello to client"></a>When server sleeps 0.5s and says hello to client</h3><ol><li><p>Only one client, one connection</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   503.43ms    1.95ms 511.62ms   64.35%</span><br><span class="line">    Req/Sec   130.60    119.12   485.00     80.85%</span><br><span class="line">  2000 requests <span class="keyword">in</span> 10.10s, 250.00KB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    198.04</span><br><span class="line">Transfer/sec:     24.75KB</span><br></pre></td></tr></table></figure></li><li><p>Fixed-size Connection pool  </p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   504.44ms    5.14ms 529.46ms   92.58%</span><br><span class="line">    Req/Sec   119.40     95.83   470.00     85.11%</span><br><span class="line">  1901 requests <span class="keyword">in</span> 10.07s, 237.62KB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    188.80</span><br><span class="line">Transfer/sec:     23.60KB</span><br></pre></td></tr></table></figure></li><li><p>one connection per request</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ wrk -t2 -c100 -d10s http://localhost:10099/performance</span><br><span class="line">Running 10s <span class="built_in">test</span> @ http://localhost:10099/performance</span><br><span class="line">  2 threads and 100 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   509.30ms    4.85ms 529.65ms   73.74%</span><br><span class="line">    Req/Sec   188.81    188.12   494.00     71.23%</span><br><span class="line">  1900 requests <span class="keyword">in</span> 10.06s, 237.50KB <span class="built_in">read</span></span><br><span class="line">Requests/sec:    188.89</span><br><span class="line">Transfer/sec:     23.61KB</span><br></pre></td></tr></table></figure></li></ol><h2 id="Sample-Code"><a href="#Sample-Code" class="headerlink" title="Sample Code"></a>Sample Code</h2><p>Find <a href="https://github.com/songrgg/go-experiments/tree/master/grpc/clientconn_test">sample code</a></p><h2 id="Some-Results"><a href="#Some-Results" class="headerlink" title="Some Results"></a>Some Results</h2><p>In gereral, use shared grpc client rather than use a customized connection pool. </p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://grpc.io">grpc</a><br><a href="https://mycodesmells.com/post/pooling-grpc-connections">pooling-grpc-connections</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;gRPC is a well-known RPC protocol and a lot of companies adopted it as an internal communication protocol because of its robustness and stability. To use it more efficiently, I’ve done some experiments about how to maximize the gRPC client concurrency.&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="gRPC" scheme="https://songrgg.github.io/tags/gRPC/"/>
    
      <category term="client performance" scheme="https://songrgg.github.io/tags/client-performance/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes DNS拓展</title>
    <link href="https://songrgg.github.io/operation/extend-kubernetes-dns/"/>
    <id>https://songrgg.github.io/operation/extend-kubernetes-dns/</id>
    <published>2018-08-18T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.399Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes DNS在内部服务与外部服务交互，内部服务与内部服务，内部服务与云托管服务交互的工具，拓展DNS可以在内部服务访问集群外服务时像访问集群内服务一样，通过DNS映射将统一风格的域名映射到可访问的IP，而不需要影响内部服务的运行，这里介绍如何使用Consul来拓展DNS。</p><a id="more"></a><h3 id="自定义域名解析"><a href="#自定义域名解析" class="headerlink" title="自定义域名解析"></a>自定义域名解析</h3><p>拓展DNS的方法就是为特定规则的域名指定DNS服务器，在ConfigMap中设置指定域名相对的dns server，如<code>consul.local</code>结尾的域名使用<code>10.150.0.1</code>来解析。</p><figure class="highlight yaml"><figcaption><span>ConfigMap</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-dns</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">stubDomains:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">&#123;"consul.local":</span> <span class="string">["10.150.0.1"]&#125;</span></span><br><span class="line">  <span class="attr">upstreamNameservers:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">["172.16.0.1"]</span></span><br></pre></td></tr></table></figure><p>自定义规则不对<strong>dnsPolicy</strong>为<code>Default</code>或<code>None</code>的Pod起作用，只有当<code>ClusterFirst</code>时，域名解析会按照stubDomains和upstreamNameservers来解析。<br><strong>无自定义配置</strong>: 任何不匹配集群域名后缀的请求，被转发给节点的dns.<br><strong>自定义</strong>: 如果stub和upstream配置，按照如下顺序</p><ol><li>带集群后缀的，请求转发给kube-dns</li><li>stub后缀的，转发给指定的dns</li><li>其它的转发给upstream dns</li></ol><h3 id="Consul-as-a-DNS"><a href="#Consul-as-a-DNS" class="headerlink" title="Consul as a DNS"></a>Consul as a DNS</h3><p><a href="https://consul.io/">Consul</a>是Golang实现的服务发现工具，同时支持DNS解析，通过HTTP API动态添加服务发现节点实现动态DNS解析。</p><ul><li><p>注册Redis1到redis</p><figure class="highlight json"><figcaption><span>dns.json</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ID"</span>: <span class="string">"redis1"</span>,</span><br><span class="line">  <span class="attr">"Name"</span>: <span class="string">"redis"</span>,</span><br><span class="line">  <span class="attr">"Tags"</span>: [</span><br><span class="line">    <span class="string">"primary"</span>,</span><br><span class="line">    <span class="string">"v1"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">  <span class="attr">"Port"</span>: <span class="number">8000</span>,</span><br><span class="line">  <span class="attr">"Meta"</span>: &#123;</span><br><span class="line">    <span class="attr">"redis_version"</span>: <span class="string">"4.0"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"EnableTagOverride"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XPUT http://localhost:8500/v1/agent/service/register -d @dns.json</span><br></pre></td></tr></table></figure></li><li><p>使用DNS查询</p><figure class="highlight bash"><figcaption><span>dig redis service</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ dig @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line">; (1 server found)</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 6823</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 3</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;redis.service.consul.INSRV</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">redis.service.consul.0INSRV1 1 8000 srjiangs-MacBook-Pro.local.node.dc1.consul.</span><br><span class="line"></span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN A 127.0.0.1</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN TXT <span class="string">"consul-network-segment="</span></span><br></pre></td></tr></table></figure></li><li><p>注册多个Redis</p><figure class="highlight json"><figcaption><span>dns.json</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"ID"</span>: <span class="string">"redis2"</span>,</span><br><span class="line">  <span class="attr">"Name"</span>: <span class="string">"redis"</span>,</span><br><span class="line">  <span class="attr">"Tags"</span>: [</span><br><span class="line">    <span class="string">"primary"</span>,</span><br><span class="line">    <span class="string">"v1"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">  <span class="attr">"Port"</span>: <span class="number">8000</span>,</span><br><span class="line">  <span class="attr">"Meta"</span>: &#123;</span><br><span class="line">    <span class="attr">"redis_version"</span>: <span class="string">"4.0"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"EnableTagOverride"</span>: <span class="literal">false</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><figcaption><span>register</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -XPUT http://localhost:8500/v1/agent/service/register -d @dns.json</span><br></pre></td></tr></table></figure></li><li><p>DNS查询</p><figure class="highlight bash"><figcaption><span>dig</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ dig @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @127.0.0.1 -p 8600 redis.service.consul SRV</span><br><span class="line">; (1 server found)</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 11920</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 5</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; OPT PSEUDOSECTION:</span><br><span class="line">; EDNS: version: 0, flags:; udp: 4096</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;redis.service.consul.INSRV</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">redis.service.consul.0INSRV1 1 9000 srjiangs-MacBook-Pro.local.node.dc1.consul.</span><br><span class="line">redis.service.consul.0INSRV1 1 8000 srjiangs-MacBook-Pro.local.node.dc1.consul.</span><br><span class="line"></span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN A 127.0.0.1</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN TXT <span class="string">"consul-network-segment="</span></span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN A 127.0.0.1</span><br><span class="line">srjiangs-MacBook-Pro.local.node.dc1.consul. 0 IN TXT <span class="string">"consul-network-segment="</span></span><br><span class="line"></span><br><span class="line">;; Query time: 0 msec</span><br><span class="line">;; SERVER: 127.0.0.1<span class="comment">#8600(127.0.0.1)</span></span><br><span class="line">;; WHEN: Thu Aug 16 16:47:43 CST 2018</span><br><span class="line">;; MSG SIZE  rcvd: 277</span><br></pre></td></tr></table></figure></li><li><p>Consul Service</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://localhost:8500/v1/agent/services</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"redis1"</span>: &#123;</span><br><span class="line">        <span class="string">"ID"</span>: <span class="string">"redis1"</span>,</span><br><span class="line">        <span class="string">"Service"</span>: <span class="string">"redis"</span>,</span><br><span class="line">        <span class="string">"Tags"</span>: [</span><br><span class="line">            <span class="string">"primary"</span>,</span><br><span class="line">            <span class="string">"v1"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="string">"Port"</span>: 8000,</span><br><span class="line">        <span class="string">"EnableTagOverride"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"CreateIndex"</span>: 0,</span><br><span class="line">        <span class="string">"ModifyIndex"</span>: 0</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"redis2"</span>: &#123;</span><br><span class="line">        <span class="string">"ID"</span>: <span class="string">"redis2"</span>,</span><br><span class="line">        <span class="string">"Service"</span>: <span class="string">"redis"</span>,</span><br><span class="line">        <span class="string">"Tags"</span>: [</span><br><span class="line">            <span class="string">"primary"</span>,</span><br><span class="line">            <span class="string">"v1"</span></span><br><span class="line">        ],</span><br><span class="line">        <span class="string">"Address"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="string">"Port"</span>: 9000,</span><br><span class="line">        <span class="string">"EnableTagOverride"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"CreateIndex"</span>: 0,</span><br><span class="line">        <span class="string">"ModifyIndex"</span>: 0</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="更多细节"><a href="#更多细节" class="headerlink" title="更多细节"></a>更多细节</h3><ul><li>根据集群DC返回该数据中心能访问到的DNS</li><li>动态添加域名和IP映射</li></ul><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><ol><li><p><a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/">Customizing DNS Service - Kubernetes</a></p></li><li><p><a href="https://github.com/skynetservices/skydns">GitHub - skynetservices/skydns: DNS service discovery for etcd</a></p></li><li><p><a href="https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/">Adding entries to Pod /etc/hosts with HostAliases - Kubernetes</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes DNS在内部服务与外部服务交互，内部服务与内部服务，内部服务与云托管服务交互的工具，拓展DNS可以在内部服务访问集群外服务时像访问集群内服务一样，通过DNS映射将统一风格的域名映射到可访问的IP，而不需要影响内部服务的运行，这里介绍如何使用Consul来拓展DNS。&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
  </entry>
  
  <entry>
    <title>以Kubernetes sidecar方式部署Nginx: 提供更好的Web性能</title>
    <link href="https://songrgg.github.io/operation/nginx-kubernetes-sidecar-for-better-performance/"/>
    <id>https://songrgg.github.io/operation/nginx-kubernetes-sidecar-for-better-performance/</id>
    <published>2018-04-22T19:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.412Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Web-server’s-gzip"><a href="#Web-server’s-gzip" class="headerlink" title="Web server’s gzip"></a>Web server’s gzip</h3><p>Web服务开启数据压缩，有利于节省带宽。服务器根据客户端请求头所带的<code>Accept-Encoding</code>判断是否需要对返回数据进行压缩，通常支持的压缩格式是gzip。</p><h3 id="应用gzip-or-Nginx-gzip"><a href="#应用gzip-or-Nginx-gzip" class="headerlink" title="应用gzip or Nginx gzip"></a>应用gzip or Nginx gzip</h3><p>开发人员可以选择在Web framework中开发一些middleware来实现Gzip，也可以选择使用Nginx gzip，将所有gzip放在nginx中完成。</p><p>放在nginx中实现的优势是nginx中gzip性能优秀，能很大程度地减少gzip带来的消耗，像Golang中系统自带库中实现的gzip性能上相比nginx就差很多，并且需要使用对象池进行优化，避免每次创建gzip对象带来的性能损耗，在CPU和内存上占用较大。</p><h3 id="使用Nginx-gzip替代应用gzip"><a href="#使用Nginx-gzip替代应用gzip" class="headerlink" title="使用Nginx gzip替代应用gzip"></a>使用Nginx gzip替代应用gzip</h3><p>如果使用Nginx实现的gzip，那么部署的时候可以有几种方案。</p><ol><li><p>集中式nginx集群<br>nginx集中部署，通过配置反向代理服务各种应用，优势是部署方便，集中管理。劣势是更新路由也是牵一发动全身，并且需要及时拓容。</p></li><li><p>每个实例搭配nginx<br>原本对外暴露的应用现在通过nginx代理，1:1的方式部署，不用担心拓容的问题。需要解决的就是如何保证它们打包部署。</p></li></ol><h3 id="Sidecar-in-Kubernetes"><a href="#Sidecar-in-Kubernetes" class="headerlink" title="Sidecar in Kubernetes"></a>Sidecar in Kubernetes</h3><p>这里讨论Kubernetes中部署Web服务的情况，遇到刚才的方案二，可以在Kubernetes中找到非常匹配的部署方法。</p><p>Kubernetes中最小部署单位称为Pod，Pod中可以部署1个以上的功能紧密联系的容器，并且它们共享网络、磁盘，也就是它们能通过<code>localhost:port</code>访问到彼此，那以上的情况nginx作为gzip功能可以说和后端应用是紧密结合，所以可以以sidecar的形式部署。</p><h4 id="Nginx配置"><a href="#Nginx配置" class="headerlink" title="Nginx配置"></a>Nginx配置</h4><p>如果你的应用监听在8080端口，nginx监听在8090，可以如下配置</p><figure class="highlight nginx"><figcaption><span>/etc/nginx/site.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">user</span>  nginx;</span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">  <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="attribute">error_log</span>  /var/log/nginx/error.log <span class="literal">warn</span>;</span><br><span class="line"><span class="attribute">pid</span>        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">  <span class="attribute">include</span>       /etc/nginx/mime.types;</span><br><span class="line">  <span class="attribute">default_type</span>  application/octet-stream;</span><br><span class="line">  <span class="attribute">keepalive_timeout</span>  <span class="number">65</span>;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">gzip</span> <span class="literal">on</span>;</span><br><span class="line">  <span class="attribute">gzip_min_length</span>    <span class="number">256</span>;</span><br><span class="line">  <span class="attribute">gzip_types</span> application/javascript application/json text/css text/plain;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">include</span> /etc/nginx/conf.d/<span class="regexp">*.conf</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight nginx"><figcaption><span>/etc/nginx/conf.d/site.conf</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  <span class="attribute">listen</span> <span class="number">8090</span>;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">location</span> / &#123;</span><br><span class="line">      <span class="attribute">proxy_pass</span>              http://127.0.0.1:8088/;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> Host   <span class="variable">$http_host</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol><li><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/#uses-of-pods">Use of pods</a></li><li><a href="http://nginx.org/en/docs/http/ngx_http_gzip_module.html">Nginx gzip</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Encoding">HTTP Accept-Encoding</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Web-server’s-gzip&quot;&gt;&lt;a href=&quot;#Web-server’s-gzip&quot; class=&quot;headerlink&quot; title=&quot;Web server’s gzip&quot;&gt;&lt;/a&gt;Web server’s gzip&lt;/h3&gt;&lt;p&gt;Web服务开启数据压
      
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="kubernetes" scheme="https://songrgg.github.io/tags/kubernetes/"/>
    
      <category term="sidecar" scheme="https://songrgg.github.io/tags/sidecar/"/>
    
      <category term="nginx" scheme="https://songrgg.github.io/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Ansible常用命令</title>
    <link href="https://songrgg.github.io/operation/ansible-frequently-used-commands/"/>
    <id>https://songrgg.github.io/operation/ansible-frequently-used-commands/</id>
    <published>2018-03-05T20:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.396Z</updated>
    
    <content type="html"><![CDATA[<h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>记录一下常用的Ansible指令、模块，方便检索。</p><h3 id="Ansible主机"><a href="#Ansible主机" class="headerlink" title="Ansible主机"></a>Ansible主机</h3><p>/etc/ansible/hosts中，server是目标服务器列表名，包含两个服务器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[spark]</span><br><span class="line">10.0.0.1</span><br><span class="line">10.0.0.2</span><br></pre></td></tr></table></figure><h3 id="Ansible-Shell模块"><a href="#Ansible-Shell模块" class="headerlink" title="Ansible Shell模块"></a>Ansible Shell模块</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在spark集群上执行ls指令</span></span><br><span class="line">$ ansible spark -m shell -a <span class="string">'ls'</span></span><br></pre></td></tr></table></figure><h3 id="Ansible-playbook"><a href="#Ansible-playbook" class="headerlink" title="Ansible-playbook"></a>Ansible-playbook</h3><p>执行较大的复杂任务时，以<code>YAML</code>的声明语法来配置，并且可以放置一些模板类文件和资源文件等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">|___python.yml</span><br><span class="line">|___python.host</span><br><span class="line">|___roles</span><br><span class="line">| |___python</span><br><span class="line">| | |___defaults  # 默认变量</span><br><span class="line">| | |___handlers  # 可以被任务使用或者任何该任务之外的地方</span><br><span class="line">| | |___files</span><br><span class="line">| | |___vars      # 其它变量</span><br><span class="line">| | |___templates # 模板</span><br><span class="line">| | |___meta      # 元数据</span><br><span class="line">| | |___tasks     # 主要任务列表</span><br><span class="line">| | | |___main.yml</span><br><span class="line">| |___airflow</span><br><span class="line">| | |___tasks</span><br><span class="line">| | | |___main.yml</span><br><span class="line">| | | |___templates</span><br><span class="line">| | | | |___airflow.cfg</span><br></pre></td></tr></table></figure><h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 声明变量</span></span><br><span class="line"><span class="attr">foo:</span></span><br><span class="line">  <span class="attr">field1:</span> <span class="string">one</span></span><br><span class="line">  <span class="attr">field2:</span> <span class="string">two</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用base_path</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">app_servers</span></span><br><span class="line">  <span class="attr">vars:</span></span><br><span class="line">      <span class="attr">app_path:</span> <span class="string">&#123;</span> <span class="string">&#123;</span> <span class="string">base_path</span> <span class="string">&#125;</span> <span class="string">&#125;/22</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在命令行传入变量</span></span><br><span class="line">$ ansible-playbook release.yml --extra-vars <span class="string">"hosts=vipers user=starbuck"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件形式</span></span><br><span class="line">$ ansible-playbook release.yml --extra-vars <span class="string">"@some_file.json"</span></span><br></pre></td></tr></table></figure><p>更多的变量还有3类作用域等，以后用到再加。</p><h4 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将files目录下的conf/发送到目标节点</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">conf</span> <span class="string">files</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=conf/agent.conf</span> <span class="string">dest=/opt/flume/apache-flume-1.7.0-bin/conf/</span></span><br></pre></td></tr></table></figure><h4 id="handler"><a href="#handler" class="headerlink" title="handler"></a>handler</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># handlers/main.yml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">start</span> <span class="string">telegraf</span></span><br><span class="line">  <span class="attr">service:</span> <span class="string">name=telegraf</span> <span class="string">state=started</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝docker配置文件并触发docker重启</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">docker</span> <span class="string">conf</span> <span class="string">to</span> <span class="string">dest</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=conf/docker.conf</span> <span class="string">dest=/etc/telegraf/telegraf.d/</span></span><br><span class="line">  <span class="attr">when:</span> <span class="string">"'docker' in group_names"</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">restart</span> <span class="string">telegraf</span></span><br></pre></td></tr></table></figure><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p><code>roles</code>目录就是按具体安装的功能模块划分，比如python模块、jdk模块、spark模块等等，他们相互不重复，并且可以有依赖关系，比如jdk -&gt; spark，通过多个role的组合搭配出各种环境的配置方法。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python/tasks/main.yml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">apt:</span> </span><br><span class="line">    <span class="attr">name:</span> <span class="string">python-pip</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Upgrade</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">pip</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">--upgrade</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># airflow/tasks/main.yml</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">virtualenv</span> <span class="string">for</span> <span class="string">airflow</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">virtualenv</span> <span class="string">/home/ubuntu/airflow_v</span> <span class="string">creates=/home/ubuntu/airflow_v</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">mysqlclient</span></span><br><span class="line">  <span class="attr">apt:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">libmysqlclient-dev</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">airflow</span> <span class="string">within</span> <span class="string">`airflow_v`</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">apache-airflow[all]</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">/home/ubuntu/airflow_v</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">celery[redis]</span> <span class="string">within</span> <span class="string">`airflow_v`</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">celery[redis]</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">/home/ubuntu/airflow_v</span></span><br><span class="line">    </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">Airflow</span> <span class="string">home</span></span><br><span class="line">  <span class="attr">file:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/home/ubuntu/airflow</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">directory</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="number">0755</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Initialize</span> <span class="string">airflow</span> <span class="string">database</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">source</span> <span class="string">/home/ubuntu/airflow_v/bin/activate</span> <span class="string">&amp;&amp;</span> <span class="string">/home/ubuntu/airflow_v/bin/airflow</span> <span class="string">initdb</span> <span class="string">creates=/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="attr">AIRFLOW_HOME:</span> <span class="string">/home/ubuntu/airflow</span></span><br><span class="line">    </span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Syncronize</span> <span class="string">airflow</span> <span class="string">configuration</span></span><br><span class="line">  <span class="attr">synchronize:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">templates/airflow.cfg</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="入口文件"><a href="#入口文件" class="headerlink" title="入口文件"></a>入口文件</h4><p><code>python.yml</code>是ansible入口文件，包含目标host、运行的具体任务。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># 发布机上的代码初始化</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">hosts:</span> <span class="string">spark</span></span><br><span class="line">  <span class="attr">roles:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">python</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">airflow</span></span><br></pre></td></tr></table></figure><p>下面是任务中常用的模块</p><hr><h4 id="apt安装模块"><a href="#apt安装模块" class="headerlink" title="apt安装模块"></a>apt安装模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装pip</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">apt:</span> </span><br><span class="line">    <span class="attr">name:</span> <span class="string">python-pip</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">present</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="Pip安装模块"><a href="#Pip安装模块" class="headerlink" title="Pip安装模块"></a>Pip安装模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用pip升级pip</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Upgrade</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pip</span></span><br><span class="line">  <span class="attr">extra_args:</span> <span class="string">--upgrade</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用指定虚拟环境安装依赖</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">celery[redis]</span> <span class="string">within</span> <span class="string">`airflow_v`</span></span><br><span class="line">  <span class="attr">pip:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">celery[redis]</span></span><br><span class="line">    <span class="attr">extra_args:</span> <span class="string">-i</span> <span class="string">https://pypi.doubanio.com/simple/</span></span><br><span class="line">    <span class="attr">virtualenv:</span> <span class="string">/home/ubuntu/airflow_v</span></span><br></pre></td></tr></table></figure><h4 id="Shell模块"><a href="#Shell模块" class="headerlink" title="Shell模块"></a>Shell模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Initialize</span> <span class="string">airflow</span> <span class="string">database</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">source</span> <span class="string">/home/ubuntu/airflow_v/bin/activate</span> <span class="string">&amp;&amp;</span> <span class="string">/home/ubuntu/airflow_v/bin/airflow</span> <span class="string">initdb</span> <span class="string">creates=/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="attr">AIRFLOW_HOME:</span> <span class="string">/home/ubuntu/airflow</span></span><br></pre></td></tr></table></figure><h4 id="File模块"><a href="#File模块" class="headerlink" title="File模块"></a>File模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在目标服务器上创建权限为0755的目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Create</span> <span class="string">Airflow</span> <span class="string">home</span></span><br><span class="line">  <span class="attr">file:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/home/ubuntu/airflow</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">directory</span></span><br><span class="line">    <span class="attr">mode:</span> <span class="number">0755</span></span><br></pre></td></tr></table></figure><h4 id="Synchronize模块"><a href="#Synchronize模块" class="headerlink" title="Synchronize模块"></a>Synchronize模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将本地文件同步到目标服务器上</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Syncronize</span> <span class="string">airflow</span> <span class="string">configuration</span></span><br><span class="line">  <span class="attr">synchronize:</span></span><br><span class="line">    <span class="attr">src:</span> <span class="string">templates/airflow.cfg</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/home/ubuntu/airflow/airflow.cfg</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><h4 id="下载模块"><a href="#下载模块" class="headerlink" title="下载模块"></a>下载模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从指定URL下载文件到目标服务器指定目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Download</span> <span class="string">the</span> <span class="string">Go</span> <span class="string">tarball</span></span><br><span class="line">  <span class="attr">get_url:</span></span><br><span class="line">    <span class="attr">url:</span> <span class="string">"<span class="template-variable">&#123;&#123; go_download_location &#125;&#125;</span>"</span></span><br><span class="line">    <span class="attr">dest:</span> <span class="string">/usr/local/src/&#123;&#123;</span> <span class="string">go_tarball</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">checksum:</span> <span class="string">"<span class="template-variable">&#123;&#123; go_tarball_checksum &#125;&#125;</span>"</span></span><br></pre></td></tr></table></figure><h4 id="Systemd模块"><a href="#Systemd模块" class="headerlink" title="Systemd模块"></a>Systemd模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重启docker服务</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">systemd:</span></span><br><span class="line">    <span class="attr">state:</span> <span class="string">restarted</span></span><br><span class="line">    <span class="attr">daemon_reload:</span> <span class="literal">yes</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="Template模块"><a href="#Template模块" class="headerlink" title="Template模块"></a>Template模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将templates目录下的docker.my模板复制到目标服务器的/etc/default/docker目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Configure</span> <span class="string">docker</span> <span class="string">mirror</span> <span class="string">registry</span> <span class="string">to</span> <span class="string">Aliyun</span></span><br><span class="line">  <span class="attr">template:</span> <span class="string">src=docker.my</span> <span class="string">dest=/etc/default/docker</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="string">restart</span> <span class="string">docker</span></span><br><span class="line">  <span class="attr">become:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h4 id="Blockinfile模块"><a href="#Blockinfile模块" class="headerlink" title="Blockinfile模块"></a>Blockinfile模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个官网例子，在/etc/hosts里添加映射</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Add</span> <span class="string">mappings</span> <span class="string">to</span> <span class="string">/etc/hosts</span></span><br><span class="line">  <span class="attr">blockinfile:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/etc/hosts</span></span><br><span class="line">    <span class="attr">block:</span> <span class="string">|</span></span><br><span class="line">      <span class="string">&#123;&#123;</span> <span class="string">item.ip</span> <span class="string">&#125;&#125;</span> <span class="string">&#123;&#123;</span> <span class="string">item.name</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">marker:</span> <span class="string">"# &#123;mark&#125; ANSIBLE MANAGED BLOCK <span class="template-variable">&#123;&#123; item.name &#125;&#125;</span>"</span></span><br><span class="line">  <span class="attr">with_items:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">name:</span> <span class="string">host1,</span> <span class="attr">ip:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.10</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">name:</span> <span class="string">host2,</span> <span class="attr">ip:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.11</span> <span class="string">&#125;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#123;</span> <span class="attr">name:</span> <span class="string">host3,</span> <span class="attr">ip:</span> <span class="number">10.10</span><span class="number">.1</span><span class="number">.12</span> <span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h4 id="Copy模块"><a href="#Copy模块" class="headerlink" title="Copy模块"></a>Copy模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拷贝zookeeper配置文件</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">copy</span> <span class="string">zookeeper</span> <span class="string">conf</span> <span class="string">to</span> <span class="string">dest</span> <span class="string">host</span></span><br><span class="line">  <span class="attr">copy:</span> <span class="string">src=conf/zookeeper.conf</span> <span class="string">dest=/etc/zookeeper/conf/</span></span><br></pre></td></tr></table></figure><h4 id="Service模块"><a href="#Service模块" class="headerlink" title="Service模块"></a>Service模块</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">restart</span> <span class="string">telegraf</span></span><br><span class="line">  <span class="attr">service:</span> <span class="string">name=telegraf</span> <span class="string">state=restarted</span></span><br></pre></td></tr></table></figure><h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><ol><li><a href="http://docs.ansible.com/ansible/latest/" title="Ansible文档">http://docs.ansible.com/ansible/latest/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;动机&quot;&gt;&lt;a href=&quot;#动机&quot; class=&quot;headerlink&quot; title=&quot;动机&quot;&gt;&lt;/a&gt;动机&lt;/h3&gt;&lt;p&gt;记录一下常用的Ansible指令、模块，方便检索。&lt;/p&gt;
&lt;h3 id=&quot;Ansible主机&quot;&gt;&lt;a href=&quot;#Ansible主机&quot; 
      
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
  </entry>
  
  <entry>
    <title>Spark on Hive实现APP渠道分析</title>
    <link href="https://songrgg.github.io/programming/spark-on-hive-app-channel-analytics/"/>
    <id>https://songrgg.github.io/programming/spark-on-hive-app-channel-analytics/</id>
    <published>2018-02-04T20:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.414Z</updated>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>最近在做APP投放渠道分析，就是Android应用投放到应用市场，所谓渠道就是huawei,xiaomi,yingyongbao之类，运营人员根据数据分析渠道的下载安装情况、各个渠道的投放效果。</p><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>完成一个Android渠道分析的展示面板，包含以下指标：</p><ul><li>APP总新增激活数量</li><li>按渠道划分的新增数量</li><li>各渠道的新增变化走势图（以小时为单位）</li><li>品牌占比</li><li>操作系统占比</li></ul><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/images/app-channel-analytics-architecture.webp" alt="app channel analytics"></p><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>APP激活时上报给服务端数据，Flume处理数据并将数据发送到Kafka。</p><h4 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h4><p>客户端上报对JSON格式更加友好，所以这里选择使用JSON格式，格式定义一方面需要考虑客户端的开发成本，一方面需要考虑日后的拓展性，所以最直接的方法是统一固定的字段，将根据事件所变化的内容放到拓展字段里去，拓展字段是Map类型，可以支持各种拓展的形式。</p><h4 id="数据内容"><a href="#数据内容" class="headerlink" title="数据内容"></a>数据内容</h4><p>以此次渠道分析为例，客户端需要上传客户端的渠道、APP版本、设备标志符、设备型号等信息，更详细的如Geo信息，如果想获得更好的数据展示效果，可以上传，但在此场景可以不需要，这些是主动上报的部分。还有一部分内容是需要在服务端获取的，例如设备IP，为了之后的地理展示，可以使用MaxMind公司的IP与城市对应的数据库进行地理解析。</p><h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><p><a href="https://flume.apache.org">flume</a>接受到客户端的数据之后，需要对数据进行解析JSON，并且获得用户IP、分析Geo Location做一些轻量级的处理，因为这个部分是在前端flume做的，这个部分的flume重点是逻辑要轻，重要的是吞吐量高和延迟低。</p><p>接下来前端flume把处理完的数据按照事件名发送到<a href="https://kafka.apache.org">Kafka</a>同名的topic中，后端flume消费Kafka并将消息转存到Hdfs中。</p><h4 id="数据持久化"><a href="#数据持久化" class="headerlink" title="数据持久化"></a>数据持久化</h4><p>将数据从Hdfs持久化到Hive，一方面是更节省空间，一方面是更有利于<a href="https://spark.apache.org">Spark</a>进行查询。</p><p>这里持久化到Hive的方法，可以有几种：</p><ul><li>Flume直接读取Kafka的数据并存储到Hive，这是由Flume的Hive Sink实现的，数据持久化到Hive Transaction表，是Hive 0.13引入的，支持ACID。</li><li>Flume读取数据到Hdfs，支持配置文件路径，可以根据时间来划分存储路径，之后可以定期使用Hive加载数据，将数据存储到Hive中去。</li></ul><p>第一种方法，相对来说配置简单，省去了中间一步转储的过程。第二种方法，相对繁琐，但是之后会有一个好处。</p><p>下面是设备注册表<code>device_registration</code>的schema</p><figure class="highlight sql"><figcaption><span>device_registration</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`bi.device_registration`</span>(</span><br><span class="line">  <span class="string">`app_id`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`uid`</span> <span class="built_in">bigint</span>,</span><br><span class="line">  <span class="string">`time`</span> <span class="built_in">bigint</span>,</span><br><span class="line">  <span class="string">`ip`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`device_id`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`app_version`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`os_name`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`os_version`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`device_brand`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`device_model`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`ua_name`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`ua_version`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`channel`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`ts`</span> <span class="built_in">timestamp</span>,</span><br><span class="line">  <span class="string">`lon`</span> <span class="keyword">double</span>,</span><br><span class="line">  <span class="string">`lat`</span> <span class="keyword">double</span>,</span><br><span class="line">  <span class="string">`country`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`city`</span> <span class="keyword">string</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这里要提一下，为什么有了<code>time</code>这个unix时间戳，还需要<code>ts</code>这个<code>timestamp</code>类型的时间，实际上是为了之后的查询工具<code>Superset</code>需要使用来实现按时间查询。</p><h3 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h3><p>这里的计算每小时运行一次，从Hive中读取过去一个小时的设备激活原数据，与<code>device_registration</code>进行比对，将未出现在<code>device_registration</code>中的设备信息加入。</p><p>这里可以使用<code>JOIN</code>来实现，Spark数据表之间的Join方式有多种，<code>inner</code>, <code>cross</code>, <code>outer</code>, <code>full</code>, <code>full_outer</code>, <code>left</code>, <code>left_outer</code>, <code>right</code>, <code>right_outer</code>, <code>left_semi</code>, <code>left_anti</code></p><p>这里场景适合使用<code>left_anti</code>，因为是取不在这个集合的设备信息。</p><p>这里还要注意，因为时间区间内的数据有可能会有重复，所以需要取时间较早的那条，这里用到了<code>groupByKey</code>和<code>reduceGroups</code>，具体是</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">deviceInfos.as[<span class="type">Device</span>]</span><br><span class="line">    .groupByKey(_.device_id)</span><br><span class="line">    .reduceGroups((x, y) =&gt; <span class="keyword">if</span> (x.time &lt; y.time) x <span class="keyword">else</span> y)</span><br><span class="line">    .map[<span class="type">Device</span>]((x: (<span class="type">String</span>, <span class="type">Device</span>)) =&gt; x._2)</span><br><span class="line">    .write.mode(<span class="type">SaveMode</span>.<span class="type">Append</span>)</span><br><span class="line">    .format(<span class="string">"hive"</span>)</span><br><span class="line">    .saveAsTable(<span class="string">"bi.device_registration"</span>)</span><br></pre></td></tr></table></figure><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>查询引擎使用<a href="https://prestodb.io">Presto</a>，配置Hive Connector，实时搜索数据。刚才上面提到数据持久化Hive中的两种方法，其中支持事务的表不可用于Presto的查询，因为Hive Transaction表的数据格式未被Presto支持(详见<a href="https://github.com/prestodb/presto/issues/1970">Implement Hive ACID table support</a>)。</p><h5 id="直接查询"><a href="#直接查询" class="headerlink" title="直接查询"></a>直接查询</h5><p>通过上一步的<code>device_registration</code>表，我们可以通过时间维度进行查询。</p><p>直接查询就是查询raw data，数据更加丰富。这里以“按渠道划分的新增数量”为例，</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="string">"channel"</span> <span class="keyword">AS</span> <span class="string">"channel"</span>,</span><br><span class="line">       date_trunc(<span class="string">'hour'</span>, <span class="keyword">CAST</span>(ts <span class="keyword">AS</span> <span class="built_in">TIMESTAMP</span>)) <span class="keyword">AS</span> <span class="string">"__timestamp"</span>,</span><br><span class="line">       <span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> <span class="string">"count"</span></span><br><span class="line"><span class="keyword">FROM</span> <span class="string">"bi"</span>.<span class="string">"device_registration"</span></span><br><span class="line"><span class="keyword">WHERE</span> <span class="string">"ts"</span> &gt;= from_iso8601_timestamp(<span class="string">'2018-02-03T16:29:29'</span>)</span><br><span class="line">  <span class="keyword">AND</span> <span class="string">"ts"</span> &lt;= from_iso8601_timestamp(<span class="string">'2018-02-05T08:29:29'</span>)</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="string">"channel"</span>,</span><br><span class="line">         date_trunc(<span class="string">'hour'</span>, <span class="keyword">CAST</span>(ts <span class="keyword">AS</span> <span class="built_in">TIMESTAMP</span>))</span><br></pre></td></tr></table></figure><h5 id="预先计算"><a href="#预先计算" class="headerlink" title="预先计算"></a>预先计算</h5><p>预先计算就是将图表展示需要的数据结果提前计算存储到数据库，查询的时候直接就可以从结果表中查询。</p><p>预先计算是用空间换时间，损失一些灵活性，不如查询raw data时可以自由定制查询。每次新增查询对于预先计算来说都需要新增加计算逻辑。随着数据量的增大，预先计算不可避免。</p><h5 id="优化查询速度"><a href="#优化查询速度" class="headerlink" title="优化查询速度"></a>优化查询速度</h5><p>运行一段时间后，查询速度明显变慢，查看Hdfs上的hive目录发现数据表内的小文件多达几百上千，这是由于Spark处理完数据并写入Hive会产生非常多的bucket，与数据条数成正比，写入成本低却增加了读数据的成本，这样当数据查询时，由于Hdfs上的小文件非常之多，I/O花费很大，导致整体查询速度下降迅速，这里想办法将文件进行合并，减少文件数量。</p><p>通过使用Hive执行compaction，方法比较取巧，就是在每次计算完数据之后，运行Hive脚本，通过复制数据库，Hive会自动将文件数量压缩：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> bi.device_registration_compact <span class="keyword">AS</span> <span class="keyword">SELECT</span> * <span class="keyword">from</span> bi.device_registration;</span><br><span class="line"><span class="keyword">DROP</span> <span class="keyword">TABLE</span> bi.device_registration;</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> bi.device_registration_compact <span class="keyword">RENAME</span> <span class="keyword">TO</span> bi.device_registration;</span><br></pre></td></tr></table></figure><p>将Hdfs上的文件数量降低到个位数，查询也在秒级完成，这种方法只适用于数据量不大的情况，目前记录条数在1M以内的查询速度在秒级，之后依然会考虑使用其它方案改良。</p><h3 id="展示"><a href="#展示" class="headerlink" title="展示"></a>展示</h3><p><a href="https://superset.apache.org/">Superset</a>是Airbnb开源的图表展示工具，不仅支持很多后端查询引擎，并且有许多成熟的图表展示，更可贵的是拥有用户权限管理。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h3&gt;&lt;p&gt;最近在做APP投放渠道分析，就是Android应用投放到应用市场，所谓渠道就是huawei,xiaomi,yingyongbao之类，运营人
      
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="hive" scheme="https://songrgg.github.io/tags/hive/"/>
    
      <category term="spark" scheme="https://songrgg.github.io/tags/spark/"/>
    
      <category term="app channel analytics" scheme="https://songrgg.github.io/tags/app-channel-analytics/"/>
    
  </entry>
  
  <entry>
    <title>Hive on spark实践</title>
    <link href="https://songrgg.github.io/programming/hive-on-spark-practice/"/>
    <id>https://songrgg.github.io/programming/hive-on-spark-practice/</id>
    <published>2018-01-14T23:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.402Z</updated>
    
    <content type="html"><![CDATA[<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>利用Cloudera的CDH套件搭建好Hadoop 2.6，可CDH中的Hive版本不高，于是独立安装Hive 2.3，由于Hive的执行引擎默认是Spark，根据Hive官网上的Hive on Spark教程开始配置。</p><h5 id="Standalone"><a href="#Standalone" class="headerlink" title="Standalone"></a>Standalone</h5><p>配置了Spark Standalone模式之后，配置Hive遇到一些困难。</p><p>由于使用的是pre-build版本的Spark，遇到报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java.lang.NoSuchFieldError: SPARK_RPC_CLIENT_CONNECT_TIMEOUT</span><br><span class="line">    at org.apache.hive.spark.client.rpc.RpcConfiguration.&lt;clinit&gt;(RpcConfiguration.java:46)</span><br></pre></td></tr></table></figure><p>接下来要自己编译Spark without Hive，可是一直没有解决，报错为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[info] &#39;compiler-interface&#39; not yet compiled for Scala 2.11.8. Compiling...</span><br><span class="line">error: scala.reflect.internal.MissingRequirementError: object java.lang.Object in compiler mirror not found.</span><br><span class="line">at scala.reflect.internal.MissingRequirementError$.signal(MissingRequirementError.scala:17)</span><br><span class="line">at scala.reflect.internal.MissingRequirementError$.notFound(MissingRequirementError.scala:18)</span><br></pre></td></tr></table></figure><p>非常曲折，最后选择尝试已经配置好的Yarn模式的Spark。</p><h5 id="Yarn"><a href="#Yarn" class="headerlink" title="Yarn"></a>Yarn</h5><p>Yarn模式的Spark集群已经就绪，在Hive中配置Spark</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">set hive.execution.engine&#x3D;spark;</span><br><span class="line">set spark.master&#x3D;yarn;</span><br><span class="line">set spark.executor.memory&#x3D;512m;</span><br><span class="line">set spark.serializer&#x3D;org.apache.spark.serializer.KryoSerializer;</span><br><span class="line">set spark.eventLog.enabled&#x3D;true;</span><br><span class="line">set spark.eventLog.dir&#x3D;&lt;Spark event log folder (must exist)&gt;</span><br></pre></td></tr></table></figure><p>上传Spark应用所需的Spark依赖jar包到Hdfs中，例如放到Hdfs中的/spark-jars目录，并配置hive-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>spark.yarn.jars<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://xxxx:8020/spark-jars/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意这里需要保证使用Hive时的用户能够有权限访问Hdfs上指定的目录。</p><h4 id="用户数据导入"><a href="#用户数据导入" class="headerlink" title="用户数据导入"></a>用户数据导入</h4><h5 id="源数据"><a href="#源数据" class="headerlink" title="源数据"></a>源数据</h5><p>当源数据是JSON并位于Hdfs的/tmp目录，如</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"time"</span>: <span class="string">"1515682813526"</span>,</span><br><span class="line">    <span class="string">"uid"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">"ip"</span>: <span class="string">"1.1.1.1"</span>,</span><br><span class="line">    <span class="string">"path"</span>: <span class="string">"https://github.com"</span>,</span><br><span class="line">    <span class="string">"referer"</span>: <span class="string">"https://google.com"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="创建Hive外部表"><a href="#创建Hive外部表" class="headerlink" title="创建Hive外部表"></a>创建Hive外部表</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> tmp.pageview(</span><br><span class="line">    <span class="built_in">time</span> <span class="built_in">BIGINT</span>,</span><br><span class="line">    uid  <span class="built_in">BIGINT</span>,</span><br><span class="line">    ip   <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="keyword">path</span> <span class="keyword">STRING</span>,</span><br><span class="line">    referer <span class="keyword">STRING</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> SERDE <span class="string">'org.apache.hive.hcatalog.data.JsonSerDe'</span></span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> TEXTFILE</span><br><span class="line">LOCATION <span class="string">'/tmp'</span>;</span><br></pre></td></tr></table></figure><h5 id="导入ORC表"><a href="#导入ORC表" class="headerlink" title="导入ORC表"></a>导入ORC表</h5><p>ORC表是Hive的一种高效表，在查询上更加快速，可以从外部表将数据导入ORC表。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> orc.pageview(</span><br><span class="line">    <span class="built_in">time</span> <span class="built_in">BIGINT</span>,</span><br><span class="line">    uid  <span class="built_in">BIGINT</span>,</span><br><span class="line">    ip   <span class="keyword">STRING</span>,</span><br><span class="line">    <span class="keyword">path</span> <span class="keyword">STRING</span>,</span><br><span class="line">    referer <span class="keyword">STRING</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">STORED</span> <span class="keyword">AS</span> ORC;</span><br><span class="line"></span><br><span class="line">FROM tmp.pageview pv</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> orc.pageview</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">time</span>, uid, ip, <span class="keyword">path</span>, referer;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;配置&quot;&gt;&lt;a href=&quot;#配置&quot; class=&quot;headerlink&quot; title=&quot;配置&quot;&gt;&lt;/a&gt;配置&lt;/h4&gt;&lt;p&gt;利用Cloudera的CDH套件搭建好Hadoop 2.6，可CDH中的Hive版本不高，于是独立安装Hive 2.3，由于Hive的执行引
      
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="hive" scheme="https://songrgg.github.io/tags/hive/"/>
    
      <category term="spark" scheme="https://songrgg.github.io/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>etcd生产环境实践</title>
    <link href="https://songrgg.github.io/operation/etcd-for-production/"/>
    <id>https://songrgg.github.io/operation/etcd-for-production/</id>
    <published>2017-06-12T19:27:50.000Z</published>
    <updated>2020-03-20T19:02:13.398Z</updated>
    
    <content type="html"><![CDATA[<h3 id="生产环境搭建etcd"><a href="#生产环境搭建etcd" class="headerlink" title="生产环境搭建etcd"></a>生产环境搭建etcd</h3><p>以搭建3节点高可用ETCD集群为例，分别在三台主机上初始化<code>ETCD1</code>,<code>ETCD2</code>,<code>ETCD3</code>作为机器IP地址。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">$ ETCD1=http://10.0.0.1</span><br><span class="line">$ ETCD2=http://10.0.0.2</span><br><span class="line">$ ETCD2=http://10.0.0.3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点1为4核4GB的机器</span></span><br><span class="line">$ etcd --name etcd1 \</span><br><span class="line">--initial-advertise-peer-urls <span class="variable">$ETCD1</span>:2380  \</span><br><span class="line">--listen-peer-urls <span class="variable">$ETCD1</span>:2380  \</span><br><span class="line">--listen-client-urls <span class="variable">$ETCD1</span>:2379,http://127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls <span class="variable">$ETCD1</span>:2379  \</span><br><span class="line">--initial-cluster-token etcd-cluster \</span><br><span class="line">--initial-cluster etcd1=<span class="variable">$ETCD1</span>:2380,etcd2=<span class="variable">$ETCD2</span>:2380,etcd3=<span class="variable">$ETCD3</span>:2380 \</span><br><span class="line">--auto-compaction-retention=1 \</span><br><span class="line">--quota-backend-bytes=$((4*1024*1024*1024)) \</span><br><span class="line">--initial-cluster-state new</span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点2为4核4GB的机器</span></span><br><span class="line">$ etcd  --name etcd2 \</span><br><span class="line">--initial-advertise-peer-urls <span class="variable">$ETCD2</span>:2380 \</span><br><span class="line">--listen-peer-urls <span class="variable">$ETCD2</span>:2380 \</span><br><span class="line">--listen-client-urls <span class="variable">$ETCD2</span>:2379,http://127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls <span class="variable">$ETCD2</span>:2379 \</span><br><span class="line">--initial-cluster-token etcd-cluster \</span><br><span class="line">--initial-cluster etcd1=<span class="variable">$ETCD1</span>:2380,etcd2=<span class="variable">$ETCD2</span>:2380,etcd3=<span class="variable">$ETCD3</span>:2380 \</span><br><span class="line">--auto-compaction-retention=1 \</span><br><span class="line">--quota-backend-bytes=$((4*1024*1024*1024)) \</span><br><span class="line">--initial-cluster-state new</span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点3为4核4GB的机器</span></span><br><span class="line">$ etcd  --name etcd3 \</span><br><span class="line">--initial-advertise-peer-urls <span class="variable">$ETCD3</span>:2380 \</span><br><span class="line">--listen-peer-urls <span class="variable">$ETCD3</span>:2380 \</span><br><span class="line">--listen-client-urls <span class="variable">$ETCD3</span>:2379,http://127.0.0.1:2379 \</span><br><span class="line">--advertise-client-urls <span class="variable">$ETCD3</span>:2379 \</span><br><span class="line">--initial-cluster-token etcd-cluster \</span><br><span class="line">--initial-cluster etcd1=<span class="variable">$ETCD1</span>:2380,etcd2=<span class="variable">$ETCD2</span>:2380,etcd3=<span class="variable">$ETCD3</span>:2380 \</span><br><span class="line">--auto-compaction-retention=1 \</span><br><span class="line">--quota-backend-bytes=$((4*1024*1024*1024)) \</span><br><span class="line">--initial-cluster-state new</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查集群是否正确启动</span></span><br><span class="line">$ etcdctl --endpoints=<span class="variable">$ETCD1</span>:2379 member list</span><br><span class="line">400938f1eaf1d0ed: name=etcd3 peerURLs=http://10.0.0.1:2380 clientURLs=http://10.0.0.1:2379 isLeader=<span class="literal">false</span></span><br><span class="line">bd0ff97b33ac1165: name=etcd2 peerURLs=http://10.0.0.2:2380 clientURLs=http://10.0.0.2:2379 isLeader=<span class="literal">false</span></span><br><span class="line">be62429afec4445f: name=etcd1 peerURLs=http://10.0.0.3:2380 clientURLs=http://10.0.0.3:2379 isLeader=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="历史记录压缩"><a href="#历史记录压缩" class="headerlink" title="历史记录压缩"></a>历史记录压缩</h3><p>如果将etcd用作服务发现，每次服务注册和更新都可以看做一条新数据，日积月累，这些数据的量会导致etcd占用内存越来越大，直到etcd到达空间配额限制的时候，etcd的写入将会被静止，影响线上服务，定期删除历史记录就是避免这种情况。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只保留一个小时的历史数据</span></span><br><span class="line">$ etcd --auto-compaction-retention=1</span><br></pre></td></tr></table></figure><h3 id="磁盘去碎片化"><a href="#磁盘去碎片化" class="headerlink" title="磁盘去碎片化"></a>磁盘去碎片化</h3><p><a href="https://coreos.com/etcd/docs/latest/op-guide/maintenance.html#defragmentation">etcd官方</a>是说在进行compaction操作之后，旧的revision被压缩，会产生内部的碎片，内部碎片是指空闲状态的，能被后端使用但是仍然消耗存储空间的磁盘空间。去碎片化实际上是将存储空间还给文件系统。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl defrag</span><br></pre></td></tr></table></figure><h3 id="空间配额"><a href="#空间配额" class="headerlink" title="空间配额"></a>空间配额</h3><p>空间配额用来保障集群可靠地进行操作。如果没有限制配额，当键空间变大之后，直到用光了磁盘空间，它就会影响etcd集群的表现。当任意节点超出空间配额， 那么它将进入维护状态，只接受读/删操作。只有释放了足够空间、去碎片化了后端数据库并且清理了空间配额之后，集群才能继续正常操作。</p><p>默认限制是<strong>2GB</strong>，可以通过<code>--quota-backend-bytes</code>配置，最高上限为<strong>8GB</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显式配置配额为16MB</span></span><br><span class="line">$ etcd --quota-backend-bytes=$((16*1024*1024))</span><br><span class="line">$ ETCDCTL_API=3 etcdctl --write-out=table endpoint status</span><br></pre></td></tr></table></figure><p>如果遇到空间配额不足的情况，那么需要对etcd进行操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取当前版本号</span></span><br><span class="line">$ rev=$(ETCDCTL_API=3 etcdctl --endpoints=:2379 endpoint status --write-out=<span class="string">"json"</span> | egrep -o <span class="string">'"revision":[0-9]*'</span> | egrep -o <span class="string">'[0-9]*'</span>）</span><br><span class="line"><span class="comment"># 压缩所有旧版本</span></span><br><span class="line">$ ETCDCTL_API=3 etcdctl compact <span class="variable">$rev</span></span><br><span class="line"><span class="comment"># 去碎片化</span></span><br><span class="line">$ ETCDCTL_API=3 etcdctl defrag</span><br><span class="line"><span class="comment"># 取消警报</span></span><br><span class="line">$ ETCDCTL_API=3 etcdctl alarm disarm</span><br><span class="line"><span class="comment"># 测试通过</span></span><br><span class="line">$ ETCDCTL_API=3 etcdctl put newkey 123</span><br></pre></td></tr></table></figure><h3 id="快照备份"><a href="#快照备份" class="headerlink" title="快照备份"></a>快照备份</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ etcdctl snapshot save backup.db</span><br><span class="line">$ etcdctl --write-out=table snapshot status backup.db</span><br><span class="line">+----------+----------+------------+------------+</span><br><span class="line">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</span><br><span class="line">+----------+----------+------------+------------+</span><br><span class="line">| fe01cf57 |       10 |          7 | 2.1 MB     |</span><br><span class="line">+----------+----------+------------+------------+</span><br></pre></td></tr></table></figure><h3 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h3><p>跨数据中心时，需要调整心跳间隔和选举超时时间<br>默认的心跳时间是100ms，建议为round trip时间<br>默认选举超时是1000ms</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ol><li><a href="https://coreos.com/etcd/docs/latest/op-guide/configuration.html">详细配置</a></li><li><a href="https://github.com/coreos/etcd/blob/master/Documentation/op-guide/maintenance.md">etcd运维</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;生产环境搭建etcd&quot;&gt;&lt;a href=&quot;#生产环境搭建etcd&quot; class=&quot;headerlink&quot; title=&quot;生产环境搭建etcd&quot;&gt;&lt;/a&gt;生产环境搭建etcd&lt;/h3&gt;&lt;p&gt;以搭建3节点高可用ETCD集群为例，分别在三台主机上初始化&lt;code&gt;ETC
      
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
      <category term="etcd" scheme="https://songrgg.github.io/tags/etcd/"/>
    
      <category term="operation" scheme="https://songrgg.github.io/tags/operation/"/>
    
      <category term="configuration management" scheme="https://songrgg.github.io/tags/configuration-management/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统频次限制实现</title>
    <link href="https://songrgg.github.io/programming/rate-limiter-for-distributed-system/"/>
    <id>https://songrgg.github.io/programming/rate-limiter-for-distributed-system/</id>
    <published>2017-06-02T22:00:00.000Z</published>
    <updated>2020-02-22T14:36:02.181Z</updated>
    
    <content type="html"><![CDATA[<p>频次限制（rate limiting）是Web系统比较常见的功能，防止用户频繁访问接口，导致系统负载增加而影响服务的质量。这里来介绍在分布式系统中实现一个共享的频次限制服务，且保证接口低时延高访问量。</p><a id="more"></a><h3 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h3><ul><li>针对线上的功能，实现对指定对象有访问频次的限制</li><li>支持多个客户端访问</li><li>低延迟</li><li>承受较大的访问量</li><li>易于拓展</li></ul><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><ol><li>设置服务频次限制，如针对某个消耗资源很高的API设置1QPS的访问限制，并为单一用户生成访问该API的唯一<code>key</code>，如<code>userA_APIX</code>就是表示userA访问APIX的情况</li><li>根据指定<code>key</code>，服务向<code>ratelimiter</code>询问是否允许此次访问</li></ol><h4 id="基于令牌桶算法的伪代码"><a href="#基于令牌桶算法的伪代码" class="headerlink" title="基于令牌桶算法的伪代码"></a>基于令牌桶算法的伪代码</h4><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始换状态</span></span><br><span class="line">rate := <span class="number">1</span> <span class="comment">// 设置频率为1ops</span></span><br><span class="line">needed := <span class="number">1</span> <span class="comment">// 设置访问1次API需要的令牌数量为1</span></span><br><span class="line">key := <span class="string">"userA_APIX"</span> <span class="comment">// userA访问APIX的场景</span></span><br><span class="line">tokens := <span class="number">0</span> <span class="comment">// 当前可用令牌数</span></span><br><span class="line">lastTime := time.Now() <span class="comment">// 上次令牌更新时间</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 时间过去1s</span></span><br><span class="line">time.Sleep(time.Second)</span><br><span class="line"></span><br><span class="line"><span class="comment">// userA请求访问APIX</span></span><br><span class="line">nowTime := time.Now()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算这段时间新生成的令牌数量</span></span><br><span class="line">newTokens := (nowTime-lastTime)*rate</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断是否允许访问</span></span><br><span class="line">allow := (newTokens+tokens)&gt;needed</span><br><span class="line"></span><br><span class="line"><span class="comment">// 更新数据</span></span><br><span class="line"><span class="keyword">if</span> allow &#123;</span><br><span class="line">    tokens = newTokens+tokens-needed</span><br><span class="line">    lastTime = nowTime</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 响应用户操作</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    tokens = tokens+newTokens</span><br><span class="line">    lastTime = nowTime</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提示用户操作超过限制</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h3><ol><li><p>频次限制应该统一存储<br>webserver是任意可拓展个数的服务，一开始，我将<code>ratelimiter</code>的存储放在了各自服务中，导致明明我限制的是整个集群这个<code>API</code>的访问单人不可超过<code>1</code>QPS，如果N个服务，实际上是<code>N</code>QPS。所以这个频次限制需要集中存储，统一整个系统的访问频次。</p></li><li><p>频次限制本质是一个服务<br>我试着把存储挪到了<code>redis</code>，并且使用了一些<code>redis</code>的<code>WATCH</code>命令实现了<strong>CAS</strong>(Compare And Set)，<code>redis</code>里存了<code>key</code>，<code>tokens</code>，<code>lastTime</code>，算法逻辑仍然放在<code>client</code>端（也就是那些web server）。<br>经过压测，QPS比较低，主要是因为CAS的重试率随着并发量上升不断升高，况且重试过程不断访问<code>redis</code>增加了网络开销，于是考虑如何将逻辑和数据放到一起。</p></li><li><p>控制成本<br>重新开发一个频限服务，需要考虑多节点数据同步，请求转发，failover等功能，我希望以最小的开支实现这个系统。</p></li></ol><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>最终选择了<code>redis</code>的<code>lua</code>脚本实现了频限功能，既统一了存储，又可以利用<code>redis cluster</code>实现了可拓展的频限服务，以最小的成本实现功能。<br>我司技术栈是<code>Golang</code>，所以实现了<code>Golang</code>的简单库，逻辑是初始化<code>redis client</code>并将<code>lua</code>脚本上传，在判断是否超过频率限制的时候，使用<code>EVALSHA</code>命令执行。由于逻辑都在<code>redis</code>端，所以客户端实际上代码极少，只要注意<code>redis</code>挂了不影响服务的响应，并且<code>redis</code>重启后保证<code>lua</code>脚本上传等。</p><p><code>lua</code>脚本是来自<code>Stripe</code>公司的一位工程师：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> tokens_key = KEYS[<span class="number">1</span>]</span><br><span class="line"><span class="keyword">local</span> timestamp_key = KEYS[<span class="number">2</span>]</span><br><span class="line"><span class="keyword">local</span> rate = <span class="built_in">tonumber</span>(ARGV[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">local</span> capacity = <span class="built_in">tonumber</span>(ARGV[<span class="number">2</span>])</span><br><span class="line"><span class="keyword">local</span> now = <span class="built_in">tonumber</span>(ARGV[<span class="number">3</span>])</span><br><span class="line"><span class="keyword">local</span> requested = <span class="built_in">tonumber</span>(ARGV[<span class="number">4</span>])</span><br><span class="line"><span class="keyword">local</span> fill_time = capacity/rate</span><br><span class="line"><span class="keyword">local</span> ttl = <span class="built_in">math</span>.<span class="built_in">floor</span>(fill_time*<span class="number">2</span>)</span><br><span class="line"><span class="keyword">local</span> last_tokens = <span class="built_in">tonumber</span>(redis.call(<span class="string">"get"</span>, tokens_key))</span><br><span class="line"><span class="keyword">if</span> last_tokens == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">    last_tokens = capacity</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">local</span> last_refreshed = <span class="built_in">tonumber</span>(redis.call(<span class="string">"get"</span>, timestamp_key))</span><br><span class="line"><span class="keyword">if</span> last_refreshed == <span class="literal">nil</span> <span class="keyword">then</span></span><br><span class="line">    last_refreshed = <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">local</span> delta = <span class="built_in">math</span>.<span class="built_in">max</span>(<span class="number">0</span>, now-last_refreshed)</span><br><span class="line"><span class="keyword">local</span> filled_tokens = <span class="built_in">math</span>.<span class="built_in">min</span>(capacity, last_tokens+(delta*rate))</span><br><span class="line"><span class="keyword">local</span> allowed = filled_tokens &gt;= requested</span><br><span class="line"><span class="keyword">local</span> new_tokens = filled_tokens</span><br><span class="line"><span class="keyword">if</span> allowed <span class="keyword">then</span></span><br><span class="line">    new_tokens = filled_tokens - requested</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">redis.call(<span class="string">"setex"</span>, tokens_key, ttl, new_tokens)</span><br><span class="line">redis.call(<span class="string">"setex"</span>, timestamp_key, ttl, now)</span><br><span class="line"><span class="keyword">return</span> &#123; allowed, new_tokens &#125;</span><br></pre></td></tr></table></figure><p>通过<code>SCRIPT LOAD</code>上传该脚本获得<code>hash</code>，使用<code>EVALSHA &lt;hash&gt; 2 userA_APIX_token userA_APIX_ts 1 1 &lt;now_time&gt; 1</code>调用该脚本，根据返回的<code>allowed</code>决定此次操作是否进行。</p><h3 id="benchmark"><a href="#benchmark" class="headerlink" title="benchmark"></a>benchmark</h3><p>经过测试，MacBook Pro (Retina, 13-inch, Late 2013), CPU 2.4 GHz Intel Core i5, Memory 8 GB 1600 MHz DDR3上能达到<strong>1w+</strong>QPS。</p><h3 id="项目地址"><a href="#项目地址" class="headerlink" title="项目地址"></a>项目地址</h3><p><a href="https://github.com/wallstreetcn/rate">ratelimiter的golang实现</a>，目前该版本暂时支持<code>redis client</code>，为了拓展性，可以将其升级为<code>redis cluster</code>，满足大并发系统的需求。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;频次限制（rate limiting）是Web系统比较常见的功能，防止用户频繁访问接口，导致系统负载增加而影响服务的质量。这里来介绍在分布式系统中实现一个共享的频次限制服务，且保证接口低时延高访问量。&lt;/p&gt;
    
    </summary>
    
    
      <category term="programming" scheme="https://songrgg.github.io/categories/programming/"/>
    
    
      <category term="distributed system" scheme="https://songrgg.github.io/tags/distributed-system/"/>
    
      <category term="ratelimiter" scheme="https://songrgg.github.io/tags/ratelimiter/"/>
    
  </entry>
  
  <entry>
    <title>基于gitlab搭建CI</title>
    <link href="https://songrgg.github.io/operation/build-ci-with-gitlab/"/>
    <id>https://songrgg.github.io/operation/build-ci-with-gitlab/</id>
    <published>2017-04-17T22:00:00.000Z</published>
    <updated>2020-03-20T19:02:13.396Z</updated>
    
    <content type="html"><![CDATA[<h4 id="自建gitlab"><a href="#自建gitlab" class="headerlink" title="自建gitlab"></a>自建gitlab</h4><p>自建gitlab一大优势是<strong>快</strong>，之前用翻墙走github速度也在1M/s左右，可是自建的gitlab提升了建立连接的速度，可以说体验又上升了一个档次。</p><p>用docker起一个gitlab服务尤其方便 <a href="https://docs.gitlab.com/omnibus/docker/README.html">GitLab Docker images</a></p><a id="more"></a><h4 id="选择CI"><a href="#选择CI" class="headerlink" title="选择CI"></a>选择CI</h4><p>如果有人像我一样对Jenkins的UI和配置不感兴趣，那么Gitlab CI runner是不错的选择，配置用<code>YAML</code>，清晰明了，UI集成在gitlab中。<strong>对比jenkins，上手容易，颜值更高。</strong></p><h4 id="Gitlab-CI-runner"><a href="#Gitlab-CI-runner" class="headerlink" title="Gitlab CI runner"></a>Gitlab CI runner</h4><ul><li>找一台ubuntu 16.04，机器配置按照项目大小和数量决定</li><li>安装CI runner<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install gitlab-ci-multi-runner</span><br></pre></td></tr></table></figure></li><li>将runner注册到gitlab<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo gitlab-ci-multi-runner register</span><br></pre></td></tr></table></figure></li><li>调整配置<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">concurrent</span> <span class="string">=</span> <span class="number">16</span> <span class="comment"># 更新并发build数量到16</span></span><br><span class="line"></span><br><span class="line"><span class="string">[[runners]]</span></span><br><span class="line">  <span class="string">name</span> <span class="string">=</span> <span class="string">"10-1-10-10"</span> <span class="comment"># 这里是runner的名字</span></span><br><span class="line">  <span class="string">url</span> <span class="string">=</span> <span class="string">"https://gitlab.com"</span> <span class="comment"># 所属gitlab的url</span></span><br><span class="line">  <span class="string">token</span> <span class="string">=</span> <span class="string">"please-input-gitlab-register-token"</span> <span class="comment"># gitlab注册token</span></span><br><span class="line">  <span class="string">executor</span> <span class="string">=</span> <span class="string">"docker"</span> <span class="comment"># 以docker形式运行每次CI任务</span></span><br><span class="line">  <span class="string">[runners.docker]</span></span><br><span class="line">    <span class="string">tls_verify</span> <span class="string">=</span> <span class="literal">false</span></span><br><span class="line">    <span class="string">image</span> <span class="string">=</span> <span class="string">"ruby:2.1"</span> <span class="comment"># docker运行的默认镜像</span></span><br><span class="line">    <span class="string">privileged</span> <span class="string">=</span> <span class="literal">false</span> <span class="comment"># 不授权</span></span><br><span class="line">    <span class="string">volumes</span> <span class="string">=</span> <span class="string">["/cache",</span> <span class="string">"/var/run/docker.sock:/var/run/docker.sock"</span><span class="string">]</span></span><br><span class="line">    <span class="string">extra_hosts</span> <span class="string">=</span> <span class="string">["gitlab.com:some-internal-ip"]</span></span><br><span class="line">  <span class="string">[runners.cache]</span></span><br></pre></td></tr></table></figure></li></ul><blockquote><p><strong>调整<em>concurrent</em>，最大限度利用机器</strong><br><strong>若镜像中使用<code>docker push</code>等命令，将宿主机<em>docker.sock</em>挂载到容器中</strong><br><strong>若gitlab与runner在同网络，设置docker容器内的gitlab host为内网IP，最小化网络延迟</strong></p></blockquote><h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p>pipeline指CI的流程可以当做管道，只有上一个操作成功之后，下一个操作继续执行，如利用gitlab ci构建build-&gt;test-&gt;release-&gt;deployment的流程，当代码push到<code>master</code>时，CI触发，如下<br><img src="/images/gitlabci.webp" alt="gitlabci"></p><h4 id="配置CI"><a href="#配置CI" class="headerlink" title="配置CI"></a>配置CI</h4><p><strong>.gitlab-ci.yml</strong>是gitlab项目的CI配置文件，文件形式是<code>yaml</code>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="string">ruby:2.1</span></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">release</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">deployment</span></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line">  <span class="attr">DOCKER_DRIVER:</span> <span class="string">overlay</span></span><br><span class="line">  <span class="attr">SERVICE_NAME:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">CONTAINER_TEST_IMAGE:</span> <span class="string">$IMAGE_NAME:$CI_BUILD_REF_NAME</span></span><br><span class="line">  <span class="attr">CONTAINER_RELEASE_IMAGE:</span> <span class="string">$IMAGE_NAME:latest</span></span><br><span class="line"></span><br><span class="line"><span class="attr">test:1.8.0:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">golang:1.8</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">before_script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"before test"</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"test"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">build:test:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">golang:1.8</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">before_script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"before script"</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">mkdir</span> <span class="string">-p</span> <span class="string">binaries/</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">touch</span> <span class="string">binaries/test</span></span><br><span class="line">  <span class="attr">artifacts:</span></span><br><span class="line">    <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">binaries/</span></span><br><span class="line">    <span class="attr">expire_in:</span> <span class="string">1h</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">build:prod:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">golang:1.8</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">build</span></span><br><span class="line">  <span class="attr">before_script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"before build"</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">mkdir</span> <span class="string">-p</span> <span class="string">binaries/</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">touch</span> <span class="string">binaries/prod</span></span><br><span class="line">  <span class="attr">artifacts:</span></span><br><span class="line">    <span class="attr">paths:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">binaries/</span></span><br><span class="line">    <span class="attr">expire_in:</span> <span class="string">1h</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line"></span><br><span class="line"><span class="attr">release:test:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">release</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"release $CONTAINER_TEST_IMAGE"</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">test</span></span><br><span class="line">  <span class="attr">dependencies:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">build:test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">release:prod:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">release</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"release $CONTAINER_RELEASE_IMAGE"</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">dependencies:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">build:prod</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deployment:test:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">deployment</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">kroniak/ssh-client</span></span><br><span class="line">  <span class="attr">before_script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"before script"</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"deployment test"</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">test</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deployment:stage:</span></span><br><span class="line">  <span class="attr">stage:</span> <span class="string">deployment</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">kroniak/ssh-client</span></span><br><span class="line">  <span class="attr">before_script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"before script"</span></span><br><span class="line">  <span class="attr">only:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">script:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">echo</span> <span class="string">"deployment stage"</span></span><br></pre></td></tr></table></figure><ul><li>stage声明管道有几个阶段，stage的顺序代表着前置stage完成后才能进入下一个stage，每个stage有1个或多个可执行点</li><li>每个可执行操作里有一些配置<ul><li>stage<br>当前执行所属阶段，就是文件开头声明的<code>stages</code>列表中一个</li><li>image<br>当前命令执行的基础镜像</li><li>before_script<br>脚本执行前初始化命令</li><li>only<br>限制执行的分支，例如只有test分支能触发<code>deployment:test</code></li><li>script(required)<br>执行的脚本</li><li>artifacts<br>这次执行将产生的需要传递给下一个stage的文件</li><li>dependencies<br>当前执行依赖的前置执行，不仅是声明一种依赖关系，同时上个执行生成的artifacts也会传递过来</li></ul></li><li>在gitlab项目中设置<strong>CI/CD Pipelines</strong>的<code>variables</code>，可以为docker容器注入隐秘变量，如docker仓库秘钥，这些变量可以在CI运行脚本时被解析。</li></ul><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>Gitlab CI能自定义阶段和在容器里执行脚本，并且水平拓容便捷，和Gitlab的集成好。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;自建gitlab&quot;&gt;&lt;a href=&quot;#自建gitlab&quot; class=&quot;headerlink&quot; title=&quot;自建gitlab&quot;&gt;&lt;/a&gt;自建gitlab&lt;/h4&gt;&lt;p&gt;自建gitlab一大优势是&lt;strong&gt;快&lt;/strong&gt;，之前用翻墙走github速度也在1M/s左右，可是自建的gitlab提升了建立连接的速度，可以说体验又上升了一个档次。&lt;/p&gt;
&lt;p&gt;用docker起一个gitlab服务尤其方便 &lt;a href=&quot;https://docs.gitlab.com/omnibus/docker/README.html&quot;&gt;GitLab Docker images&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="operation" scheme="https://songrgg.github.io/categories/operation/"/>
    
    
  </entry>
  
</feed>
